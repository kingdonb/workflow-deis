{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Deis Workflow \u00b6 Deis (pronounced DAY-iss) Workflow is an open source Platform as a Service (PaaS) that adds a developer-friendly layer to any Kubernetes cluster, making it easy to deploy and manage applications. Deis Workflow includes capabilities for building and deploying from source via git push , simple application configuration, creating and rolling back releases, managing domain names and SSL certificates, providing seamless edge routing, aggregating logs, and sharing applications with teams. All of this is exposed through a simple REST API and command line interface. Please note that this documentation is for Hephy Workflow (v2.19.4). Older versions of Deis and Hephy Workflow are not supported. Getting Started \u00b6 To get started with Workflow, follow our Quick Start guide. Take a deep dive into Deis Workflow in our Concepts , Architecture , and Components sections. Feel like contibuting some code or want to get started as a maintainer? Pick an issue tagged as an easy fix or help wanted and start contributing! Service and Support \u00b6 Coming soon.","title":"Home"},{"location":"#welcome-to-deis-workflow","text":"Deis (pronounced DAY-iss) Workflow is an open source Platform as a Service (PaaS) that adds a developer-friendly layer to any Kubernetes cluster, making it easy to deploy and manage applications. Deis Workflow includes capabilities for building and deploying from source via git push , simple application configuration, creating and rolling back releases, managing domain names and SSL certificates, providing seamless edge routing, aggregating logs, and sharing applications with teams. All of this is exposed through a simple REST API and command line interface. Please note that this documentation is for Hephy Workflow (v2.19.4). Older versions of Deis and Hephy Workflow are not supported.","title":"Welcome to Deis Workflow"},{"location":"#getting-started","text":"To get started with Workflow, follow our Quick Start guide. Take a deep dive into Deis Workflow in our Concepts , Architecture , and Components sections. Feel like contibuting some code or want to get started as a maintainer? Pick an issue tagged as an easy fix or help wanted and start contributing!","title":"Getting Started"},{"location":"#service-and-support","text":"Coming soon.","title":"Service and Support"},{"location":"_includes/install-workflow/","text":"Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install workflow"},{"location":"_includes/install-workflow/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"_includes/install-workflow/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"_includes/install-workflow/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Deis Workflow"},{"location":"applications/deploying-apps/","text":"Deploying an Application \u00b6 An Application is deployed to Deis using git push or the deis client. Supported Applications \u00b6 Deis Workflow can deploy any application or service that can run inside a Docker container. In order to be scaled horizontally, applications must follow the Twelve-Factor App methodology and store any application state in external backing services. For example, if your application persists state to the local filesystem -- common with content management systems like Wordpress and Drupal -- it cannot be scaled horizontally using deis scale . Fortunately, most modern applications feature a stateless application tier that can scale horizontally inside Deis. Login to the Controller \u00b6 Important if you haven't yet, now is a good time to install the client and register . Before deploying an application, users must first authenticate against the Deis Controller using the URL supplied by their Deis administrator. $ deis login http://deis.example.com username: deis password: Logged in as deis Select a Build Process \u00b6 Deis Workflow supports three different ways of building applications: Buildpacks \u00b6 Heroku buildpacks are useful if you want to follow Heroku's best practices for building applications or if you are porting an application from Heroku. Learn how to deploy applications using Buildpacks . Dockerfiles \u00b6 Dockerfiles are a powerful way to define a portable execution environment built on a base OS of your choosing. Learn how to deploy applications using Dockerfiles . Docker Image \u00b6 Deploying a Docker image onto Deis allows you to take a Docker image from either a public or a private registry and copy it over bit-for-bit, ensuring that you are running the same image in development or in your CI pipeline as you are in production. Learn how to deploy applications using Docker images . Tuning Application Settings \u00b6 It is possible to configure a few of the globally tunable settings on per application basis using config:set . Setting Description DEIS_DISABLE_CACHE if set, this will disable the slugbuilder cache (default: not set) DEIS_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DEIS_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes [image pull policy][pull-policy] for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) Deploy Timeout \u00b6 Deploy timeout in seconds - There are 2 deploy methods, Deployments (see below) and RC (versions prior to 2.4) and this setting affects those a bit differently. Deployments \u00b6 Deployments behave a little bit differently from the RC based deployment strategy. Kubernetes takes care of the entire deploy, doing rolling updates in the background. As a result, there is only an overall deployment timeout instead of a configurable per-batch timeout. The base timeout is multiplied with DEIS_DEPLOY_BATCHES to create an overall timeout. This would be 240 (timeout) * 4 (batches) = 960 second overall timeout. RC deploy \u00b6 This deploy timeout defines how long to wait for each batch to complete in DEIS_DEPLOY_BATCHES . Additions to the base timeout \u00b6 The base timeout is extended as well with healthchecks using initialDelaySeconds on liveness and readiness where the bigger of those two is applied. Additionally the timeout system accounts for slow image pulls by adding an additional 10 minutes when it has seen an image pull take over 1 minute. This allows the timeout values to be reasonable without having to account for image pull slowness in the base deploy timeout. Deployments \u00b6 Workflow uses Deployments for deploys. In prior versions ReplicationControllers were used with the ability to turn on Deployments via DEIS_KUBERNETES_DEPLOYMENTS=1 . The advantage of Deployments is that rolling-updates will happen server-side in Kubernetes instead of in Deis Workflow Controller, along with a few other Pod management related functionality. This allows a deploy to continue even when the CLI connection is interrupted. Behind the scenes your application deploy will be built up of a Deployment object per process type, each having multiple ReplicaSets (one per release) which in turn manage the Pods running your application. Deis Workflow will behave the same way with DEIS_KUBERNETES_DEPLOYMENTS enabled or disabled (only applicable to versions prior to 2.4). The changes are behind the scenes. Where you will see differences while using the CLI is deis ps:list will output Pod names differently.","title":"Deploying Apps"},{"location":"applications/deploying-apps/#deploying-an-application","text":"An Application is deployed to Deis using git push or the deis client.","title":"Deploying an Application"},{"location":"applications/deploying-apps/#supported-applications","text":"Deis Workflow can deploy any application or service that can run inside a Docker container. In order to be scaled horizontally, applications must follow the Twelve-Factor App methodology and store any application state in external backing services. For example, if your application persists state to the local filesystem -- common with content management systems like Wordpress and Drupal -- it cannot be scaled horizontally using deis scale . Fortunately, most modern applications feature a stateless application tier that can scale horizontally inside Deis.","title":"Supported Applications"},{"location":"applications/deploying-apps/#login-to-the-controller","text":"Important if you haven't yet, now is a good time to install the client and register . Before deploying an application, users must first authenticate against the Deis Controller using the URL supplied by their Deis administrator. $ deis login http://deis.example.com username: deis password: Logged in as deis","title":"Login to the Controller"},{"location":"applications/deploying-apps/#select-a-build-process","text":"Deis Workflow supports three different ways of building applications:","title":"Select a Build Process"},{"location":"applications/deploying-apps/#buildpacks","text":"Heroku buildpacks are useful if you want to follow Heroku's best practices for building applications or if you are porting an application from Heroku. Learn how to deploy applications using Buildpacks .","title":"Buildpacks"},{"location":"applications/deploying-apps/#dockerfiles","text":"Dockerfiles are a powerful way to define a portable execution environment built on a base OS of your choosing. Learn how to deploy applications using Dockerfiles .","title":"Dockerfiles"},{"location":"applications/deploying-apps/#docker-image","text":"Deploying a Docker image onto Deis allows you to take a Docker image from either a public or a private registry and copy it over bit-for-bit, ensuring that you are running the same image in development or in your CI pipeline as you are in production. Learn how to deploy applications using Docker images .","title":"Docker Image"},{"location":"applications/deploying-apps/#tuning-application-settings","text":"It is possible to configure a few of the globally tunable settings on per application basis using config:set . Setting Description DEIS_DISABLE_CACHE if set, this will disable the slugbuilder cache (default: not set) DEIS_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DEIS_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes [image pull policy][pull-policy] for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30)","title":"Tuning Application Settings"},{"location":"applications/deploying-apps/#deploy-timeout","text":"Deploy timeout in seconds - There are 2 deploy methods, Deployments (see below) and RC (versions prior to 2.4) and this setting affects those a bit differently.","title":"Deploy Timeout"},{"location":"applications/deploying-apps/#deployments","text":"Deployments behave a little bit differently from the RC based deployment strategy. Kubernetes takes care of the entire deploy, doing rolling updates in the background. As a result, there is only an overall deployment timeout instead of a configurable per-batch timeout. The base timeout is multiplied with DEIS_DEPLOY_BATCHES to create an overall timeout. This would be 240 (timeout) * 4 (batches) = 960 second overall timeout.","title":"Deployments"},{"location":"applications/deploying-apps/#rc-deploy","text":"This deploy timeout defines how long to wait for each batch to complete in DEIS_DEPLOY_BATCHES .","title":"RC deploy"},{"location":"applications/deploying-apps/#additions-to-the-base-timeout","text":"The base timeout is extended as well with healthchecks using initialDelaySeconds on liveness and readiness where the bigger of those two is applied. Additionally the timeout system accounts for slow image pulls by adding an additional 10 minutes when it has seen an image pull take over 1 minute. This allows the timeout values to be reasonable without having to account for image pull slowness in the base deploy timeout.","title":"Additions to the base timeout"},{"location":"applications/deploying-apps/#deployments_1","text":"Workflow uses Deployments for deploys. In prior versions ReplicationControllers were used with the ability to turn on Deployments via DEIS_KUBERNETES_DEPLOYMENTS=1 . The advantage of Deployments is that rolling-updates will happen server-side in Kubernetes instead of in Deis Workflow Controller, along with a few other Pod management related functionality. This allows a deploy to continue even when the CLI connection is interrupted. Behind the scenes your application deploy will be built up of a Deployment object per process type, each having multiple ReplicaSets (one per release) which in turn manage the Pods running your application. Deis Workflow will behave the same way with DEIS_KUBERNETES_DEPLOYMENTS enabled or disabled (only applicable to versions prior to 2.4). The changes are behind the scenes. Where you will see differences while using the CLI is deis ps:list will output Pod names differently.","title":"Deployments"},{"location":"applications/domains-and-routing/","text":"Domains and Routing \u00b6 You can use deis domains to add or remove custom domains to the application: $ deis domains:add hello.bacongobbler.com Adding hello.bacongobbler.com to finest-woodshed... done Once that's done, you can go into a DNS registrar and set up a CNAME from the new appname to the old one: $ dig hello.deisapp.com [...] ;; ANSWER SECTION: hello.bacongobbler.com. 1759 IN CNAME finest-woodshed.deisapp.com. finest-woodshed.deisapp.com. 270 IN A 172.17.8.100 Note Setting a CNAME for a root domain can cause issues. Setting an @ record to be a CNAME causes all traffic to go to the other domain, including mail and the SOA (\"start-of-authority\") records. It is highly recommended that you bind a subdomain to an application, however you can work around this by pointing the @ record to the address of the load balancer (if any). To add or remove the application from the routing mesh, use deis routing : $ deis routing:disable Disabling routing for finest-woodshed... done This will make the application unreachable through the Router , but the application is still reachable internally through its Kubernetes Service . To re-enable routing: $ deis routing:enable Enabling routing for finest-woodshed... done","title":"Domains and Routing"},{"location":"applications/domains-and-routing/#domains-and-routing","text":"You can use deis domains to add or remove custom domains to the application: $ deis domains:add hello.bacongobbler.com Adding hello.bacongobbler.com to finest-woodshed... done Once that's done, you can go into a DNS registrar and set up a CNAME from the new appname to the old one: $ dig hello.deisapp.com [...] ;; ANSWER SECTION: hello.bacongobbler.com. 1759 IN CNAME finest-woodshed.deisapp.com. finest-woodshed.deisapp.com. 270 IN A 172.17.8.100 Note Setting a CNAME for a root domain can cause issues. Setting an @ record to be a CNAME causes all traffic to go to the other domain, including mail and the SOA (\"start-of-authority\") records. It is highly recommended that you bind a subdomain to an application, however you can work around this by pointing the @ record to the address of the load balancer (if any). To add or remove the application from the routing mesh, use deis routing : $ deis routing:disable Disabling routing for finest-woodshed... done This will make the application unreachable through the Router , but the application is still reachable internally through its Kubernetes Service . To re-enable routing: $ deis routing:enable Enabling routing for finest-woodshed... done","title":"Domains and Routing"},{"location":"applications/inter-app-communication/","text":"Inter-app Communication \u00b6 A common architecture pattern of multi-process applications is to have one process serve public requests while having multiple other processes supporting the public one to, for example, perform actions on a schedule or process work items from a queue. To implement this system of apps in Deis Workflow, set up the apps to communicate using DNS resolution, as shown above, and hide the supporting processes from public view by removing them from the Deis Workflow router. See Deis Blog: Private Applications on Workflow for more details, which walks through an example of removing an app from the router. DNS Service Discovery \u00b6 Deis Workflow supports deploying a single app composed of a system of processes. Each Deis Workflow app communicates on a single port, so communicating with another Workflow app means finding that app's address and port. All Workflow apps are mapped to port 80 externally, so finding its IP address is the only challenge. Workflow creates a Kubernetes Service for each app, which effectively assigns a name and one cluster-internal IP address to an app. The DNS service running in the cluster adds and removes DNS records which point from the app name to its IP address as services are added and removed. Deis Workflow apps, then, can simply send requests to the domain name given to the service, which is \"app-name.app-namespace\".","title":"Inter-app Communication"},{"location":"applications/inter-app-communication/#inter-app-communication","text":"A common architecture pattern of multi-process applications is to have one process serve public requests while having multiple other processes supporting the public one to, for example, perform actions on a schedule or process work items from a queue. To implement this system of apps in Deis Workflow, set up the apps to communicate using DNS resolution, as shown above, and hide the supporting processes from public view by removing them from the Deis Workflow router. See Deis Blog: Private Applications on Workflow for more details, which walks through an example of removing an app from the router.","title":"Inter-app Communication"},{"location":"applications/inter-app-communication/#dns-service-discovery","text":"Deis Workflow supports deploying a single app composed of a system of processes. Each Deis Workflow app communicates on a single port, so communicating with another Workflow app means finding that app's address and port. All Workflow apps are mapped to port 80 externally, so finding its IP address is the only challenge. Workflow creates a Kubernetes Service for each app, which effectively assigns a name and one cluster-internal IP address to an app. The DNS service running in the cluster adds and removes DNS records which point from the app name to its IP address as services are added and removed. Deis Workflow apps, then, can simply send requests to the domain name given to the service, which is \"app-name.app-namespace\".","title":"DNS Service Discovery"},{"location":"applications/managing-app-configuration/","text":"Configuring an Application \u00b6 A Deis application stores config in environment variables . Setting Environment Variables \u00b6 Use deis config to modify environment variables for a deployed application. $ deis help config Valid commands for config: config:list list environment variables for an app config:set set environment variables for an app config:unset unset environment variables for an app config:pull extract environment variables to .env config:push set environment variables from .env Use `deis help [command]` to learn more. When config is changed, a new release is created and deployed automatically. You can set multiple environment variables with one deis config:set command, or with deis config:push and a local .env file. $ deis config:set FOO=1 BAR=baz && deis config:pull $ cat .env FOO=1 BAR=baz $ echo \"TIDE=high\" >> .env $ deis config:push Creating config... done, v4 === yuppie-earthman DEIS_APP: yuppie-earthman FOO: 1 BAR: baz TIDE: high Attach to Backing Services \u00b6 Deis treats backing services like databases, caches and queues as attached resources . Attachments are performed using environment variables. For example, use deis config to set a DATABASE_URL that attaches the application to an external PostgreSQL database. $ deis config:set DATABASE_URL=postgres://user:pass@example.com:5432/db === peachy-waxworks DATABASE_URL: postgres://user:pass@example.com:5432/db Detachments can be performed with deis config:unset . Slugbuilder Cache \u00b6 By default, apps using the Slugbuilder will have caching turned on. This means that Deis will persist all data being written to CACHE_DIR inside the buildpack will be persisted between deploys. When deploying applications that depend on third-party libraries that have to be fetched, this could speed up deployments a lot. In order to make use of this, the buildpack must implement the cache by writing to the cache directory. Most buildpacks already implement this, but when using custom buildpacks, it might need to be changed to make full use of the cache. Disabling and re-enabling the cache \u00b6 In some cases, cache might not speed up your application. To disable caching, you can set the DEIS_DISABLE_CACHE variable with deis config:set DEIS_DISABLE_CACHE=1 . When you disable the cache, Deis will clear up files it created to store the cache. After having it turned off, run deis config:unset DEIS_DISABLE_CACHE to re-enable the cache. Clearing the cache \u00b6 Use the following procedure to clear the cache: $ deis config:set DEIS_DISABLE_CACHE=1 $ git commit --allow-empty -m \"Clearing Deis cache\" $ git push deis # (if you use a different remote, you should use your remote name) $ deis config:unset DEIS_DISABLE_CACHE Custom Health Checks \u00b6 By default, Workflow only checks that the application starts in their Container. If it is preferred to have Kubernetes respond to application health, a health check may be added by configuring a health check probe for the application. The health checks are implemented as Kubernetes container probes . A liveness and a readiness probe can be configured, and each probe can be of type httpGet , exec , or tcpSocket depending on the type of probe the container requires. A liveness probe is useful for applications running for long periods of time, eventually transitioning to broken states and cannot recover except by restarting them. Other times, a readiness probe is useful when the container is only temporarily unable to serve, and will recover on its own. In this case, if a container fails its readiness probe, the container will not be shut down, but rather the container will stop receiving incoming requests. httpGet probes are just as it sounds: it performs a HTTP GET operation on the Container. A response code inside the 200-399 range is considered a pass. exec probes run a command inside the Container to determine its health, such as cat /var/run/myapp.pid or a script that determines when the application is ready. An exit code of zero is considered a pass, while a non-zero status code is considered a fail. tcpSocket probes attempt to open a socket in the Container. The Container is only considered healthy if the check can establish a connection. tcpSocket probes accept a port number to perform the socket connection on the Container. Health checks can be configured on a per-proctype basis for each application using deis healthchecks:set . If no type is mentioned then the health checks are applied to default proc types, web or cmd, whichever is present. To configure a httpGet liveness probe: $ deis healthchecks:set liveness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. If the application relies on certain headers being set (such as the Host header) or a specific URL path relative to the root, you can also send specific HTTP headers: $ deis healthchecks:set liveness httpGet 80 \\ --path /welcome/index.html \\ --headers \"X-Client-Version:v1.0,X-Foo:bar\" === peachy-waxworks Healthchecks web/cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/welcome/index.html\" Port=80 HTTPHeaders=[X-Client-Version=v1.0] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. To configure an exec readiness probe: $ deis healthchecks:set readiness exec -- /bin/echo -n hello --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: Command=[/bin/echo -n hello] HTTP GET Probe: N/A TCP Socket Probe: N/A You can overwrite a probe by running deis healthchecks:set again: $ deis healthchecks:set readiness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Configured health checks also modify the default application deploy behavior. When starting a new Pod, Workflow will wait for the health check to pass before moving onto the next Pod. Isolate the Application \u00b6 Workflow supports isolating applications onto a set of nodes using deis tags . Note In order to use tags, you must first launch your cluster with the proper node labels. If you do not, tag commands will fail. Learn more by reading \"Assigning Pods to Nodes\" . Once your nodes are configured with appropriate label selectors, use deis tags:set to restrict the application to those nodes: $ deis tags:set environ=prod Applying tags... done, v4 environ prod","title":"Managing App Configuration"},{"location":"applications/managing-app-configuration/#configuring-an-application","text":"A Deis application stores config in environment variables .","title":"Configuring an Application"},{"location":"applications/managing-app-configuration/#setting-environment-variables","text":"Use deis config to modify environment variables for a deployed application. $ deis help config Valid commands for config: config:list list environment variables for an app config:set set environment variables for an app config:unset unset environment variables for an app config:pull extract environment variables to .env config:push set environment variables from .env Use `deis help [command]` to learn more. When config is changed, a new release is created and deployed automatically. You can set multiple environment variables with one deis config:set command, or with deis config:push and a local .env file. $ deis config:set FOO=1 BAR=baz && deis config:pull $ cat .env FOO=1 BAR=baz $ echo \"TIDE=high\" >> .env $ deis config:push Creating config... done, v4 === yuppie-earthman DEIS_APP: yuppie-earthman FOO: 1 BAR: baz TIDE: high","title":"Setting Environment Variables"},{"location":"applications/managing-app-configuration/#attach-to-backing-services","text":"Deis treats backing services like databases, caches and queues as attached resources . Attachments are performed using environment variables. For example, use deis config to set a DATABASE_URL that attaches the application to an external PostgreSQL database. $ deis config:set DATABASE_URL=postgres://user:pass@example.com:5432/db === peachy-waxworks DATABASE_URL: postgres://user:pass@example.com:5432/db Detachments can be performed with deis config:unset .","title":"Attach to Backing Services"},{"location":"applications/managing-app-configuration/#slugbuilder-cache","text":"By default, apps using the Slugbuilder will have caching turned on. This means that Deis will persist all data being written to CACHE_DIR inside the buildpack will be persisted between deploys. When deploying applications that depend on third-party libraries that have to be fetched, this could speed up deployments a lot. In order to make use of this, the buildpack must implement the cache by writing to the cache directory. Most buildpacks already implement this, but when using custom buildpacks, it might need to be changed to make full use of the cache.","title":"Slugbuilder Cache"},{"location":"applications/managing-app-configuration/#disabling-and-re-enabling-the-cache","text":"In some cases, cache might not speed up your application. To disable caching, you can set the DEIS_DISABLE_CACHE variable with deis config:set DEIS_DISABLE_CACHE=1 . When you disable the cache, Deis will clear up files it created to store the cache. After having it turned off, run deis config:unset DEIS_DISABLE_CACHE to re-enable the cache.","title":"Disabling and re-enabling the cache"},{"location":"applications/managing-app-configuration/#clearing-the-cache","text":"Use the following procedure to clear the cache: $ deis config:set DEIS_DISABLE_CACHE=1 $ git commit --allow-empty -m \"Clearing Deis cache\" $ git push deis # (if you use a different remote, you should use your remote name) $ deis config:unset DEIS_DISABLE_CACHE","title":"Clearing the cache"},{"location":"applications/managing-app-configuration/#custom-health-checks","text":"By default, Workflow only checks that the application starts in their Container. If it is preferred to have Kubernetes respond to application health, a health check may be added by configuring a health check probe for the application. The health checks are implemented as Kubernetes container probes . A liveness and a readiness probe can be configured, and each probe can be of type httpGet , exec , or tcpSocket depending on the type of probe the container requires. A liveness probe is useful for applications running for long periods of time, eventually transitioning to broken states and cannot recover except by restarting them. Other times, a readiness probe is useful when the container is only temporarily unable to serve, and will recover on its own. In this case, if a container fails its readiness probe, the container will not be shut down, but rather the container will stop receiving incoming requests. httpGet probes are just as it sounds: it performs a HTTP GET operation on the Container. A response code inside the 200-399 range is considered a pass. exec probes run a command inside the Container to determine its health, such as cat /var/run/myapp.pid or a script that determines when the application is ready. An exit code of zero is considered a pass, while a non-zero status code is considered a fail. tcpSocket probes attempt to open a socket in the Container. The Container is only considered healthy if the check can establish a connection. tcpSocket probes accept a port number to perform the socket connection on the Container. Health checks can be configured on a per-proctype basis for each application using deis healthchecks:set . If no type is mentioned then the health checks are applied to default proc types, web or cmd, whichever is present. To configure a httpGet liveness probe: $ deis healthchecks:set liveness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. If the application relies on certain headers being set (such as the Host header) or a specific URL path relative to the root, you can also send specific HTTP headers: $ deis healthchecks:set liveness httpGet 80 \\ --path /welcome/index.html \\ --headers \"X-Client-Version:v1.0,X-Foo:bar\" === peachy-waxworks Healthchecks web/cmd: Liveness -------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/welcome/index.html\" Port=80 HTTPHeaders=[X-Client-Version=v1.0] TCP Socket Probe: N/A Readiness --------- No readiness probe configured. To configure an exec readiness probe: $ deis healthchecks:set readiness exec -- /bin/echo -n hello --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: Command=[/bin/echo -n hello] HTTP GET Probe: N/A TCP Socket Probe: N/A You can overwrite a probe by running deis healthchecks:set again: $ deis healthchecks:set readiness httpGet 80 --type cmd === peachy-waxworks Healthchecks cmd: Liveness -------- No liveness probe configured. Readiness --------- Initial Delay (seconds): 50 Timeout (seconds): 50 Period (seconds): 10 Success Threshold: 1 Failure Threshold: 3 Exec Probe: N/A HTTP GET Probe: Path=\"/\" Port=80 HTTPHeaders=[] TCP Socket Probe: N/A Configured health checks also modify the default application deploy behavior. When starting a new Pod, Workflow will wait for the health check to pass before moving onto the next Pod.","title":"Custom Health Checks"},{"location":"applications/managing-app-configuration/#isolate-the-application","text":"Workflow supports isolating applications onto a set of nodes using deis tags . Note In order to use tags, you must first launch your cluster with the proper node labels. If you do not, tag commands will fail. Learn more by reading \"Assigning Pods to Nodes\" . Once your nodes are configured with appropriate label selectors, use deis tags:set to restrict the application to those nodes: $ deis tags:set environ=prod Applying tags... done, v4 environ prod","title":"Isolate the Application"},{"location":"applications/managing-app-lifecycle/","text":"Managing an Application \u00b6 Track Application Changes \u00b6 Deis Workflow tracks all changes to your application. Application changes are the result of either new application code pushed to the platform (via git push deis master ), or an update to application configuration (via deis config:set KEY=VAL ). Each time a build or config change is made to your application a new release is created. These release numbers increase monotonically. You can see a record of changes to your application using deis releases : $ deis releases === peachy-waxworks Releases v4 3 minutes ago gabrtv deployed d3ccc05 v3 1 hour 17 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 2 minutes ago gabrtv deployed deis/helloworld Rollback a Release \u00b6 Deis Workflow also supports rolling back go previous releases. If buggy code or an errant configuration change is pushed to your application, you may rollback to a previously known, good release. Note All rollbacks create a new, numbered release. But will reference the build/code and configuration from the desired rollback point. In this example, the application is currently running release v4. Using deis rollback v2 tells Workflow to deploy the build and configuration that was used for release v2. This creates a new release named v5 whose contents are the source and configuration from release v2: $ deis releases === folksy-offshoot Releases v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed deis/helloworld $ deis rollback v2 Rolled back to v2 $ deis releases === folksy-offshoot Releases v5 Just now gabrtv rolled back to v2 v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed deis/helloworld Run One-off Administration Tasks \u00b6 Deis applications use one-off processes for admin tasks like database migrations and other commands that must run against the live application. Use deis run to execute commands on the deployed application. $ deis run 'ls -l' Running `ls -l`... total 28 -rw-r--r-- 1 root root 553 Dec 2 23:59 LICENSE -rw-r--r-- 1 root root 60 Dec 2 23:59 Procfile -rw-r--r-- 1 root root 33 Dec 2 23:59 README.md -rw-r--r-- 1 root root 1622 Dec 2 23:59 pom.xml drwxr-xr-x 3 root root 4096 Dec 2 23:59 src -rw-r--r-- 1 root root 25 Dec 2 23:59 system.properties drwxr-xr-x 6 root root 4096 Dec 3 00:00 target Share an Application \u00b6 Use deis perms:create to allow another Deis user to collaborate on your application. $ deis perms:create otheruser Adding otheruser to peachy-waxworks collaborators... done Use deis perms to see who an application is currently shared with, and deis perms:remove to remove a collaborator. Note Collaborators can do anything with an application that its owner can do, except delete the application. When working with an application that has been shared with you, clone the original repository and add Deis' git remote entry before attempting to git push any changes to Deis. $ git clone https://github.com/teamhephy/example-java-jetty.git Cloning into 'example-java-jetty'... done $ cd example-java-jetty $ git remote add -f deis ssh://git@local3.deisapp.com:2222/peachy-waxworks.git Updating deis From deis-controller.local:peachy-waxworks * [new branch] master -> deis/master Application Maintenance \u00b6 Maintenance mode for applications is useful to perform certain migrations or upgrades during which we don't want to serve client requests. Deis Workflow supports maintenance mode for an app during which the access to the app is blocked. Blocking access to the application means all the requests to the app are served with an error code of 503 and a static maintenance page by the router but the app will still be running and one-off commands can still be run. Currently the maintenance page is not configurable and is present as part of the router component. To enable maintenance mode for app, use deis maintenance : $ deis maintenance:on Enabling maintenance for drafty-zaniness... done This will make the router answer all requests to the application with a 503, although the app is still running. To disable maintenance mode: $ deis maintenance:off Disabling maintenance for drafty-zaniness... done Application Troubleshooting \u00b6 Applications deployed on Deis Workflow treat logs as event streams . Deis Workflow aggregates stdout and stderr from every Container making it easy to troubleshoot problems with your application. Use deis logs to view the log output from your deployed application. $ deis logs | tail Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.Server:jetty-7.6.0.v20120127 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10005 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10006 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10007 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10008","title":"Managing App Lifecycle"},{"location":"applications/managing-app-lifecycle/#managing-an-application","text":"","title":"Managing an Application"},{"location":"applications/managing-app-lifecycle/#track-application-changes","text":"Deis Workflow tracks all changes to your application. Application changes are the result of either new application code pushed to the platform (via git push deis master ), or an update to application configuration (via deis config:set KEY=VAL ). Each time a build or config change is made to your application a new release is created. These release numbers increase monotonically. You can see a record of changes to your application using deis releases : $ deis releases === peachy-waxworks Releases v4 3 minutes ago gabrtv deployed d3ccc05 v3 1 hour 17 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 2 minutes ago gabrtv deployed deis/helloworld","title":"Track Application Changes"},{"location":"applications/managing-app-lifecycle/#rollback-a-release","text":"Deis Workflow also supports rolling back go previous releases. If buggy code or an errant configuration change is pushed to your application, you may rollback to a previously known, good release. Note All rollbacks create a new, numbered release. But will reference the build/code and configuration from the desired rollback point. In this example, the application is currently running release v4. Using deis rollback v2 tells Workflow to deploy the build and configuration that was used for release v2. This creates a new release named v5 whose contents are the source and configuration from release v2: $ deis releases === folksy-offshoot Releases v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed deis/helloworld $ deis rollback v2 Rolled back to v2 $ deis releases === folksy-offshoot Releases v5 Just now gabrtv rolled back to v2 v4 4 minutes ago gabrtv deployed d3ccc05 v3 1 hour 18 minutes ago gabrtv added DATABASE_URL v2 6 hours 2 minutes ago gabrtv deployed 7cb3321 v1 6 hours 3 minutes ago gabrtv deployed deis/helloworld","title":"Rollback a Release"},{"location":"applications/managing-app-lifecycle/#run-one-off-administration-tasks","text":"Deis applications use one-off processes for admin tasks like database migrations and other commands that must run against the live application. Use deis run to execute commands on the deployed application. $ deis run 'ls -l' Running `ls -l`... total 28 -rw-r--r-- 1 root root 553 Dec 2 23:59 LICENSE -rw-r--r-- 1 root root 60 Dec 2 23:59 Procfile -rw-r--r-- 1 root root 33 Dec 2 23:59 README.md -rw-r--r-- 1 root root 1622 Dec 2 23:59 pom.xml drwxr-xr-x 3 root root 4096 Dec 2 23:59 src -rw-r--r-- 1 root root 25 Dec 2 23:59 system.properties drwxr-xr-x 6 root root 4096 Dec 3 00:00 target","title":"Run One-off Administration Tasks"},{"location":"applications/managing-app-lifecycle/#share-an-application","text":"Use deis perms:create to allow another Deis user to collaborate on your application. $ deis perms:create otheruser Adding otheruser to peachy-waxworks collaborators... done Use deis perms to see who an application is currently shared with, and deis perms:remove to remove a collaborator. Note Collaborators can do anything with an application that its owner can do, except delete the application. When working with an application that has been shared with you, clone the original repository and add Deis' git remote entry before attempting to git push any changes to Deis. $ git clone https://github.com/teamhephy/example-java-jetty.git Cloning into 'example-java-jetty'... done $ cd example-java-jetty $ git remote add -f deis ssh://git@local3.deisapp.com:2222/peachy-waxworks.git Updating deis From deis-controller.local:peachy-waxworks * [new branch] master -> deis/master","title":"Share an Application"},{"location":"applications/managing-app-lifecycle/#application-maintenance","text":"Maintenance mode for applications is useful to perform certain migrations or upgrades during which we don't want to serve client requests. Deis Workflow supports maintenance mode for an app during which the access to the app is blocked. Blocking access to the application means all the requests to the app are served with an error code of 503 and a static maintenance page by the router but the app will still be running and one-off commands can still be run. Currently the maintenance page is not configurable and is present as part of the router component. To enable maintenance mode for app, use deis maintenance : $ deis maintenance:on Enabling maintenance for drafty-zaniness... done This will make the router answer all requests to the application with a 503, although the app is still running. To disable maintenance mode: $ deis maintenance:off Disabling maintenance for drafty-zaniness... done","title":"Application Maintenance"},{"location":"applications/managing-app-lifecycle/#application-troubleshooting","text":"Applications deployed on Deis Workflow treat logs as event streams . Deis Workflow aggregates stdout and stderr from every Container making it easy to troubleshoot problems with your application. Use deis logs to view the log output from your deployed application. $ deis logs | tail Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.Server:jetty-7.6.0.v20120127 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.5]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10005 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.6]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10006 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler{/,null} Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.7]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10007 Dec 3 00:30:31 ip-10-250-15-201 peachy-waxworks[web.8]: INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:10008","title":"Application Troubleshooting"},{"location":"applications/managing-app-processes/","text":"Managing Application Processes \u00b6 Deis Workflow manages your application as a set of processes that can be named, scaled and configured according to their role. This gives you the flexibility to easily manage the different facets of your application. For example, you may have web-facing processes that handle HTTP traffic, background worker processes that do async work, and a helper process that streams from the Twitter API. By using a Procfile, either checked in to your application or provided via the CLI you can specify the name of the type and the application command that should run. To spawn other process types, use deis scale <type>=<n> to scale those types accordingly. Default Process Types \u00b6 In the absence of a Procfile, a single, default process type is assumed for each application. Applications built using Buildpacks via git push implicitly receive a web process type, which starts the application server. Rails 4, for example, has the following process type: web: bundle exec rails server -p $PORT All applications utilizing Dockerfiles have an implied cmd process type, which runs the Dockerfile's CMD directive unmodified: $ cat Dockerfile FROM centos:latest COPY . /app WORKDIR /app CMD python -m SimpleHTTPServer 5000 EXPOSE 5000 For the above Dockerfile-based application, the cmd process type would run the Docker CMD of python -m SimpleHTTPServer 5000 . Applications utilizing remote Docker images , a cmd process type is also implied, and runs the CMD specified in the Docker image. Note The web and cmd process types are special as they\u2019re the only process types that will receive HTTP traffic from Workflow\u2019s routers. Other process types can be named arbitrarily. Declaring Process Types \u00b6 If you use Buildpack or Dockerfile builds and want to override or specify additional process types, simply include a file named Procfile in the root of your application's source tree. The format of a Procfile is one process type per line, with each line containing the command to invoke: <process type>: <command> The syntax is defined as: <process type> \u2013 a lowercase alphanumeric string, is a name for your command, such as web, worker, urgentworker, clock, etc. <command> \u2013 a command line to launch the process, such as rake jobs:work . This example Procfile specifies two types, web and sleeper . The web process launches a web server on port 5000 and a simple process which sleeps for 900 seconds and exits. $ cat Procfile web: bundle exec ruby web.rb -p ${PORT:-5000} sleeper: sleep 900 If you are using remote Docker images , you may define process types by either running deis pull with a Procfile in your working directory, or by passing a stringified Procfile to the --procfile CLI option. For example, passing process types inline: $ deis pull deis/example-go:latest --procfile=\"cmd: /app/bin/boot\" Read a Procfile in another directory: $ deis pull deis/example-go:latest --procfile=\"$(cat deploy/Procfile)\" Or via a Procfile located in your current, working directory: $ cat Procfile cmd: /bin/boot sleeper: echo \"sleeping\"; sleep 900 $ deis pull -a steely-mainsail deis/example-go Creating build... done $ deis scale sleeper=1 -a steely-mainsail Scaling processes... but first, coffee! done in 0s === steely-mainsail Processes --- cmd: steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper: steely-mainsail-sleeper-3291896318-oq1jr up (v3) Note Only process types of web and cmd will be scaled to 1 automatically. If you have additional process types remember to scale the process counts after creation. To remove a process type simply scale it to 0: $ deis scale sleeper=0 -a steely-mainsail Scaling processes... but first, coffee! done in 3s === steely-mainsail Processes --- cmd: steely-mainsail-cmd-3291896318-nyrim up (v3) Scaling Processes \u00b6 Applications deployed on Deis Workflow scale out via the process model . Use deis scale to control the number of containers that power your app. $ deis scale cmd=5 -a iciest-waggoner Scaling processes... but first, coffee! done in 3s === iciest-waggoner Processes --- cmd: iciest-waggoner-web-3291896318-09j0o up (v2) iciest-waggoner-web-3291896318-3r7kp up (v2) iciest-waggoner-web-3291896318-gc4xv up (v2) iciest-waggoner-web-3291896318-lviwo up (v2) iciest-waggoner-web-3291896318-kt7vu up (v2) If you have multiple process types for your application you may scale the process count for each type separately. For example, this allows you to manage web process independently from background workers. For more information on process types see our documentation for Managing App Processes . In this example, we are scaling the process type web to 5 but leaving the process type background with one worker. $ deis scale web=5 Scaling processes... but first, coffee! done in 4s === scenic-icehouse Processes --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-jn957 up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vwhnh up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background: scenic-icehouse-web-3291896318-background-yf8kh up (v2) Note The default process type for Dockerfile and Docker Image applications is 'cmd' rather than 'web'. Scaling a process down, by reducing the process count, sends a TERM signal to the processes, followed by a SIGKILL if they have not exited within 30 seconds. Depending on your application, scaling down may interrupt long-running HTTP client connections. For example, scaling from 5 processes to 3: $ deis scale web=3 Scaling processes... but first, coffee! done in 1s === scenic-icehouse Processes --- background: scenic-icehouse-web-3291896318-background-yf8kh up (v2) --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) Autoscale \u00b6 Autoscale allows adding a minimum and maximum number of pods on a per process type basis. This is accomplished by specifying a target CPU usage across all available pods. This feature is built on top of Horizontal Pod Autoscaling in Kubernetes or HPA for short. Note This is an alpha feature. It is recommended to be on the latest Kubernetes when using this feature. $ deis autoscale:set web --min=3 --max=8 --cpu-percent=75 Applying autoscale settings for process type web on scenic-icehouse... done And then review the scaling rule that was created for web $ deis autoscale:list === scenic-icehouse Autoscale --- web: Min Replicas: 3 Max Replicas: 8 CPU: 75% Remove scaling rule $ deis autoscale:unset web Removing autoscale for process type web on scenic-icehouse... done For autoscaling to work CPU requests have to be specified on each application Pod (can be done via deis limits --cpu ). This allows the autoscale policies to do the appropriate calculations and make decisions on when to scale up and down. Scale up can only happen if there was no rescaling within the last 3 minutes. Scale down will wait for 5 minutes from the last rescaling. That information and more can be found at HPA algorithm page . Web vs Cmd Process Types \u00b6 When deploying to Deis Workflow using a Heroku Buildpack, Workflow boots the web process type to boot the application server. When you deploy an application that has a Dockerfile or uses Docker images , Workflow boots the cmd process type. Both act similarly in that they are exposed to the router as web applications. However, the cmd process type is special because, if left undefined, it is equivalent to running the container without any additional arguments. (i.e. The process specified by the Dockerfile or Docker image's CMD directive will be used.) If migrating an application from Heroku Buildpacks to a Docker-based deployment, Workflow will not automatically convert the web process type to cmd . To do this, you'll have to manually scale down the old process type and scale the new process type up. Restarting an Application Processes \u00b6 If you need to restart an application process, you may use deis ps:restart . Behind the scenes, Deis Workflow instructs Kubernetes to terminate the old process and launch a new one in its place. $ deis ps === scenic-icehouse Processes --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background: scenic-icehouse-background-3291896318-yf8kh up (v2) $ deis ps:restart scenic-icehouse-background-3291896318-yf8kh Restarting processes... but first, coffee! done in 6s === scenic-icehouse Processes --- background: scenic-icehouse-background-3291896318-yd87g up (v2) Notice that the process name has changed from scenic-icehouse-background-3291896318-yf8kh to scenic-icehouse-background-3291896318-yd87g . In a multi-node Kubernetes cluster, this may also have the effect of scheduling the Pod to a new node.","title":"Managing App Processes"},{"location":"applications/managing-app-processes/#managing-application-processes","text":"Deis Workflow manages your application as a set of processes that can be named, scaled and configured according to their role. This gives you the flexibility to easily manage the different facets of your application. For example, you may have web-facing processes that handle HTTP traffic, background worker processes that do async work, and a helper process that streams from the Twitter API. By using a Procfile, either checked in to your application or provided via the CLI you can specify the name of the type and the application command that should run. To spawn other process types, use deis scale <type>=<n> to scale those types accordingly.","title":"Managing Application Processes"},{"location":"applications/managing-app-processes/#default-process-types","text":"In the absence of a Procfile, a single, default process type is assumed for each application. Applications built using Buildpacks via git push implicitly receive a web process type, which starts the application server. Rails 4, for example, has the following process type: web: bundle exec rails server -p $PORT All applications utilizing Dockerfiles have an implied cmd process type, which runs the Dockerfile's CMD directive unmodified: $ cat Dockerfile FROM centos:latest COPY . /app WORKDIR /app CMD python -m SimpleHTTPServer 5000 EXPOSE 5000 For the above Dockerfile-based application, the cmd process type would run the Docker CMD of python -m SimpleHTTPServer 5000 . Applications utilizing remote Docker images , a cmd process type is also implied, and runs the CMD specified in the Docker image. Note The web and cmd process types are special as they\u2019re the only process types that will receive HTTP traffic from Workflow\u2019s routers. Other process types can be named arbitrarily.","title":"Default Process Types"},{"location":"applications/managing-app-processes/#declaring-process-types","text":"If you use Buildpack or Dockerfile builds and want to override or specify additional process types, simply include a file named Procfile in the root of your application's source tree. The format of a Procfile is one process type per line, with each line containing the command to invoke: <process type>: <command> The syntax is defined as: <process type> \u2013 a lowercase alphanumeric string, is a name for your command, such as web, worker, urgentworker, clock, etc. <command> \u2013 a command line to launch the process, such as rake jobs:work . This example Procfile specifies two types, web and sleeper . The web process launches a web server on port 5000 and a simple process which sleeps for 900 seconds and exits. $ cat Procfile web: bundle exec ruby web.rb -p ${PORT:-5000} sleeper: sleep 900 If you are using remote Docker images , you may define process types by either running deis pull with a Procfile in your working directory, or by passing a stringified Procfile to the --procfile CLI option. For example, passing process types inline: $ deis pull deis/example-go:latest --procfile=\"cmd: /app/bin/boot\" Read a Procfile in another directory: $ deis pull deis/example-go:latest --procfile=\"$(cat deploy/Procfile)\" Or via a Procfile located in your current, working directory: $ cat Procfile cmd: /bin/boot sleeper: echo \"sleeping\"; sleep 900 $ deis pull -a steely-mainsail deis/example-go Creating build... done $ deis scale sleeper=1 -a steely-mainsail Scaling processes... but first, coffee! done in 0s === steely-mainsail Processes --- cmd: steely-mainsail-cmd-3291896318-nyrim up (v3) --- sleeper: steely-mainsail-sleeper-3291896318-oq1jr up (v3) Note Only process types of web and cmd will be scaled to 1 automatically. If you have additional process types remember to scale the process counts after creation. To remove a process type simply scale it to 0: $ deis scale sleeper=0 -a steely-mainsail Scaling processes... but first, coffee! done in 3s === steely-mainsail Processes --- cmd: steely-mainsail-cmd-3291896318-nyrim up (v3)","title":"Declaring Process Types"},{"location":"applications/managing-app-processes/#scaling-processes","text":"Applications deployed on Deis Workflow scale out via the process model . Use deis scale to control the number of containers that power your app. $ deis scale cmd=5 -a iciest-waggoner Scaling processes... but first, coffee! done in 3s === iciest-waggoner Processes --- cmd: iciest-waggoner-web-3291896318-09j0o up (v2) iciest-waggoner-web-3291896318-3r7kp up (v2) iciest-waggoner-web-3291896318-gc4xv up (v2) iciest-waggoner-web-3291896318-lviwo up (v2) iciest-waggoner-web-3291896318-kt7vu up (v2) If you have multiple process types for your application you may scale the process count for each type separately. For example, this allows you to manage web process independently from background workers. For more information on process types see our documentation for Managing App Processes . In this example, we are scaling the process type web to 5 but leaving the process type background with one worker. $ deis scale web=5 Scaling processes... but first, coffee! done in 4s === scenic-icehouse Processes --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-jn957 up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vwhnh up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background: scenic-icehouse-web-3291896318-background-yf8kh up (v2) Note The default process type for Dockerfile and Docker Image applications is 'cmd' rather than 'web'. Scaling a process down, by reducing the process count, sends a TERM signal to the processes, followed by a SIGKILL if they have not exited within 30 seconds. Depending on your application, scaling down may interrupt long-running HTTP client connections. For example, scaling from 5 processes to 3: $ deis scale web=3 Scaling processes... but first, coffee! done in 1s === scenic-icehouse Processes --- background: scenic-icehouse-web-3291896318-background-yf8kh up (v2) --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2)","title":"Scaling Processes"},{"location":"applications/managing-app-processes/#autoscale","text":"Autoscale allows adding a minimum and maximum number of pods on a per process type basis. This is accomplished by specifying a target CPU usage across all available pods. This feature is built on top of Horizontal Pod Autoscaling in Kubernetes or HPA for short. Note This is an alpha feature. It is recommended to be on the latest Kubernetes when using this feature. $ deis autoscale:set web --min=3 --max=8 --cpu-percent=75 Applying autoscale settings for process type web on scenic-icehouse... done And then review the scaling rule that was created for web $ deis autoscale:list === scenic-icehouse Autoscale --- web: Min Replicas: 3 Max Replicas: 8 CPU: 75% Remove scaling rule $ deis autoscale:unset web Removing autoscale for process type web on scenic-icehouse... done For autoscaling to work CPU requests have to be specified on each application Pod (can be done via deis limits --cpu ). This allows the autoscale policies to do the appropriate calculations and make decisions on when to scale up and down. Scale up can only happen if there was no rescaling within the last 3 minutes. Scale down will wait for 5 minutes from the last rescaling. That information and more can be found at HPA algorithm page .","title":"Autoscale"},{"location":"applications/managing-app-processes/#web-vs-cmd-process-types","text":"When deploying to Deis Workflow using a Heroku Buildpack, Workflow boots the web process type to boot the application server. When you deploy an application that has a Dockerfile or uses Docker images , Workflow boots the cmd process type. Both act similarly in that they are exposed to the router as web applications. However, the cmd process type is special because, if left undefined, it is equivalent to running the container without any additional arguments. (i.e. The process specified by the Dockerfile or Docker image's CMD directive will be used.) If migrating an application from Heroku Buildpacks to a Docker-based deployment, Workflow will not automatically convert the web process type to cmd . To do this, you'll have to manually scale down the old process type and scale the new process type up.","title":"Web vs Cmd Process Types"},{"location":"applications/managing-app-processes/#restarting-an-application-processes","text":"If you need to restart an application process, you may use deis ps:restart . Behind the scenes, Deis Workflow instructs Kubernetes to terminate the old process and launch a new one in its place. $ deis ps === scenic-icehouse Processes --- web: scenic-icehouse-web-3291896318-7lord up (v2) scenic-icehouse-web-3291896318-rsekj up (v2) scenic-icehouse-web-3291896318-vokg7 up (v2) --- background: scenic-icehouse-background-3291896318-yf8kh up (v2) $ deis ps:restart scenic-icehouse-background-3291896318-yf8kh Restarting processes... but first, coffee! done in 6s === scenic-icehouse Processes --- background: scenic-icehouse-background-3291896318-yd87g up (v2) Notice that the process name has changed from scenic-icehouse-background-3291896318-yf8kh to scenic-icehouse-background-3291896318-yd87g . In a multi-node Kubernetes cluster, this may also have the effect of scheduling the Pod to a new node.","title":"Restarting an Application Processes"},{"location":"applications/managing-resource-limits/","text":"Managing Application Resource Limits \u00b6 Deis Workflow supports restricting memory and CPU shares of each process. Requests/Limits set on a per-process type are given to Kubernetes as a requests and limits. Which means you guarantee <requests> amount of resource for a process as well as limit the process from using more than <limits>. By default, Kubernetes will set <requests> equal to <limit> if we don't explicitly set <requests> value. Please keep in mind that 0 <= requests <= limits . Limiting Memory \u00b6 If you set a requests/limits that is out of range for your cluster, Kubernetes will be unable to schedule your application processes into the cluster! Available units for memory are: Unit Amount B Bytes K KiB (Power of 2) M MiB (Power of 2) G GiB (Power of 2) Important The minimum memory limit allowed is 4MiB. Use deis limits:set <type>=<value> to restrict memory by process type, where value can be <limit> or <request>/<limit> format : $ deis limits:set web=64M Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU Unlimited $ deis limits:set cmd=32M/64M Applying limits... done === outdoor-whitecap Limits --- Memory cmd 32M/64M --- CPU Unlimited If you would like to remove any configured memory limits use deis limits:unset web : $ deis limits:unset web Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited Limiting CPU \u00b6 You can also use deis limits:set <type>=<value> --cpu to restrict CPU shares, where value can be <limit> or <request>/<limit> format. CPU shares are tracked in milli-cores. One CPU core is equivalent to 1000 milli-cores. To dedicate half a core to your process, you would need 500 milli-cores or 500m. Unit Amount 1000m 1000 milli-cores == 100% CPU core 500m 500 milli-cores == 50% CPU core 250m 250 milli-cores == 25% CPU core 100m 100 milli-cores == 10% CPU core $ deis limits:set web=250m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 250m $ deis limits:set web=1500m/2000m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 1500m/2000m You can verify the CPU and memory limits by inspecting the application process Pod with kubectl : $ deis ps === indoor-whitecap Processes --- web: indoor-whitecap-v14-web-8slcj up (v14) $ kubectl --namespace=indoor-whitecap describe po indoor-whitecap-v14-web-8slcj Name: indoor-whitecap-v14-web-8slcj Containers: QoS Tier: cpu: Guaranteed memory: Guaranteed Limits: cpu: 2000m memory: 64Mi Requests: memory: 64Mi cpu: 1500m Important If you restrict resources to the point where containers do not start, the limits:set command will hang. If this happens, use CTRL-C to break out of limits:set and use limits:unset to revert. To unset a CPU limit use deis limits:unset web --cpu : $ deis limits:unset web --cpu Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Resource Limits"},{"location":"applications/managing-resource-limits/#managing-application-resource-limits","text":"Deis Workflow supports restricting memory and CPU shares of each process. Requests/Limits set on a per-process type are given to Kubernetes as a requests and limits. Which means you guarantee <requests> amount of resource for a process as well as limit the process from using more than <limits>. By default, Kubernetes will set <requests> equal to <limit> if we don't explicitly set <requests> value. Please keep in mind that 0 <= requests <= limits .","title":"Managing Application Resource Limits"},{"location":"applications/managing-resource-limits/#limiting-memory","text":"If you set a requests/limits that is out of range for your cluster, Kubernetes will be unable to schedule your application processes into the cluster! Available units for memory are: Unit Amount B Bytes K KiB (Power of 2) M MiB (Power of 2) G GiB (Power of 2) Important The minimum memory limit allowed is 4MiB. Use deis limits:set <type>=<value> to restrict memory by process type, where value can be <limit> or <request>/<limit> format : $ deis limits:set web=64M Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU Unlimited $ deis limits:set cmd=32M/64M Applying limits... done === outdoor-whitecap Limits --- Memory cmd 32M/64M --- CPU Unlimited If you would like to remove any configured memory limits use deis limits:unset web : $ deis limits:unset web Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Limiting Memory"},{"location":"applications/managing-resource-limits/#limiting-cpu","text":"You can also use deis limits:set <type>=<value> --cpu to restrict CPU shares, where value can be <limit> or <request>/<limit> format. CPU shares are tracked in milli-cores. One CPU core is equivalent to 1000 milli-cores. To dedicate half a core to your process, you would need 500 milli-cores or 500m. Unit Amount 1000m 1000 milli-cores == 100% CPU core 500m 500 milli-cores == 50% CPU core 250m 250 milli-cores == 25% CPU core 100m 100 milli-cores == 10% CPU core $ deis limits:set web=250m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 250m $ deis limits:set web=1500m/2000m --cpu Applying limits... done === indoor-whitecap Limits --- Memory web 64M --- CPU web 1500m/2000m You can verify the CPU and memory limits by inspecting the application process Pod with kubectl : $ deis ps === indoor-whitecap Processes --- web: indoor-whitecap-v14-web-8slcj up (v14) $ kubectl --namespace=indoor-whitecap describe po indoor-whitecap-v14-web-8slcj Name: indoor-whitecap-v14-web-8slcj Containers: QoS Tier: cpu: Guaranteed memory: Guaranteed Limits: cpu: 2000m memory: 64Mi Requests: memory: 64Mi cpu: 1500m Important If you restrict resources to the point where containers do not start, the limits:set command will hang. If this happens, use CTRL-C to break out of limits:set and use limits:unset to revert. To unset a CPU limit use deis limits:unset web --cpu : $ deis limits:unset web --cpu Applying limits... done === indoor-whitecap Limits --- Memory Unlimited --- CPU Unlimited","title":"Limiting CPU"},{"location":"applications/ssl-certificates/","text":"Application SSL Certificates \u00b6 SSL is a cryptographic protocol that provides end-to-end encryption and integrity for all web requests. Apps that transmit sensitive data should enable SSL to ensure all information is transmitted securely. To enable SSL on a custom domain, e.g., www.example.com , use the SSL endpoint. Note deis certs is only useful for custom domains. Default application domains are SSL-enabled already and can be accessed simply by using https, e.g. https://foo.deisapp.com (provided that you have installed your wildcard certificate on the routers or on the load balancer). Overview \u00b6 Because of the unique nature of SSL validation, provisioning SSL for your domain is a multi-step process that involves several third-parties. You will need to: Purchase an SSL certificate from your SSL provider Upload the cert to Deis Acquire SSL Certificate \u00b6 Purchasing an SSL cert varies in cost and process depending on the vendor. RapidSSL offers a simple way to purchase a certificate and is a recommended solution. If you\u2019re able to use this provider, see buy an SSL certificate with RapidSSL for instructions. DNS and Domain Configuration \u00b6 Once the SSL certificate is provisioned and your cert is confirmed, you must route requests for your domain through Deis. Unless you've already done so, add the domain specified when generating the CSR to your app with: $ deis domains:add www.example.com -a foo Adding www.example.com to foo... done Add a Certificate \u00b6 Add your certificate, any intermediate certificates, and private key to the endpoint with the certs:add command. $ deis certs:add example-com server.crt server.key Adding SSL endpoint... done www.example.com Note The name given to the certificate can only contain a-z (lowercase), 0-9 and hyphens The Deis platform will investigate the certificate and extract any relevant information from it such as the Common Name, Subject Alt Names (SAN), fingerprint and more. This allows for wildcard certificates and multiple domains in the SAN without uploading duplicates. Add a Certificate Chain \u00b6 Sometimes, your certificates (such as a self-signed or a cheap certificate) need additional certificates to establish the chain of trust. What you need to do is bundle all the certificates into one file and give that to Deis. Importantly, your site\u2019s certificate must be the first one: $ cat server.crt server.ca > server.bundle After that, you can add them to Deis with the certs:add command: $ deis certs:add example-com server.bundle server.key Adding SSL endpoint... done www.example.com Attach SSL certificate to a domain \u00b6 Certificates are not automagically connected up to domains, instead you will have to attach a certificate to a domain $ deis certs:attach example-com example.com Each certificate can be connected to many domains. There is no need to upload duplicates. To remove an association $ deis certs:detach example-com example.com Endpoint overview \u00b6 You can verify the details of your domain's SSL configuration with deis certs . $ deis certs Name | Common Name | SubjectAltName | Expires | Fingerprint | Domains | Updated | Created +-------------+-------------------+-------------------+-------------------------+-----------------+--------------+-------------+-------------+ example-com | example.com | blog.example.com | 31 Dec 2017 (in 1 year) | 8F:8E[...]CD:EB | example.com | 30 Jan 2016 | 29 Jan 2016 or by looking at at each certificates detailed information $ deis certs:info example-com === bar-com Certificate Common Name(s): example.com Expires At: 2017-01-14 23:57:57 +0000 UTC Starts At: 2016-01-15 23:57:57 +0000 UTC Fingerprint: 7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0 Subject Alt Name: blog.example.com Issuer: /C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=example.com/emailAddress=engineering@deis.com Subject: /C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=example.com/emailAddress=engineering@deis.com Connected Domains: example.com Owner: admin-user Created: 2016-01-28 19:07:41 +0000 UTC Updated: 2016-01-30 00:10:02 +0000 UTC Testing SSL \u00b6 Use a command line utility like curl to test that everything is configured correctly for your secure domain. Note The -k option flag tells curl to ignore untrusted certificates. Pay attention to the output. It should print SSL certificate verify ok . If it prints something like common name: www.example.com (does not match 'www.somedomain.com') then something is not configured correctly. Enforcing SSL at the Router \u00b6 To enforce all HTTP requests be redirected to HTTPS, TLS can be enforced at the router level by running $ deis tls:enable -a foo Enabling https-only requests for foo... done Users hitting the HTTP endpoint for the application will now receive a 301 redirect to the HTTPS endpoint. To disable enforced TLS, run $ deis tls:disable -a foo Disabling https-only requests for foo... done Remove Certificate \u00b6 You can remove a certificate using the certs:remove command: $ deis certs:remove my-cert Removing www.example.com... Done. Swapping out certificates \u00b6 Over the lifetime of an application an operator will have to acquire certificates with new expire dates and apply it to all relevant applications, below is the recommended way to swap out certificates. Be intentional with certificate names, name them example-com-2017 when possible, where the year signifies the expiry year. This allows for example-com-2018 when a new certificate is purchased. Assuming all applications are already using example-com-2017 the following commands can be ran, chained together or otherwise: $ deis certs:detach example-com-2017 example.com $ deis certs:attach example-com-2018 example.com This will take care of a singular domain which allows the operator to verify everything went as planned and slowly roll it out to any other application using the same method. Troubleshooting \u00b6 Here are some steps you can follow if your SSL endpoint is not working as you'd expect. Untrusted Certificate \u00b6 In some cases when accessing the SSL endpoint, it may list your certificate as untrusted. If this occurs, it may be because it is not trusted by Mozilla\u2019s list of root CAs . If this is the case, your certificate may be considered untrusted for many browsers. If you have uploaded a certificate that was signed by a root authority but you get the message that it is not trusted, then something is wrong with the certificate. For example, it may be missing intermediary certificates . If so, download the intermediary certificates from your SSL provider, remove the certificate from Deis and re-run the certs:add command.","title":"SSL Certificates"},{"location":"applications/ssl-certificates/#application-ssl-certificates","text":"SSL is a cryptographic protocol that provides end-to-end encryption and integrity for all web requests. Apps that transmit sensitive data should enable SSL to ensure all information is transmitted securely. To enable SSL on a custom domain, e.g., www.example.com , use the SSL endpoint. Note deis certs is only useful for custom domains. Default application domains are SSL-enabled already and can be accessed simply by using https, e.g. https://foo.deisapp.com (provided that you have installed your wildcard certificate on the routers or on the load balancer).","title":"Application SSL Certificates"},{"location":"applications/ssl-certificates/#overview","text":"Because of the unique nature of SSL validation, provisioning SSL for your domain is a multi-step process that involves several third-parties. You will need to: Purchase an SSL certificate from your SSL provider Upload the cert to Deis","title":"Overview"},{"location":"applications/ssl-certificates/#acquire-ssl-certificate","text":"Purchasing an SSL cert varies in cost and process depending on the vendor. RapidSSL offers a simple way to purchase a certificate and is a recommended solution. If you\u2019re able to use this provider, see buy an SSL certificate with RapidSSL for instructions.","title":"Acquire SSL Certificate"},{"location":"applications/ssl-certificates/#dns-and-domain-configuration","text":"Once the SSL certificate is provisioned and your cert is confirmed, you must route requests for your domain through Deis. Unless you've already done so, add the domain specified when generating the CSR to your app with: $ deis domains:add www.example.com -a foo Adding www.example.com to foo... done","title":"DNS and Domain Configuration"},{"location":"applications/ssl-certificates/#add-a-certificate","text":"Add your certificate, any intermediate certificates, and private key to the endpoint with the certs:add command. $ deis certs:add example-com server.crt server.key Adding SSL endpoint... done www.example.com Note The name given to the certificate can only contain a-z (lowercase), 0-9 and hyphens The Deis platform will investigate the certificate and extract any relevant information from it such as the Common Name, Subject Alt Names (SAN), fingerprint and more. This allows for wildcard certificates and multiple domains in the SAN without uploading duplicates.","title":"Add a Certificate"},{"location":"applications/ssl-certificates/#add-a-certificate-chain","text":"Sometimes, your certificates (such as a self-signed or a cheap certificate) need additional certificates to establish the chain of trust. What you need to do is bundle all the certificates into one file and give that to Deis. Importantly, your site\u2019s certificate must be the first one: $ cat server.crt server.ca > server.bundle After that, you can add them to Deis with the certs:add command: $ deis certs:add example-com server.bundle server.key Adding SSL endpoint... done www.example.com","title":"Add a Certificate Chain"},{"location":"applications/ssl-certificates/#attach-ssl-certificate-to-a-domain","text":"Certificates are not automagically connected up to domains, instead you will have to attach a certificate to a domain $ deis certs:attach example-com example.com Each certificate can be connected to many domains. There is no need to upload duplicates. To remove an association $ deis certs:detach example-com example.com","title":"Attach SSL certificate to a domain"},{"location":"applications/ssl-certificates/#endpoint-overview","text":"You can verify the details of your domain's SSL configuration with deis certs . $ deis certs Name | Common Name | SubjectAltName | Expires | Fingerprint | Domains | Updated | Created +-------------+-------------------+-------------------+-------------------------+-----------------+--------------+-------------+-------------+ example-com | example.com | blog.example.com | 31 Dec 2017 (in 1 year) | 8F:8E[...]CD:EB | example.com | 30 Jan 2016 | 29 Jan 2016 or by looking at at each certificates detailed information $ deis certs:info example-com === bar-com Certificate Common Name(s): example.com Expires At: 2017-01-14 23:57:57 +0000 UTC Starts At: 2016-01-15 23:57:57 +0000 UTC Fingerprint: 7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0 Subject Alt Name: blog.example.com Issuer: /C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=example.com/emailAddress=engineering@deis.com Subject: /C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=example.com/emailAddress=engineering@deis.com Connected Domains: example.com Owner: admin-user Created: 2016-01-28 19:07:41 +0000 UTC Updated: 2016-01-30 00:10:02 +0000 UTC","title":"Endpoint overview"},{"location":"applications/ssl-certificates/#testing-ssl","text":"Use a command line utility like curl to test that everything is configured correctly for your secure domain. Note The -k option flag tells curl to ignore untrusted certificates. Pay attention to the output. It should print SSL certificate verify ok . If it prints something like common name: www.example.com (does not match 'www.somedomain.com') then something is not configured correctly.","title":"Testing SSL"},{"location":"applications/ssl-certificates/#enforcing-ssl-at-the-router","text":"To enforce all HTTP requests be redirected to HTTPS, TLS can be enforced at the router level by running $ deis tls:enable -a foo Enabling https-only requests for foo... done Users hitting the HTTP endpoint for the application will now receive a 301 redirect to the HTTPS endpoint. To disable enforced TLS, run $ deis tls:disable -a foo Disabling https-only requests for foo... done","title":"Enforcing SSL at the Router"},{"location":"applications/ssl-certificates/#remove-certificate","text":"You can remove a certificate using the certs:remove command: $ deis certs:remove my-cert Removing www.example.com... Done.","title":"Remove Certificate"},{"location":"applications/ssl-certificates/#swapping-out-certificates","text":"Over the lifetime of an application an operator will have to acquire certificates with new expire dates and apply it to all relevant applications, below is the recommended way to swap out certificates. Be intentional with certificate names, name them example-com-2017 when possible, where the year signifies the expiry year. This allows for example-com-2018 when a new certificate is purchased. Assuming all applications are already using example-com-2017 the following commands can be ran, chained together or otherwise: $ deis certs:detach example-com-2017 example.com $ deis certs:attach example-com-2018 example.com This will take care of a singular domain which allows the operator to verify everything went as planned and slowly roll it out to any other application using the same method.","title":"Swapping out certificates"},{"location":"applications/ssl-certificates/#troubleshooting","text":"Here are some steps you can follow if your SSL endpoint is not working as you'd expect.","title":"Troubleshooting"},{"location":"applications/ssl-certificates/#untrusted-certificate","text":"In some cases when accessing the SSL endpoint, it may list your certificate as untrusted. If this occurs, it may be because it is not trusted by Mozilla\u2019s list of root CAs . If this is the case, your certificate may be considered untrusted for many browsers. If you have uploaded a certificate that was signed by a root authority but you get the message that it is not trusted, then something is wrong with the certificate. For example, it may be missing intermediary certificates . If so, download the intermediary certificates from your SSL provider, remove the certificate from Deis and re-run the certs:add command.","title":"Untrusted Certificate"},{"location":"applications/using-buildpacks/","text":"Using Buildpacks \u00b6 Deis supports deploying applications via Heroku Buildpacks . Buildpacks are useful if you're interested in following Heroku's best practices for building applications or if you are deploying an application that already runs on Heroku. Add SSH Key \u00b6 For Buildpack based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run deis keys:add to upload your SSH key to Deis Workflow. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done Read more about adding/removing SSH Keys here . Prepare an Application \u00b6 If you do not have an existing application, you can clone an example application that demonstrates the Heroku Buildpack workflow. $ git clone https://github.com/teamhephy/example-go.git $ cd example-go Create an Application \u00b6 Use deis create to create an application on the Controller . $ deis create Creating application... done, created skiing-keypunch Git remote deis added Push to Deploy \u00b6 Use git push deis master to deploy your application. $ git push deis master Counting objects: 75, done. Delta compression using up to 8 threads. Compressing objects: 100% (48/48), done. Writing objects: 100% (75/75), 18.28 KiB | 0 bytes/s, done. Total 75 (delta 30), reused 58 (delta 22) Starting build... but first, coffee! -----> Go app detected -----> Checking Godeps/Godeps.json file. -----> Installing go1.4.2... done -----> Running: godep go install -tags heroku ./... -----> Discovering process types Procfile declares types -> web -----> Compiled slug size is 1.7M Build complete. Launching app. Launching... Done, skiing-keypunch:v2 deployed to Deis Use 'deis open' to view this application in your browser To learn more, use 'deis help' or visit http://deis.io To ssh://git@deis.staging-2.deis.com:2222/skiing-keypunch.git * [new branch] master -> master $ curl -s http://skiing-keypunch.example.com Powered by Deis Release v2 on skiing-keypunch-v2-web-02zb9 Because a Heroku-style application is detected, the web process type is automatically scaled to 1 on first deploy. Use deis scale web=3 to increase web processes to 3, for example. Scaling a process type directly changes the number of pods running that process. Included Buildpacks \u00b6 For convenience, a number of buildpacks come bundled with Deis: Ruby Buildpack Nodejs Buildpack Java Buildpack Gradle Buildpack Grails Buildpack Play Buildpack Python Buildpack PHP Buildpack Clojure Buildpack Scala Buildpack Go Buildpack Multi Buildpack Deis will cycle through the bin/detect script of each buildpack to match the code you are pushing. Note If you're testing against the Scala Buildpack , the Builder requires at least 512MB of free memory to execute the Scala Build Tool. Using a Custom Buildpack \u00b6 To use a custom buildpack, set the BUILDPACK_URL environment variable. $ deis config:set BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal Creating config... done, v2 === humble-autoharp BUILDPACK_URL: https://github.com/dpiddy/heroku-buildpack-ruby-minimal Note If, however, you're unable to deploy using the latest version of the buildpack, You can set an exact version of a buildpack by using a git revision in your BUILDPACK_URL . For example: BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal#v13 On your next git push , the custom buildpack will be used. Compile Hooks \u00b6 Sometimes, an application needs a way to stop or check if a service is running before building an app, which may require notifying a service that the Builder has finished compiling the app. In order to do this, an app can provide two files in their bin/ directory: bin/pre-compile bin/post-compile The builder will run these commands before and after the build process, respectively. Using Private Repositories \u00b6 To pull code from private repositories, set the SSH_KEY environment variable to a private key which has access. Use either the path of a private key file or the raw key material: $ deis config:set SSH_KEY=/home/user/.ssh/id_rsa $ deis config:set SSH_KEY=\"\"\"-----BEGIN RSA PRIVATE KEY----- (...) -----END RSA PRIVATE KEY-----\"\"\" For example, to use a custom buildpack hosted at a private GitHub URL, ensure that an SSH public key exists in your GitHub settings . Then set SSH_KEY to the corresponding SSH private key and set BUILDPACK_URL to the URL: $ deis config:set SSH_KEY=/home/user/.ssh/github_id_rsa $ deis config:set BUILDPACK_URL=git@github.com:user/private_buildpack.git $ git push deis master","title":"Buildpacks"},{"location":"applications/using-buildpacks/#using-buildpacks","text":"Deis supports deploying applications via Heroku Buildpacks . Buildpacks are useful if you're interested in following Heroku's best practices for building applications or if you are deploying an application that already runs on Heroku.","title":"Using Buildpacks"},{"location":"applications/using-buildpacks/#add-ssh-key","text":"For Buildpack based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run deis keys:add to upload your SSH key to Deis Workflow. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done Read more about adding/removing SSH Keys here .","title":"Add SSH Key"},{"location":"applications/using-buildpacks/#prepare-an-application","text":"If you do not have an existing application, you can clone an example application that demonstrates the Heroku Buildpack workflow. $ git clone https://github.com/teamhephy/example-go.git $ cd example-go","title":"Prepare an Application"},{"location":"applications/using-buildpacks/#create-an-application","text":"Use deis create to create an application on the Controller . $ deis create Creating application... done, created skiing-keypunch Git remote deis added","title":"Create an Application"},{"location":"applications/using-buildpacks/#push-to-deploy","text":"Use git push deis master to deploy your application. $ git push deis master Counting objects: 75, done. Delta compression using up to 8 threads. Compressing objects: 100% (48/48), done. Writing objects: 100% (75/75), 18.28 KiB | 0 bytes/s, done. Total 75 (delta 30), reused 58 (delta 22) Starting build... but first, coffee! -----> Go app detected -----> Checking Godeps/Godeps.json file. -----> Installing go1.4.2... done -----> Running: godep go install -tags heroku ./... -----> Discovering process types Procfile declares types -> web -----> Compiled slug size is 1.7M Build complete. Launching app. Launching... Done, skiing-keypunch:v2 deployed to Deis Use 'deis open' to view this application in your browser To learn more, use 'deis help' or visit http://deis.io To ssh://git@deis.staging-2.deis.com:2222/skiing-keypunch.git * [new branch] master -> master $ curl -s http://skiing-keypunch.example.com Powered by Deis Release v2 on skiing-keypunch-v2-web-02zb9 Because a Heroku-style application is detected, the web process type is automatically scaled to 1 on first deploy. Use deis scale web=3 to increase web processes to 3, for example. Scaling a process type directly changes the number of pods running that process.","title":"Push to Deploy"},{"location":"applications/using-buildpacks/#included-buildpacks","text":"For convenience, a number of buildpacks come bundled with Deis: Ruby Buildpack Nodejs Buildpack Java Buildpack Gradle Buildpack Grails Buildpack Play Buildpack Python Buildpack PHP Buildpack Clojure Buildpack Scala Buildpack Go Buildpack Multi Buildpack Deis will cycle through the bin/detect script of each buildpack to match the code you are pushing. Note If you're testing against the Scala Buildpack , the Builder requires at least 512MB of free memory to execute the Scala Build Tool.","title":"Included Buildpacks"},{"location":"applications/using-buildpacks/#using-a-custom-buildpack","text":"To use a custom buildpack, set the BUILDPACK_URL environment variable. $ deis config:set BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal Creating config... done, v2 === humble-autoharp BUILDPACK_URL: https://github.com/dpiddy/heroku-buildpack-ruby-minimal Note If, however, you're unable to deploy using the latest version of the buildpack, You can set an exact version of a buildpack by using a git revision in your BUILDPACK_URL . For example: BUILDPACK_URL=https://github.com/dpiddy/heroku-buildpack-ruby-minimal#v13 On your next git push , the custom buildpack will be used.","title":"Using a Custom Buildpack"},{"location":"applications/using-buildpacks/#compile-hooks","text":"Sometimes, an application needs a way to stop or check if a service is running before building an app, which may require notifying a service that the Builder has finished compiling the app. In order to do this, an app can provide two files in their bin/ directory: bin/pre-compile bin/post-compile The builder will run these commands before and after the build process, respectively.","title":"Compile Hooks"},{"location":"applications/using-buildpacks/#using-private-repositories","text":"To pull code from private repositories, set the SSH_KEY environment variable to a private key which has access. Use either the path of a private key file or the raw key material: $ deis config:set SSH_KEY=/home/user/.ssh/id_rsa $ deis config:set SSH_KEY=\"\"\"-----BEGIN RSA PRIVATE KEY----- (...) -----END RSA PRIVATE KEY-----\"\"\" For example, to use a custom buildpack hosted at a private GitHub URL, ensure that an SSH public key exists in your GitHub settings . Then set SSH_KEY to the corresponding SSH private key and set BUILDPACK_URL to the URL: $ deis config:set SSH_KEY=/home/user/.ssh/github_id_rsa $ deis config:set BUILDPACK_URL=git@github.com:user/private_buildpack.git $ git push deis master","title":"Using Private Repositories"},{"location":"applications/using-docker-images/","text":"Using Docker Images \u00b6 Deis supports deploying applications via an existing Docker Image . This is useful for integrating Deis into Docker-based CI/CD pipelines. Prepare an Application \u00b6 Start by cloning an example application: $ git clone https://github.com/teamhephy/example-dockerfile-http.git $ cd example-dockerfile-http Next use your local docker client to build the image and push it to DockerHub . $ docker build -t <username>/example-dockerfile-http . $ docker push <username>/example-dockerfile-http Docker Image Requirements \u00b6 In order to deploy Docker images, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: deis config:set PORT=5000 . See Configuring Registry for more info. Create an Application \u00b6 Use deis create to create an application on the controller . $ mkdir -p /tmp/example-dockerfile-http && cd /tmp/example-dockerfile-http $ deis create example-dockerfile-http --no-remote Creating application... done, created example-dockerfile-http Note For all commands except for deis create , the deis client uses the name of the current directory as the app name if you don't specify it explicitly with --app . Deploy the Application \u00b6 Use deis pull to deploy your application from DockerHub or a public registry. $ deis pull <username>/example-dockerfile-http:latest Creating build... done, v2 $ curl -s http://example-dockerfile-http.local3.deisapp.com Powered by Deis Because you are deploying a Docker image, the cmd process type is automatically scaled to 1 on first deploy. Use deis scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of Containers running that process. Private Registry \u00b6 To deploy Docker images from a private registry or from a private repository, use deis registry to attach credentials to your application. These credentials are the same as you'd use when running docker login at your private registry. To deploy private Docker images, take the following steps: Gather the username and password for the registry, such as a Quay.io Robot Account or a GCR.io Long Lived Token Run deis registry:set username=<the-user> password=<secret> -a <application-name> Now perform deis pull as normal, against an image in the private registry When using a GCR.io Long Lived Token , the JSON blob will have to be compacted first using a tool like jq and then used in the password field in deis registry:set . For the username, use _json_key . For example: deis registry:set username=_json_key password=\"$(cat google_cloud_cred.json | jq -c .)\" When using a private registry the docker images are no longer pulled into the Deis Internal Registry via the Deis Workflow Controller but rather is managed by Kubernetes. This will increase security and overall speed, however the application port information can no longer be discovered. Instead the application port information can be set via deis config:set PORT=80 prior to setting the registry information. Note Currently GCR.io and ECR in short lived auth token mode are not supported.","title":"Docker Images"},{"location":"applications/using-docker-images/#using-docker-images","text":"Deis supports deploying applications via an existing Docker Image . This is useful for integrating Deis into Docker-based CI/CD pipelines.","title":"Using Docker Images"},{"location":"applications/using-docker-images/#prepare-an-application","text":"Start by cloning an example application: $ git clone https://github.com/teamhephy/example-dockerfile-http.git $ cd example-dockerfile-http Next use your local docker client to build the image and push it to DockerHub . $ docker build -t <username>/example-dockerfile-http . $ docker push <username>/example-dockerfile-http","title":"Prepare an Application"},{"location":"applications/using-docker-images/#docker-image-requirements","text":"In order to deploy Docker images, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: deis config:set PORT=5000 . See Configuring Registry for more info.","title":"Docker Image Requirements"},{"location":"applications/using-docker-images/#create-an-application","text":"Use deis create to create an application on the controller . $ mkdir -p /tmp/example-dockerfile-http && cd /tmp/example-dockerfile-http $ deis create example-dockerfile-http --no-remote Creating application... done, created example-dockerfile-http Note For all commands except for deis create , the deis client uses the name of the current directory as the app name if you don't specify it explicitly with --app .","title":"Create an Application"},{"location":"applications/using-docker-images/#deploy-the-application","text":"Use deis pull to deploy your application from DockerHub or a public registry. $ deis pull <username>/example-dockerfile-http:latest Creating build... done, v2 $ curl -s http://example-dockerfile-http.local3.deisapp.com Powered by Deis Because you are deploying a Docker image, the cmd process type is automatically scaled to 1 on first deploy. Use deis scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of Containers running that process.","title":"Deploy the Application"},{"location":"applications/using-docker-images/#private-registry","text":"To deploy Docker images from a private registry or from a private repository, use deis registry to attach credentials to your application. These credentials are the same as you'd use when running docker login at your private registry. To deploy private Docker images, take the following steps: Gather the username and password for the registry, such as a Quay.io Robot Account or a GCR.io Long Lived Token Run deis registry:set username=<the-user> password=<secret> -a <application-name> Now perform deis pull as normal, against an image in the private registry When using a GCR.io Long Lived Token , the JSON blob will have to be compacted first using a tool like jq and then used in the password field in deis registry:set . For the username, use _json_key . For example: deis registry:set username=_json_key password=\"$(cat google_cloud_cred.json | jq -c .)\" When using a private registry the docker images are no longer pulled into the Deis Internal Registry via the Deis Workflow Controller but rather is managed by Kubernetes. This will increase security and overall speed, however the application port information can no longer be discovered. Instead the application port information can be set via deis config:set PORT=80 prior to setting the registry information. Note Currently GCR.io and ECR in short lived auth token mode are not supported.","title":"Private Registry"},{"location":"applications/using-dockerfiles/","text":"Using Dockerfiles \u00b6 Deis supports deploying applications via Dockerfiles. A Dockerfile automates the steps for crafting a Docker Image . Dockerfiles are incredibly powerful but require some extra work to define your exact application runtime environment. Add SSH Key \u00b6 For Dockerfile based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run deis keys:add to upload your SSH key to Deis Workflow. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done Read more about adding/removing SSH Keys here . Prepare an Application \u00b6 If you do not have an existing application, you can clone an example application that demonstrates the Dockerfile workflow. $ git clone https://github.com/teamhephy/helloworld.git $ cd helloworld Dockerfile Requirements \u00b6 In order to deploy Dockerfile applications, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: deis config:set PORT=5000 . See Configuring Registry for more info. Create an Application \u00b6 Use deis create to create an application on the Controller . $ deis create Creating application... done, created folksy-offshoot Git remote deis added Push to Deploy \u00b6 Use git push deis master to deploy your application. $ git push deis master Counting objects: 13, done. Delta compression using up to 8 threads. Compressing objects: 100% (13/13), done. Writing objects: 100% (13/13), 1.99 KiB | 0 bytes/s, done. Total 13 (delta 2), reused 0 (delta 0) -----> Building Docker image Uploading context 4.096 kB Uploading context Step 0 : FROM deis/base:latest ---> 60024338bc63 Step 1 : RUN wget -O /tmp/go1.2.1.linux-amd64.tar.gz -q https://go.googlecode.com/files/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> cf9ef8c5caa7 Step 2 : RUN tar -C /usr/local -xzf /tmp/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> 515b1faf3bd8 Step 3 : RUN mkdir -p /go ---> Using cache ---> ebf4927a00e9 Step 4 : ENV GOPATH /go ---> Using cache ---> c6a276eded37 Step 5 : ENV PATH /usr/local/go/bin:/go/bin:$PATH ---> Using cache ---> 2ba6f6c9f108 Step 6 : ADD . /go/src/github.com/deis/helloworld ---> 94ab7f4b977b Removing intermediate container 171b7d9fdb34 Step 7 : RUN cd /go/src/github.com/deis/helloworld && go install -v . ---> Running in 0c8fbb2d2812 github.com/deis/helloworld ---> 13b5af931393 Removing intermediate container 0c8fbb2d2812 Step 8 : ENV PORT 80 ---> Running in 9b07da36a272 ---> 2dce83167874 Removing intermediate container 9b07da36a272 Step 9 : CMD [\"/go/bin/helloworld\"] ---> Running in f7b215199940 ---> b1e55ce5195a Removing intermediate container f7b215199940 Step 10 : EXPOSE 80 ---> Running in 7eb8ec45dcb0 ---> ea1a8cc93ca3 Removing intermediate container 7eb8ec45dcb0 Successfully built ea1a8cc93ca3 -----> Pushing image to private registry Launching... done, v2 -----> folksy-offshoot deployed to Deis http://folksy-offshoot.local3.deisapp.com To learn more, use `deis help` or visit http://deis.io To ssh://git@local3.deisapp.com:2222/folksy-offshoot.git * [new branch] master -> master $ curl -s http://folksy-offshoot.local3.deisapp.com Welcome to Deis! See the documentation at http://docs.deis.io/ for more information. Because a Dockerfile application is detected, the cmd process type is automatically scaled to 1 on first deploy. Use deis scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of containers running that process. Docker Build Arguments \u00b6 As of Workflow v2.13.0, users can inject their application config into the Docker image using Docker build arguments . To opt into this, users must add a new environment variable to their application: $ deis config:set DEIS_DOCKER_BUILD_ARGS_ENABLED=1 Every environment variable set with deis config:set will then be available for use inside the user's Dockerfile. For example, if a user runs deis config:set POWERED_BY=Workflow , the user can utilize that build argument in their Dockerfile: ARG POWERED_BY RUN echo \"Powered by $POWERED_BY\" > /etc/motd","title":"Dockerfiles"},{"location":"applications/using-dockerfiles/#using-dockerfiles","text":"Deis supports deploying applications via Dockerfiles. A Dockerfile automates the steps for crafting a Docker Image . Dockerfiles are incredibly powerful but require some extra work to define your exact application runtime environment.","title":"Using Dockerfiles"},{"location":"applications/using-dockerfiles/#add-ssh-key","text":"For Dockerfile based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. See this document for instructions on how to generate an SSH key. Run deis keys:add to upload your SSH key to Deis Workflow. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done Read more about adding/removing SSH Keys here .","title":"Add SSH Key"},{"location":"applications/using-dockerfiles/#prepare-an-application","text":"If you do not have an existing application, you can clone an example application that demonstrates the Dockerfile workflow. $ git clone https://github.com/teamhephy/helloworld.git $ cd helloworld","title":"Prepare an Application"},{"location":"applications/using-dockerfiles/#dockerfile-requirements","text":"In order to deploy Dockerfile applications, they must conform to the following requirements: The Dockerfile must use the EXPOSE directive to expose exactly one port. That port must be listening for an HTTP connection. The Dockerfile must use the CMD directive to define the default process that will run within the container. The Docker image must contain bash to run processes. Note Note that if you are using a private registry of any kind ( gcr or other) the application environment must include a $PORT config variable that matches the EXPOSE 'd port, example: deis config:set PORT=5000 . See Configuring Registry for more info.","title":"Dockerfile Requirements"},{"location":"applications/using-dockerfiles/#create-an-application","text":"Use deis create to create an application on the Controller . $ deis create Creating application... done, created folksy-offshoot Git remote deis added","title":"Create an Application"},{"location":"applications/using-dockerfiles/#push-to-deploy","text":"Use git push deis master to deploy your application. $ git push deis master Counting objects: 13, done. Delta compression using up to 8 threads. Compressing objects: 100% (13/13), done. Writing objects: 100% (13/13), 1.99 KiB | 0 bytes/s, done. Total 13 (delta 2), reused 0 (delta 0) -----> Building Docker image Uploading context 4.096 kB Uploading context Step 0 : FROM deis/base:latest ---> 60024338bc63 Step 1 : RUN wget -O /tmp/go1.2.1.linux-amd64.tar.gz -q https://go.googlecode.com/files/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> cf9ef8c5caa7 Step 2 : RUN tar -C /usr/local -xzf /tmp/go1.2.1.linux-amd64.tar.gz ---> Using cache ---> 515b1faf3bd8 Step 3 : RUN mkdir -p /go ---> Using cache ---> ebf4927a00e9 Step 4 : ENV GOPATH /go ---> Using cache ---> c6a276eded37 Step 5 : ENV PATH /usr/local/go/bin:/go/bin:$PATH ---> Using cache ---> 2ba6f6c9f108 Step 6 : ADD . /go/src/github.com/deis/helloworld ---> 94ab7f4b977b Removing intermediate container 171b7d9fdb34 Step 7 : RUN cd /go/src/github.com/deis/helloworld && go install -v . ---> Running in 0c8fbb2d2812 github.com/deis/helloworld ---> 13b5af931393 Removing intermediate container 0c8fbb2d2812 Step 8 : ENV PORT 80 ---> Running in 9b07da36a272 ---> 2dce83167874 Removing intermediate container 9b07da36a272 Step 9 : CMD [\"/go/bin/helloworld\"] ---> Running in f7b215199940 ---> b1e55ce5195a Removing intermediate container f7b215199940 Step 10 : EXPOSE 80 ---> Running in 7eb8ec45dcb0 ---> ea1a8cc93ca3 Removing intermediate container 7eb8ec45dcb0 Successfully built ea1a8cc93ca3 -----> Pushing image to private registry Launching... done, v2 -----> folksy-offshoot deployed to Deis http://folksy-offshoot.local3.deisapp.com To learn more, use `deis help` or visit http://deis.io To ssh://git@local3.deisapp.com:2222/folksy-offshoot.git * [new branch] master -> master $ curl -s http://folksy-offshoot.local3.deisapp.com Welcome to Deis! See the documentation at http://docs.deis.io/ for more information. Because a Dockerfile application is detected, the cmd process type is automatically scaled to 1 on first deploy. Use deis scale cmd=3 to increase cmd processes to 3, for example. Scaling a process type directly changes the number of containers running that process.","title":"Push to Deploy"},{"location":"applications/using-dockerfiles/#docker-build-arguments","text":"As of Workflow v2.13.0, users can inject their application config into the Docker image using Docker build arguments . To opt into this, users must add a new environment variable to their application: $ deis config:set DEIS_DOCKER_BUILD_ARGS_ENABLED=1 Every environment variable set with deis config:set will then be available for use inside the user's Dockerfile. For example, if a user runs deis config:set POWERED_BY=Workflow , the user can utilize that build argument in their Dockerfile: ARG POWERED_BY RUN echo \"Powered by $POWERED_BY\" > /etc/motd","title":"Docker Build Arguments"},{"location":"changelogs/v2.0.0/","text":"Workflow v2.0.0-rc2 -> v2.0.0 \u00b6 Fixes \u00b6 db4cd9d (postgres) - rootfs: always perform an initial backup 7c89a3c (postgres) - rootfs: enable archive_mode before initial boot 5910902 (controller) - scheduler: cast ports to int before passing them on to k8s 20ea192 (workflow) - health: remove documentation on unused HEALTHCHECK_PORT cfdd9ab (charts) - deis-dev/tpl/deis-builder-rc.yaml: make the objectstore-creds secret read-only in builder Documentation \u00b6 afc9d2a (registry) - CHANGELOG.md: add entry for v2.0.0-rc2 a807d2a (registry) - CHANGELOG.md: add entry for v2.0.0 55cf8a1 (workflow-manager) - CHANGELOG.md: add entry for v2.0.0-rc2 f110d04 (workflow-manager) - CHANGELOG.md: add entry for v2.0.0 a06057d (postgres) - CHANGELOG.md: add entry for v2.0.0-rc2 77e2991 (postgres) - CHANGELOG.md: add entry for v2.0.0 0393a7a (workflow-e2e) - README.md: remove beta status 9214eee (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0-rc2 a93420f (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0 d39fcc1 (stdout-metrics) - CHANGELOG.md: add entry for v2.0.0-rc2 305c25c (stdout-metrics) - CHANGELOG.md: add entry for v2.0.0 1993192 (slugrunner) - CHANGELOG.md: add entry for v2.0.0-rc2 8df35f9 (slugrunner) - CHANGELOG.md: add entry for v2.0.0 1bbaf04 (slugbuilder) - CHANGELOG.md: add entry for v2.0.0-rc2 71f7e6c (slugbuilder) - CHANGELOG.md: add entry for v2.0.0 eafb142 (monitor) - README: Update readme to remove beta status 6b979ed (monitor) - CHANGELOG.md: add entry for v2.0.0-rc2 42f91b2 (monitor) - README: Add architecture diagram 477be8b (monitor) - CHANGELOG.md: add entry for v2.0.0 5afdca3 (minio) - CHANGELOG.md: add entry for v2.0.0 bce6c31 (builder) - pkg: update help URL to https://deis.com/ ea6b17a (builder) - CHANGELOG.md: add entry for v2.0.0 f37322b (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0-rc2 66a176b (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0 e945cb5 (fluentd) - CHANGELOG.md: add entry for v2.0.0-rc2 06f6fed (fluentd) - CHANGELOG.md: add entry for v2.0.0 f7188cd (logger) - CHANGELOG.md: add entry for v2.0.0-rc2 9c3019c (logger) - CHANGELOG.md: add entry for v2.0.0 07eb015 (router) - CHANGELOG.md: add entry for v2.0.0-rc2 7e0eb9d (router) - CHANGELOG.md: add entry for v2.0.0 2d08fb5 (controller) - CHANGELOG.md: add entry for v2.0.0 0babcff (workflow) - CHANGELOG.md: add entry for v2.0.0 492d25e (charts) - CHANGELOG.md: add entry for v2.0.0-rc2 3ee1184 (charts) - CHANGELOG.md: add entry for v2.0.0 Maintenance \u00b6 9cd3013 (registry) - README.md: remove beta status e798cbd (workflow-manager) - README.md: remove beta status 779cef7 (postgres) - README.md: remove beta status 382cba2 (workflow-e2e) - Dockerfile: update deis CLI to a17f89a d059474 (slugbuilder) - various: remove beta status c3afeb8 (minio) - README.md: remove beta status 0112844 (builder) - various: remove beta status 91e869b (dockerbuilder) - various: remove beta status bf0cac4 (dockerbuilder) - various: remove beta status e618f9d (router) - README.md: remove beta status 816a36b (controller) - requirements: update codecov to 2.0.5 db57962 (controller) - README: remove references to beta in README 4bb866f (controller) - version: update platform version to 2.0.0 5f2c4d9 (workflow) - various: remove beta status 095035d (workflow) - docs: update version to v2.0.0 15d5ce7 (charts) - workflow-rc2: releasing workflow-rc2(-e2e) and router-rc2 4e06347 (charts) - workflow-rc2: releasing workflow-rc2(-e2e) and router-rc2- final images 7933ec4 (charts) - various: remove beta status 0301216 (charts) - workflow-v2.0.0: releasing workflow-v2.0.0","title":"v2.0.0"},{"location":"changelogs/v2.0.0/#workflow-v200-rc2-v200","text":"","title":"Workflow v2.0.0-rc2 -&gt; v2.0.0"},{"location":"changelogs/v2.0.0/#fixes","text":"db4cd9d (postgres) - rootfs: always perform an initial backup 7c89a3c (postgres) - rootfs: enable archive_mode before initial boot 5910902 (controller) - scheduler: cast ports to int before passing them on to k8s 20ea192 (workflow) - health: remove documentation on unused HEALTHCHECK_PORT cfdd9ab (charts) - deis-dev/tpl/deis-builder-rc.yaml: make the objectstore-creds secret read-only in builder","title":"Fixes"},{"location":"changelogs/v2.0.0/#documentation","text":"afc9d2a (registry) - CHANGELOG.md: add entry for v2.0.0-rc2 a807d2a (registry) - CHANGELOG.md: add entry for v2.0.0 55cf8a1 (workflow-manager) - CHANGELOG.md: add entry for v2.0.0-rc2 f110d04 (workflow-manager) - CHANGELOG.md: add entry for v2.0.0 a06057d (postgres) - CHANGELOG.md: add entry for v2.0.0-rc2 77e2991 (postgres) - CHANGELOG.md: add entry for v2.0.0 0393a7a (workflow-e2e) - README.md: remove beta status 9214eee (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0-rc2 a93420f (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0 d39fcc1 (stdout-metrics) - CHANGELOG.md: add entry for v2.0.0-rc2 305c25c (stdout-metrics) - CHANGELOG.md: add entry for v2.0.0 1993192 (slugrunner) - CHANGELOG.md: add entry for v2.0.0-rc2 8df35f9 (slugrunner) - CHANGELOG.md: add entry for v2.0.0 1bbaf04 (slugbuilder) - CHANGELOG.md: add entry for v2.0.0-rc2 71f7e6c (slugbuilder) - CHANGELOG.md: add entry for v2.0.0 eafb142 (monitor) - README: Update readme to remove beta status 6b979ed (monitor) - CHANGELOG.md: add entry for v2.0.0-rc2 42f91b2 (monitor) - README: Add architecture diagram 477be8b (monitor) - CHANGELOG.md: add entry for v2.0.0 5afdca3 (minio) - CHANGELOG.md: add entry for v2.0.0 bce6c31 (builder) - pkg: update help URL to https://deis.com/ ea6b17a (builder) - CHANGELOG.md: add entry for v2.0.0 f37322b (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0-rc2 66a176b (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0 e945cb5 (fluentd) - CHANGELOG.md: add entry for v2.0.0-rc2 06f6fed (fluentd) - CHANGELOG.md: add entry for v2.0.0 f7188cd (logger) - CHANGELOG.md: add entry for v2.0.0-rc2 9c3019c (logger) - CHANGELOG.md: add entry for v2.0.0 07eb015 (router) - CHANGELOG.md: add entry for v2.0.0-rc2 7e0eb9d (router) - CHANGELOG.md: add entry for v2.0.0 2d08fb5 (controller) - CHANGELOG.md: add entry for v2.0.0 0babcff (workflow) - CHANGELOG.md: add entry for v2.0.0 492d25e (charts) - CHANGELOG.md: add entry for v2.0.0-rc2 3ee1184 (charts) - CHANGELOG.md: add entry for v2.0.0","title":"Documentation"},{"location":"changelogs/v2.0.0/#maintenance","text":"9cd3013 (registry) - README.md: remove beta status e798cbd (workflow-manager) - README.md: remove beta status 779cef7 (postgres) - README.md: remove beta status 382cba2 (workflow-e2e) - Dockerfile: update deis CLI to a17f89a d059474 (slugbuilder) - various: remove beta status c3afeb8 (minio) - README.md: remove beta status 0112844 (builder) - various: remove beta status 91e869b (dockerbuilder) - various: remove beta status bf0cac4 (dockerbuilder) - various: remove beta status e618f9d (router) - README.md: remove beta status 816a36b (controller) - requirements: update codecov to 2.0.5 db57962 (controller) - README: remove references to beta in README 4bb866f (controller) - version: update platform version to 2.0.0 5f2c4d9 (workflow) - various: remove beta status 095035d (workflow) - docs: update version to v2.0.0 15d5ce7 (charts) - workflow-rc2: releasing workflow-rc2(-e2e) and router-rc2 4e06347 (charts) - workflow-rc2: releasing workflow-rc2(-e2e) and router-rc2- final images 7933ec4 (charts) - various: remove beta status 0301216 (charts) - workflow-v2.0.0: releasing workflow-v2.0.0","title":"Maintenance"},{"location":"changelogs/v2.1.0/","text":"Workflow v2.0.0 -> v2.1.0 \u00b6 Features \u00b6 1e6e226 (router) - *: Update nginx to 1.10.1 6314a15 (registry) - swift: add support for swift storage e494bd9 (postgres) - wal-e: use the latest wal-e to use aws instance profiles 6980348 (slugbuilder) - swift: Add support for swift storage 9e5ce71 (dockerbuilder) - swift: Add support for swift object storage cb4cc44 (fluentd) - deis-output: Custom fluentd plugin for sending data to deis components d8f48be (workflow-manager) - doctor: add doctor client code and doctor api call b95c60c (workflow-manager) - swagger: add doctor api get spec 4ab1dc2 (workflow-manager) - doctor: add curl script to access doctor endpoint f8bfa8d (monitor) - telegraf: enable etcd b1aff88 (monitor) - telegraf: enable prometheus flag 5e19462 (monitor) - grafana,telegraf: Pull metric data from nsq via telegraf 5cb3cb4 (monitor) - grafana: Add deis-health dashboard 8cca750 (workflow-e2e) - registry: PORT is required for private registry f0f5712 (workflow-e2e) - apps: apps:run will now print on stderr if the command errors (#231) 6876296 (workflow-e2e) - docker: install specified CLI version at runtime (#233) c65d01b (workflow-e2e) - *: update to use new errors from CLI (#239) a532726 (workflow-e2e) - git_push_test.go: add git push interrupt test 34cbfe2 (workflow-e2e) - healthchecks: add deis healthchecks e2e tests a369718 (logger) - ringbuffer: Treat empty ringbuffer as error 8ed585f (charts) - workflow-dev: Add nsq to the workflow chart 5b29b4c (charts) - database: Add easier off-cluster db config 6fdcf08 (builder) - lock: add timeout to repository lock feature 422075b (builder) - swift: Add support for swift object storage a1c4619 (controller) - config: validate PORT and HEALTHCHECK_* values for config:set operations ccc6b1f (controller) - release: require PORT to be set when private registry is set 0231c58 (controller) - django: explicitically define on_delete for ForeignKey fields for 2.0 compat 6e136e2 (controller) - debug: DEIS_DEBUG now affects Django DEBUG as well 4c674d0 (controller) - release: throw 409 when identical release is done sequantially af76733 (controller) - api: Add healthcheck field to Config 7af2197 (controller) - settings: log all SQL queries if DEBUG==True 2b11d1b (workflow) - Makefile/Dockerfile: add docker-test recipe 7bbb8a1 (workflow) - api: add v2.1 api documentation. (#357) Fixes \u00b6 4338ee1 (slugrunner) - Dockerfile: download the object storage CLI from GCS 8bfc4ee (postgres) - contrib: allow 5 or 6 backups 419a0e3 (postgres) - rootfs: enable archive_mode before initial boot 923c9f8 (slugbuilder) - Dockerfile: download the object storage CLI from GCS e7a22e0 (dockerbuilder) - objectstore: set properly builder bucket file environment variable f724059 (fluentd) - boot: Move from old type declaration to @type 2890575 (fluentd) - boot: Create better way to generate fluentd conf 6ae5779 (minio) - Dockerfile: download minio from a mirror (#110) af9ef04 (workflow-manager) - doctor: including API version and /doctor in url (#78) 6f71be2 (workflow-e2e) - registry: overwriting variable typo 34f16a5 (workflow-e2e) - registry: recorganise registry tests order and fix a should(say()) call 188f6aa (workflow-e2e) - registry: more port setting and fix up error message detection d56ba6d (workflow-e2e) - apps_test: escape quotes properly in deis run spec afbe0f7 (workflow-e2e) - README: update go report card badge url (#232) 8cf7025 (workflow-e2e) - apps/commands: match substring, not entire string 7d15489 (workflow-e2e) - config: unsetting a key that does not exist results in exit 1 4ee56b2 (workflow-e2e) - deps: update SDK to reflect changed spelling of hyphen (#246) 64b4512 (charts) - minio: create minio when using storage type as minio via env vars 5cf4df4 (builder) - sshd: unlock the repository when gitreceive succeeds or fails 3a332a4 (builder) - flag: Use DEIS_DEBUG instead DEBUG environment variable for debug settings 43a66c9 (builder) - README: update go report card badge url (#370) 2f253dd (builder) - server.go: don't reply false on failed lock 844b2ff (builder) - pkg: set check timeouts to 10s 3e7a785 (builder) - pkg/sshd/server.go: remove the closer channel (#359) a230d05 (builder) - pkg/gitreceive/config.go: require dependent image names (#377) df30ee6 (controller) - api: remove slug tarball info from app log 61b6858 (controller) - scheduler: remove unused health check config option: HEALTCHECK_PORT c6686e9 (controller) - scheduler: cast ports to int before passing them on to k8s 2f1b140 (controller) - management: handle errors in object loading and application deployments instead of throwing exceptions dc4769a (controller) - logs: retry fetching logs from the logger 3 times if the services is unavailable c8c7d80 (controller) - scale: get the desired number of replicas from the rc 3fa6f70 (controller) - scheduler: make deploy have 0 replicas by default and then use scaling to go up 09b9be2 (controller) - secrets: update env secrets if they already exists (overwrites existing values) 5fb1bbb (controller) - config: when rolling a new config copy from the latest release instead of latest config for the app 0d9988b (controller) - serializer: skip None values in config and registry 936a40e (controller) - exceptions: tests now capture critical only and uncaught exceptions have been reclassified as critical 3f980b8 (controller) - exceptions: log certain APIExceptions tracebacks 9f8ac04 (controller) - config: return a 422 if unsetting a config key that does not exist cae4bf9 (controller) - models: hypens -> hyphens (#840) e108f14 (workflow) - registry: explain PORT is required when using private registry information e197163 (workflow) - component-config: clarify GUNICORN_WORKERS value dc5ee1a (workflow) - api: update out of date cert api docs (#339) 25006d1 (workflow) - applications: fixup exec probe output Documentation \u00b6 044f85c (slugrunner) - CHANGELOG.md: add entry for v2.0.0 bf3e1da (router) - README: add codecov.io badge 0aa8abb (router) - readme: Add anchors to every row in annotations table a80425d (router) - CHANGELOG.md: add entry for v2.0.0 6b60912 (router) - README: fix Go report card badge 4b1f311 (registry) - CHANGELOG.md: add entry for v2.0.0 5fc10d5 (registry) - README: fix Go report card badge 61a4dc9 (postgres) - CHANGELOG.md: add entry for v2.0.0 4efe5f9 (postgres) - README.md: Fix the default value of IMAGE_PREFIX 920dbf6 (slugbuilder) - CHANGELOG.md: add entry for v2.0.0 48d4ecb (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0 7f046cc (fluentd) - CHANGELOG.md: add entry for v2.0.0 31e054d (minio) - CHANGELOG.md: add entry for v2.0.0-rc2 958ccd7 (minio) - CHANGELOG.md: add entry for v2.0.0 ebbbc3a (workflow-manager) - CHANGELOG.md: add entry for v2.0.0 04f65c6 (monitor) - CHANGELOG.md: add entry for v2.0.0 94bf4c1 (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0 778ab68 (logger) - README: add codecov.io badge d3fc751 (logger) - CHANGELOG.md: add entry for v2.0.0 178bc7c (logger) - README: fix Go report card badge 6367466 (charts) - CHANGELOG.md: add entry for v2.0.0 e038851 (builder) - CHANGELOG.md: add entry for v2.0.0-rc2 58a8786 (builder) - pkg: update help URL to https://deis.com/ 0df2ba3 (builder) - CHANGELOG.md: add entry for v2.0.0 c3945f2 (builder) - README: add codecov.io badge b001515 (controller) - CHANGELOG.md: add entry for v2.0.0-rc2 c7fb984 (controller) - CHANGELOG.md: add entry for v2.0.0 9063a96 (workflow) - installing-workflow: fix missing watch flag cf9693f (workflow) - release-checklist.md: remove bintray references cda073c (workflow) - CHANGELOG.md: add entry for v2.0.0 5c753e5 (workflow) - styles: update the theme to match deis.com a77d967 (workflow) - styles: remove sass from makefile e37b2dc (workflow) - styles: tidy up JS, better affix the sidebar menu 919f22c (workflow) - styles: fix urls, style for better mobile layout e868009 (workflow) - styles: remove bower_components 2e1c6a9 (workflow) - styles: mobile off-canvas menu 908f715 (workflow) - styles: color changes to open sidebar sections 82000d1 (workflow) - src/roadmap/release-checklist.md: update Step 2.1 7cbd1de (workflow) - src/roadmap/release-checklist.md: update if major release dad9598 (workflow) - submitting-a-pr: add \"hotfix revert\" exception to LGTM rules a0ff462 (workflow) - release-checklist: Improve instructions pertaining to previous release cdbc575 (workflow) - README.md: fix quick start guide URL 9e843cd (workflow) - s3: add instruction for using IAM creds b451c66 (workflow) - release_checklist.md: return to using immutable tags 2286765 (workflow) - submitting-a-pull-request.md: add info on testing paired commits 467a21d (workflow) - platform-logging.md: Need \"--namespace=deis\" when deleting pods. 606bdd8 (workflow) - router: Remove invalid labels from example whitelists 87e0b58 (workflow) - upgrade-workflow.md: Fix a typo. aa7144c (workflow) - platform-ssl.md: correct example manifest 9d5d1d5 (workflow) - database: Document off-cluster db configuration 0cb76fc (workflow) - applications: add documentation for healthchecks 7ee764f (workflow) - release-checklist.md: modify docker tag/push instructions to use new deisrel command (#355) eda6479 (workflow) - v2.1.0: Updates docs for latest release Maintenance \u00b6 0526f01 (slugrunner) - manifests: remove unused/deprecated manifests dir 3b3aaad (slugrunner) - Dockerfile: Remove WORKFLOW_RELEASE env var 7c23489 (router) - Dockerfile: Remove WORKFLOW_RELEASE env var f0bb535 (slugbuilder) - buildpacks: update heroku-buildpack-go to v41 4aeb7ff (slugbuilder) - buildpacks: update heroku-buildpack-php to v105 70b88ef (slugbuilder) - manifests: remove unused/deprecated manifests dir cad6225 (slugbuilder) - buildpacks: update heroku-buildpack-php to v107 eb47460 (dockerbuilder) - manifests: remove unused/deprecated manifests dir 905cde5 (fluentd) - Dockerfile: Remove WORKFLOW_RELEASE env var 52c97ad (minio) - README.md: remove beta status 6aac8ba (minio) - Dockerfile: Remove WORKFLOW_RELEASE env var 3cbf260 (monitor) - grafana: Update nsq dashboard to add message per second graph 8f52433 (monitor) - grafana: Remove stray alias in a kubernetes health graph 5ff77c7 (monitor) - Dockerfile: Remove WORKFLOW_RELEASE env var 7d6a033 (workflow-e2e) - Makefile: remove deprecated '-f' flag 7123b6a (logger) - transport: Refactor to use pluggable Aggregator component... ba819b0 (logger) - Dockerfile: Remove WORKFLOW_RELEASE env var 92abf85 (charts) - router-dev/Chart.yaml: bump version to v2.0.0 46289d0 (charts) - workflow/router-dev/Chart.yaml: prepend description with chart name 64026dc (charts) - workflow-dev: Update image name in nsqd-rc to be nsq. fcd4fce (charts) - logger/fluentd: Update logging stack to reflect nsq usage 473ea02 (charts) - workflow-dev: Update telegraf env vars 010de23 (charts) - workflow-dev: remove stdout metrics config from fluentd 3274b8c (charts) - logger: Stop logging via UDP fc70265 (charts) - workflow-v2.1.0: releasing workflow-v2.1.0(-e2e) and router-v2.1.0 f6580ee (builder) - various: remove beta status 03a8ac5 (builder) - Dockerfile: bump git to v2.8.4 bf35966 (controller) - requirements: update codecov to 2.0.5 59a8d23 (controller) - Dockerfile: update to base:0.3.0 image to get a slimmer image 3a6ee54 (controller) - README: remove references to beta in README 7a88725 (controller) - requirements: update to Django 1.9.7 04049b4 (controller) - version: update platform version to 2.0.0 db2e182 (controller) - deis: bump version to 2.1.0-dev 13cffb6 (controller) - requirements: update ndg-httpsclient to 0.4.1 eda8bea (controller) - rootfs: bump platform version to 2.1.0 (#841) 214b0a9 (controller) - api: bump api version to v2.1.0 595d377 (workflow) - health: note that kubernetes does not support query params in the health check path 88e240a (workflow) - docs: update version to v2.0.0 20f2b5a (workflow) - ga: use deis.com GA account 10b1146 (workflow) - docs: ignore bower_components for doc styles","title":"v2.1.0"},{"location":"changelogs/v2.1.0/#workflow-v200-v210","text":"","title":"Workflow v2.0.0 -&gt; v2.1.0"},{"location":"changelogs/v2.1.0/#features","text":"1e6e226 (router) - *: Update nginx to 1.10.1 6314a15 (registry) - swift: add support for swift storage e494bd9 (postgres) - wal-e: use the latest wal-e to use aws instance profiles 6980348 (slugbuilder) - swift: Add support for swift storage 9e5ce71 (dockerbuilder) - swift: Add support for swift object storage cb4cc44 (fluentd) - deis-output: Custom fluentd plugin for sending data to deis components d8f48be (workflow-manager) - doctor: add doctor client code and doctor api call b95c60c (workflow-manager) - swagger: add doctor api get spec 4ab1dc2 (workflow-manager) - doctor: add curl script to access doctor endpoint f8bfa8d (monitor) - telegraf: enable etcd b1aff88 (monitor) - telegraf: enable prometheus flag 5e19462 (monitor) - grafana,telegraf: Pull metric data from nsq via telegraf 5cb3cb4 (monitor) - grafana: Add deis-health dashboard 8cca750 (workflow-e2e) - registry: PORT is required for private registry f0f5712 (workflow-e2e) - apps: apps:run will now print on stderr if the command errors (#231) 6876296 (workflow-e2e) - docker: install specified CLI version at runtime (#233) c65d01b (workflow-e2e) - *: update to use new errors from CLI (#239) a532726 (workflow-e2e) - git_push_test.go: add git push interrupt test 34cbfe2 (workflow-e2e) - healthchecks: add deis healthchecks e2e tests a369718 (logger) - ringbuffer: Treat empty ringbuffer as error 8ed585f (charts) - workflow-dev: Add nsq to the workflow chart 5b29b4c (charts) - database: Add easier off-cluster db config 6fdcf08 (builder) - lock: add timeout to repository lock feature 422075b (builder) - swift: Add support for swift object storage a1c4619 (controller) - config: validate PORT and HEALTHCHECK_* values for config:set operations ccc6b1f (controller) - release: require PORT to be set when private registry is set 0231c58 (controller) - django: explicitically define on_delete for ForeignKey fields for 2.0 compat 6e136e2 (controller) - debug: DEIS_DEBUG now affects Django DEBUG as well 4c674d0 (controller) - release: throw 409 when identical release is done sequantially af76733 (controller) - api: Add healthcheck field to Config 7af2197 (controller) - settings: log all SQL queries if DEBUG==True 2b11d1b (workflow) - Makefile/Dockerfile: add docker-test recipe 7bbb8a1 (workflow) - api: add v2.1 api documentation. (#357)","title":"Features"},{"location":"changelogs/v2.1.0/#fixes","text":"4338ee1 (slugrunner) - Dockerfile: download the object storage CLI from GCS 8bfc4ee (postgres) - contrib: allow 5 or 6 backups 419a0e3 (postgres) - rootfs: enable archive_mode before initial boot 923c9f8 (slugbuilder) - Dockerfile: download the object storage CLI from GCS e7a22e0 (dockerbuilder) - objectstore: set properly builder bucket file environment variable f724059 (fluentd) - boot: Move from old type declaration to @type 2890575 (fluentd) - boot: Create better way to generate fluentd conf 6ae5779 (minio) - Dockerfile: download minio from a mirror (#110) af9ef04 (workflow-manager) - doctor: including API version and /doctor in url (#78) 6f71be2 (workflow-e2e) - registry: overwriting variable typo 34f16a5 (workflow-e2e) - registry: recorganise registry tests order and fix a should(say()) call 188f6aa (workflow-e2e) - registry: more port setting and fix up error message detection d56ba6d (workflow-e2e) - apps_test: escape quotes properly in deis run spec afbe0f7 (workflow-e2e) - README: update go report card badge url (#232) 8cf7025 (workflow-e2e) - apps/commands: match substring, not entire string 7d15489 (workflow-e2e) - config: unsetting a key that does not exist results in exit 1 4ee56b2 (workflow-e2e) - deps: update SDK to reflect changed spelling of hyphen (#246) 64b4512 (charts) - minio: create minio when using storage type as minio via env vars 5cf4df4 (builder) - sshd: unlock the repository when gitreceive succeeds or fails 3a332a4 (builder) - flag: Use DEIS_DEBUG instead DEBUG environment variable for debug settings 43a66c9 (builder) - README: update go report card badge url (#370) 2f253dd (builder) - server.go: don't reply false on failed lock 844b2ff (builder) - pkg: set check timeouts to 10s 3e7a785 (builder) - pkg/sshd/server.go: remove the closer channel (#359) a230d05 (builder) - pkg/gitreceive/config.go: require dependent image names (#377) df30ee6 (controller) - api: remove slug tarball info from app log 61b6858 (controller) - scheduler: remove unused health check config option: HEALTCHECK_PORT c6686e9 (controller) - scheduler: cast ports to int before passing them on to k8s 2f1b140 (controller) - management: handle errors in object loading and application deployments instead of throwing exceptions dc4769a (controller) - logs: retry fetching logs from the logger 3 times if the services is unavailable c8c7d80 (controller) - scale: get the desired number of replicas from the rc 3fa6f70 (controller) - scheduler: make deploy have 0 replicas by default and then use scaling to go up 09b9be2 (controller) - secrets: update env secrets if they already exists (overwrites existing values) 5fb1bbb (controller) - config: when rolling a new config copy from the latest release instead of latest config for the app 0d9988b (controller) - serializer: skip None values in config and registry 936a40e (controller) - exceptions: tests now capture critical only and uncaught exceptions have been reclassified as critical 3f980b8 (controller) - exceptions: log certain APIExceptions tracebacks 9f8ac04 (controller) - config: return a 422 if unsetting a config key that does not exist cae4bf9 (controller) - models: hypens -> hyphens (#840) e108f14 (workflow) - registry: explain PORT is required when using private registry information e197163 (workflow) - component-config: clarify GUNICORN_WORKERS value dc5ee1a (workflow) - api: update out of date cert api docs (#339) 25006d1 (workflow) - applications: fixup exec probe output","title":"Fixes"},{"location":"changelogs/v2.1.0/#documentation","text":"044f85c (slugrunner) - CHANGELOG.md: add entry for v2.0.0 bf3e1da (router) - README: add codecov.io badge 0aa8abb (router) - readme: Add anchors to every row in annotations table a80425d (router) - CHANGELOG.md: add entry for v2.0.0 6b60912 (router) - README: fix Go report card badge 4b1f311 (registry) - CHANGELOG.md: add entry for v2.0.0 5fc10d5 (registry) - README: fix Go report card badge 61a4dc9 (postgres) - CHANGELOG.md: add entry for v2.0.0 4efe5f9 (postgres) - README.md: Fix the default value of IMAGE_PREFIX 920dbf6 (slugbuilder) - CHANGELOG.md: add entry for v2.0.0 48d4ecb (dockerbuilder) - CHANGELOG.md: add entry for v2.0.0 7f046cc (fluentd) - CHANGELOG.md: add entry for v2.0.0 31e054d (minio) - CHANGELOG.md: add entry for v2.0.0-rc2 958ccd7 (minio) - CHANGELOG.md: add entry for v2.0.0 ebbbc3a (workflow-manager) - CHANGELOG.md: add entry for v2.0.0 04f65c6 (monitor) - CHANGELOG.md: add entry for v2.0.0 94bf4c1 (workflow-e2e) - CHANGELOG.md: add entry for v2.0.0 778ab68 (logger) - README: add codecov.io badge d3fc751 (logger) - CHANGELOG.md: add entry for v2.0.0 178bc7c (logger) - README: fix Go report card badge 6367466 (charts) - CHANGELOG.md: add entry for v2.0.0 e038851 (builder) - CHANGELOG.md: add entry for v2.0.0-rc2 58a8786 (builder) - pkg: update help URL to https://deis.com/ 0df2ba3 (builder) - CHANGELOG.md: add entry for v2.0.0 c3945f2 (builder) - README: add codecov.io badge b001515 (controller) - CHANGELOG.md: add entry for v2.0.0-rc2 c7fb984 (controller) - CHANGELOG.md: add entry for v2.0.0 9063a96 (workflow) - installing-workflow: fix missing watch flag cf9693f (workflow) - release-checklist.md: remove bintray references cda073c (workflow) - CHANGELOG.md: add entry for v2.0.0 5c753e5 (workflow) - styles: update the theme to match deis.com a77d967 (workflow) - styles: remove sass from makefile e37b2dc (workflow) - styles: tidy up JS, better affix the sidebar menu 919f22c (workflow) - styles: fix urls, style for better mobile layout e868009 (workflow) - styles: remove bower_components 2e1c6a9 (workflow) - styles: mobile off-canvas menu 908f715 (workflow) - styles: color changes to open sidebar sections 82000d1 (workflow) - src/roadmap/release-checklist.md: update Step 2.1 7cbd1de (workflow) - src/roadmap/release-checklist.md: update if major release dad9598 (workflow) - submitting-a-pr: add \"hotfix revert\" exception to LGTM rules a0ff462 (workflow) - release-checklist: Improve instructions pertaining to previous release cdbc575 (workflow) - README.md: fix quick start guide URL 9e843cd (workflow) - s3: add instruction for using IAM creds b451c66 (workflow) - release_checklist.md: return to using immutable tags 2286765 (workflow) - submitting-a-pull-request.md: add info on testing paired commits 467a21d (workflow) - platform-logging.md: Need \"--namespace=deis\" when deleting pods. 606bdd8 (workflow) - router: Remove invalid labels from example whitelists 87e0b58 (workflow) - upgrade-workflow.md: Fix a typo. aa7144c (workflow) - platform-ssl.md: correct example manifest 9d5d1d5 (workflow) - database: Document off-cluster db configuration 0cb76fc (workflow) - applications: add documentation for healthchecks 7ee764f (workflow) - release-checklist.md: modify docker tag/push instructions to use new deisrel command (#355) eda6479 (workflow) - v2.1.0: Updates docs for latest release","title":"Documentation"},{"location":"changelogs/v2.1.0/#maintenance","text":"0526f01 (slugrunner) - manifests: remove unused/deprecated manifests dir 3b3aaad (slugrunner) - Dockerfile: Remove WORKFLOW_RELEASE env var 7c23489 (router) - Dockerfile: Remove WORKFLOW_RELEASE env var f0bb535 (slugbuilder) - buildpacks: update heroku-buildpack-go to v41 4aeb7ff (slugbuilder) - buildpacks: update heroku-buildpack-php to v105 70b88ef (slugbuilder) - manifests: remove unused/deprecated manifests dir cad6225 (slugbuilder) - buildpacks: update heroku-buildpack-php to v107 eb47460 (dockerbuilder) - manifests: remove unused/deprecated manifests dir 905cde5 (fluentd) - Dockerfile: Remove WORKFLOW_RELEASE env var 52c97ad (minio) - README.md: remove beta status 6aac8ba (minio) - Dockerfile: Remove WORKFLOW_RELEASE env var 3cbf260 (monitor) - grafana: Update nsq dashboard to add message per second graph 8f52433 (monitor) - grafana: Remove stray alias in a kubernetes health graph 5ff77c7 (monitor) - Dockerfile: Remove WORKFLOW_RELEASE env var 7d6a033 (workflow-e2e) - Makefile: remove deprecated '-f' flag 7123b6a (logger) - transport: Refactor to use pluggable Aggregator component... ba819b0 (logger) - Dockerfile: Remove WORKFLOW_RELEASE env var 92abf85 (charts) - router-dev/Chart.yaml: bump version to v2.0.0 46289d0 (charts) - workflow/router-dev/Chart.yaml: prepend description with chart name 64026dc (charts) - workflow-dev: Update image name in nsqd-rc to be nsq. fcd4fce (charts) - logger/fluentd: Update logging stack to reflect nsq usage 473ea02 (charts) - workflow-dev: Update telegraf env vars 010de23 (charts) - workflow-dev: remove stdout metrics config from fluentd 3274b8c (charts) - logger: Stop logging via UDP fc70265 (charts) - workflow-v2.1.0: releasing workflow-v2.1.0(-e2e) and router-v2.1.0 f6580ee (builder) - various: remove beta status 03a8ac5 (builder) - Dockerfile: bump git to v2.8.4 bf35966 (controller) - requirements: update codecov to 2.0.5 59a8d23 (controller) - Dockerfile: update to base:0.3.0 image to get a slimmer image 3a6ee54 (controller) - README: remove references to beta in README 7a88725 (controller) - requirements: update to Django 1.9.7 04049b4 (controller) - version: update platform version to 2.0.0 db2e182 (controller) - deis: bump version to 2.1.0-dev 13cffb6 (controller) - requirements: update ndg-httpsclient to 0.4.1 eda8bea (controller) - rootfs: bump platform version to 2.1.0 (#841) 214b0a9 (controller) - api: bump api version to v2.1.0 595d377 (workflow) - health: note that kubernetes does not support query params in the health check path 88e240a (workflow) - docs: update version to v2.0.0 20f2b5a (workflow) - ga: use deis.com GA account 10b1146 (workflow) - docs: ignore bower_components for doc styles","title":"Maintenance"},{"location":"changelogs/v2.10.0/","text":"Workflow v2.9.1 -> v2.10.0 \u00b6 Releases \u00b6 controller v2.9.1 -> v2.10.0 fluentd v2.5.0 -> v2.6.0 logger v2.4.0 -> v2.4.1 postgres v2.4.4 -> v2.5.0 registry v2.3.1 -> v2.3.2 registry-token-refresher v1.0.4 -> v1.1.0 router v2.7.0 -> v2.8.1 workflow v2.9.1 -> v2.10.0 workflow-cli v2.9.1 -> v2.10.0 workflow-e2e v2.7.1 -> v2.8.0 Features \u00b6 38275ea (controller) - controller: add LDAP authentication 51cab9d (controller) - api: add deploy hooks (#1168) 805a455 (controller) - api: validate a certificate's private key (#1157) 5bed284 (fluentd) - charts: add optional syslog endpoint setting 830cee8 (postgres) - charts: Add support to specify creds for in cluster db through values file f7df62a (workflow-e2e) - auth_test.go: add interactive register spec 67b658f (workflow) - charts: Add optional syslog endpoint setting to fluentd 4a5b895 (workflow) - azure: Add docs to specify support for the azure container registry 19b9ec1 (workflow) - azure: skeleton for Azure Container Service quickstart f344230 (workflow) - Dockerfile: make the Dockerfile more functional de4564f (workflow) - managing-deis: add docs for deploy hooks e255775 (workflow) - charts: Add support to specify creds for in cluster db through values file Refactors \u00b6 ffa66e7 (controller) - api: placate new flake8 linter checks e470052 (controller) - codecov: add 0.2% failure threshold to codecov (#1192) f2bc3ae (registry) - update docs and Makefile ba06288 (workflow-cli) - placate gometalinter checks 91dda51 (workflow-e2e) - adjust error message expectations 1c05adb (workflow) - require key_json chart value to be base64-encoded Fixes \u00b6 1609d89 (controller) - apiserver: Add an option to skip ssl verification when interacting with the k8s api d2ee40f (controller) - boot: Don't change group ownership of docker socket 62f081a (controller) - scheduler: use pypa packaging to compare server version (#1167) 9f4543b (controller) - domain: remove the annotation when domain is deleted 27a59d1 (controller) - service-config: Don't add annotations if the value is empty 890a263 (controller) - api: account for NoneType when resource is gone (#1178) f132b25 (controller) - api: validate app name against k8s service regex (#1163) 9098331 (controller) - perms: Use the same regex for perms as auth endpoint (#1181) 30ab1d3 (controller) - settings: disable LDAP by default (#1191) 4c36791 (controller) - management: display error when connecting to the database (#1190) 78ad61f (fluentd) - logger: show error message and backtrace 107b2e1 (fluentd) - logger: utf-8 encoding 34da2e2 (router) - charts: enable hostports by default 4284483 (workflow-cli) - healthcheck: Parse arguments properly for httpheaders 958a3ab (workflow-cli) - Jenkinsfile: update downstream test job 2b7700d (workflow-cli) - glide: update the controller sdk go version in the glide 388fd97 (workflow-cli) - Jenkinsfile: set git_branch to env.BRANCH_NAME 6d644a1 (workflow-e2e) - docker-test-integration.sh: explicit DEBUG_MODE check f81df33 (workflow-e2e) - chart: s/ginko/ginkgo a686dfd (workflow) - values: redis params are in the redis chart b3a9db1 (workflow) - upgrade: Use a random generated name for upgrade job so it be upgraded multiple times using helm 5b7b98d (workflow) - releases: remove reference to deis/charts in release notes 233b630 (workflow) - managing-workflow: update logging and monitoring docs to reflect helm v2 6989718 (workflow) - charts: enable hostports by default 2a96baf (workflow) - upgrading-workflow: fix helm upgrade usage Documentation \u00b6 ee93ec4 (controller) - README.md: update badge to use deis-bot's account b4a86c8 (controller) - README: remove helmc mention 1e90453 (registry-token-refresher) - update key_json value 29492e5 (workflow) - managing-workflow: Add docs about resource quota for application namespace c9539d0 (workflow) - src/roadmap/releases.md: update to use k/helm 48b875e (workflow) - gke/boot: Update command to auth to kubernetes host 3c6cb1c (workflow) - azure-acs: style and typo fixes 42f99cf (workflow) - managing-workflow: Add LDAP configuration 3773830 (workflow) - releases.md: update to reference workflow-chart-stage job 6fa3f37 (workflow) - system-requirements: add warning for k8s 1.5 057cbe6 (workflow) - azure-acs: more info and spell fixes 5bbc137 (workflow) - installing-workflow: deprecate support for v1.2 clusters c5d4d46 (workflow) - update versions to v2.9.1 and add changelog 0a8e44e (workflow) - remove need for echo after helm fetch verify; update sha256 0cc5dfb (workflow) - releases.md: add patch release notes f16816e (workflow) - README.md: add temporary holiday notice 3406eac (workflow) - applications: fix broken links for SSH keys 70f50a5 (workflow) - add upgrade note for gcs/gcr 5f6dd73 (workflow) - upgrading-workflow: add note about using single quotes around base64 encoded string Maintenance \u00b6 22288eb (controller) - requirements: update requests lib to 2.12.3 f3d71c0 (controller) - requirements: update Django to 1.10.4 cfc08d6 (controller) - dev_requirements: upgrade flake8 to 3.2.1 f3d9c1b (controller) - requirements: update pytz to 2016.10 6d13723 (controller) - Makefile: remove pyvenv script (#1161) 0566131 (controller) - dev_requirements: update coverage to 4.3.1 b3056f0 (controller) - requirements: update requests to 2.12.4 f478ee9 (controller) - requirements: update idna to 2.2 b6d19d5 (logger) - manifests: remove manifests 50307cc (logger) - glide: update envconfig a0e22a7 (router) - nginx: update nginx to 1.11.7 8622f48 (router) - nginx: update nginx to 1.11.8 0fd3251 (workflow-cli) Dockerfile: update go-dev to v0.21.0 62c2e65 (workflow-cli) glide: bump controller-sdk-go to 50747d7 bf269d2 (workflow) azure: add Azure section to sidebar a4a589e (workflow) docs: add images for ui steps bf61fd6 (workflow) docs: flesh out steps for azure acs through UI ddfe3a0 (workflow) chart: update values file description 1fb84dc (workflow) controller: disable tls verification on acs","title":"v2.10.0"},{"location":"changelogs/v2.10.0/#workflow-v291-v2100","text":"","title":"Workflow v2.9.1 -&gt; v2.10.0"},{"location":"changelogs/v2.10.0/#releases","text":"controller v2.9.1 -> v2.10.0 fluentd v2.5.0 -> v2.6.0 logger v2.4.0 -> v2.4.1 postgres v2.4.4 -> v2.5.0 registry v2.3.1 -> v2.3.2 registry-token-refresher v1.0.4 -> v1.1.0 router v2.7.0 -> v2.8.1 workflow v2.9.1 -> v2.10.0 workflow-cli v2.9.1 -> v2.10.0 workflow-e2e v2.7.1 -> v2.8.0","title":"Releases"},{"location":"changelogs/v2.10.0/#features","text":"38275ea (controller) - controller: add LDAP authentication 51cab9d (controller) - api: add deploy hooks (#1168) 805a455 (controller) - api: validate a certificate's private key (#1157) 5bed284 (fluentd) - charts: add optional syslog endpoint setting 830cee8 (postgres) - charts: Add support to specify creds for in cluster db through values file f7df62a (workflow-e2e) - auth_test.go: add interactive register spec 67b658f (workflow) - charts: Add optional syslog endpoint setting to fluentd 4a5b895 (workflow) - azure: Add docs to specify support for the azure container registry 19b9ec1 (workflow) - azure: skeleton for Azure Container Service quickstart f344230 (workflow) - Dockerfile: make the Dockerfile more functional de4564f (workflow) - managing-deis: add docs for deploy hooks e255775 (workflow) - charts: Add support to specify creds for in cluster db through values file","title":"Features"},{"location":"changelogs/v2.10.0/#refactors","text":"ffa66e7 (controller) - api: placate new flake8 linter checks e470052 (controller) - codecov: add 0.2% failure threshold to codecov (#1192) f2bc3ae (registry) - update docs and Makefile ba06288 (workflow-cli) - placate gometalinter checks 91dda51 (workflow-e2e) - adjust error message expectations 1c05adb (workflow) - require key_json chart value to be base64-encoded","title":"Refactors"},{"location":"changelogs/v2.10.0/#fixes","text":"1609d89 (controller) - apiserver: Add an option to skip ssl verification when interacting with the k8s api d2ee40f (controller) - boot: Don't change group ownership of docker socket 62f081a (controller) - scheduler: use pypa packaging to compare server version (#1167) 9f4543b (controller) - domain: remove the annotation when domain is deleted 27a59d1 (controller) - service-config: Don't add annotations if the value is empty 890a263 (controller) - api: account for NoneType when resource is gone (#1178) f132b25 (controller) - api: validate app name against k8s service regex (#1163) 9098331 (controller) - perms: Use the same regex for perms as auth endpoint (#1181) 30ab1d3 (controller) - settings: disable LDAP by default (#1191) 4c36791 (controller) - management: display error when connecting to the database (#1190) 78ad61f (fluentd) - logger: show error message and backtrace 107b2e1 (fluentd) - logger: utf-8 encoding 34da2e2 (router) - charts: enable hostports by default 4284483 (workflow-cli) - healthcheck: Parse arguments properly for httpheaders 958a3ab (workflow-cli) - Jenkinsfile: update downstream test job 2b7700d (workflow-cli) - glide: update the controller sdk go version in the glide 388fd97 (workflow-cli) - Jenkinsfile: set git_branch to env.BRANCH_NAME 6d644a1 (workflow-e2e) - docker-test-integration.sh: explicit DEBUG_MODE check f81df33 (workflow-e2e) - chart: s/ginko/ginkgo a686dfd (workflow) - values: redis params are in the redis chart b3a9db1 (workflow) - upgrade: Use a random generated name for upgrade job so it be upgraded multiple times using helm 5b7b98d (workflow) - releases: remove reference to deis/charts in release notes 233b630 (workflow) - managing-workflow: update logging and monitoring docs to reflect helm v2 6989718 (workflow) - charts: enable hostports by default 2a96baf (workflow) - upgrading-workflow: fix helm upgrade usage","title":"Fixes"},{"location":"changelogs/v2.10.0/#documentation","text":"ee93ec4 (controller) - README.md: update badge to use deis-bot's account b4a86c8 (controller) - README: remove helmc mention 1e90453 (registry-token-refresher) - update key_json value 29492e5 (workflow) - managing-workflow: Add docs about resource quota for application namespace c9539d0 (workflow) - src/roadmap/releases.md: update to use k/helm 48b875e (workflow) - gke/boot: Update command to auth to kubernetes host 3c6cb1c (workflow) - azure-acs: style and typo fixes 42f99cf (workflow) - managing-workflow: Add LDAP configuration 3773830 (workflow) - releases.md: update to reference workflow-chart-stage job 6fa3f37 (workflow) - system-requirements: add warning for k8s 1.5 057cbe6 (workflow) - azure-acs: more info and spell fixes 5bbc137 (workflow) - installing-workflow: deprecate support for v1.2 clusters c5d4d46 (workflow) - update versions to v2.9.1 and add changelog 0a8e44e (workflow) - remove need for echo after helm fetch verify; update sha256 0cc5dfb (workflow) - releases.md: add patch release notes f16816e (workflow) - README.md: add temporary holiday notice 3406eac (workflow) - applications: fix broken links for SSH keys 70f50a5 (workflow) - add upgrade note for gcs/gcr 5f6dd73 (workflow) - upgrading-workflow: add note about using single quotes around base64 encoded string","title":"Documentation"},{"location":"changelogs/v2.10.0/#maintenance","text":"22288eb (controller) - requirements: update requests lib to 2.12.3 f3d71c0 (controller) - requirements: update Django to 1.10.4 cfc08d6 (controller) - dev_requirements: upgrade flake8 to 3.2.1 f3d9c1b (controller) - requirements: update pytz to 2016.10 6d13723 (controller) - Makefile: remove pyvenv script (#1161) 0566131 (controller) - dev_requirements: update coverage to 4.3.1 b3056f0 (controller) - requirements: update requests to 2.12.4 f478ee9 (controller) - requirements: update idna to 2.2 b6d19d5 (logger) - manifests: remove manifests 50307cc (logger) - glide: update envconfig a0e22a7 (router) - nginx: update nginx to 1.11.7 8622f48 (router) - nginx: update nginx to 1.11.8 0fd3251 (workflow-cli) Dockerfile: update go-dev to v0.21.0 62c2e65 (workflow-cli) glide: bump controller-sdk-go to 50747d7 bf269d2 (workflow) azure: add Azure section to sidebar a4a589e (workflow) docs: add images for ui steps bf61fd6 (workflow) docs: flesh out steps for azure acs through UI ddfe3a0 (workflow) chart: update values file description 1fb84dc (workflow) controller: disable tls verification on acs","title":"Maintenance"},{"location":"changelogs/v2.11.0/","text":"Workflow v2.10.0 -> v2.11.0 \u00b6 Releases \u00b6 builder v2.6.1 -> v2.7.1 controller v2.10.0 -> v2.11.0 dockerbuilder v2.5.2 -> v2.6.0 fluentd v2.6.0 -> v2.6.1 logger v2.4.1 -> v2.4.2 minio v2.3.4 -> v2.3.5 monitor v2.7.0 -> v2.7.1 nsq v2.2.5 -> v2.2.6 postgres v2.5.0 -> v2.5.1 redis v2.2.4 -> v2.2.5 registry v2.3.2 -> v2.3.3 registry-token-refresher v1.1.0 -> v1.1.1 router v2.8.1 -> v2.9.0 slugbuilder v2.4.8 -> v2.4.9 workflow v2.10.0 -> v2.11.0 workflow-cli v2.10.0 -> v2.11.0 workflow-e2e v2.8.0 -> v2.9.0 workflow-manager v2.4.4 -> v2.4.5 Features \u00b6 bd97e3e (builder) - cleaner: delete from object store fcc5bb0 (builder) - Makefile: set docker build flags via environment variable ae03152 (controller) - settings: Get timezone from environment variable (#1196) 48cd872 (controller) - Makefile: set docker build flags via environment variable 003e8dd (dockerbuilder) - Makefile: set docker build flags via environment variable a1e28c8 (fluentd) - Makefile: set docker build flags via environment variable 8ce9845 (logger) - Makefile: set docker build flags via environment variable b2fc347 (minio) - Makefile: set docker build flags via environment variable bfdf091 (monitor) - charts: add optional persistence storage to influxdb and grafana 138fb11 (monitor) - charts: add optional persistence storage to influxdb and grafana c58fde6 (monitor) - Makefile: set docker build flags via environment variable b32fe54 (nsq) - Makefile: set docker build flags via environment variable 524fdf5 (postgres) - Makefile: set docker build flags via environment variable 0cf0deb (redis) - Makefile: set docker build flags via environment variable 4f46069 (registry) - Makefile: set docker build flags via environment variable faf2eb2 (registry-token-refresher) - Makefile: set docker build flags via environment variable 4ca3a74 (router) - router: make default app configurable 5dba76c (router) - router: make server_token flag configurable cf87e27 (router) - Makefile: set docker build flags via environment variable 30d2caa (slugbuilder) - Makefile: set docker build flags via environment variable 3ef0a86 (workflow) Makefile: set docker build flags via environment variable 6307677 (workflow) charts: add optional persistence storage to influxdb and grafana (#699) 9b09080 (workflow-manager) - Makefile: set docker build flags via environment variable cc60fa0 (workflow-cli) Makefile: set docker build flags via environment variable 70797cb (workflow-e2e) limits-cmd: accept new limits:set value type Refactors \u00b6 7bb769f (dockerbuilder) - deploy.py: placate new flake8 linter checks 88f7007 (workflow) upgrading-workflow: use -w 0 flag when base64 encoding 3e65eba (workflow) quickstart: use markdown-include to de-duplicate quickstart info Fixes \u00b6 634bfe9 (builder) - charts: reference registry-proxy on 127.0.0.1 84b6342 (controller) - charts: pipeline time_zone value to quote func 3f860bf (controller) - Dockerfile: force gunzip of copyright archive e8f0284 (controller) - Makefile: build docker image with --no-cache by default bdb5acd (controller) - api: add certificate private key validator migration (#1199) da408b3 (controller) - charts: reference registry-proxy on 127.0.0.1 (#1239) f14a6db (dockerbuilder) - Dockerfile: fix gunzip -f c9f6e01 (postgres) - 001_setup_envdir.sh: inspect actual var instead of literal string 5aafbac (registry) - create-bucket: set BUCKET_NAME for swift 96f0c61 (router) - charts: remove deployment and service annotations 6d0d344 (slugbuilder) - download_buildpack: define name of buildpack 2817dbc (workflow) azure: use regular storage instead of premium 8691955 (workflow) azure/quickstart: fix Azure link in the menu 0d647e5 (workflow) applications: fixup --headers usage e6c9e23 (workflow) tuning-component-settings: move LDAP settings under Controller Documentation \u00b6 6cbd175 (builder) - *: Fix typo in README.md 7911fac (builder) - *: update main README.md 51879b2 (controller) - README: specify correct python version 1345f2c (controller) - README: update database usage in tests (#1233) 64eeff1 (logger) - README.md: update Deis Workflow reference 9bcbcfd (monitor) - README.md: update Deis Workflow reference 963c100 (nsq) - README.md: update Deis Workflow reference d9882fa (redis) - README.md: update Deis Workflow reference 9293f37 (workflow-cli) README: add latest stable release URL 16034cc (workflow) releases: omit obsolete requirement for a charts PR c61eedb (workflow) releases: move workflow docs release after changelog PR d430e42 (workflow) azure: streamline azure boot process a71c0da (workflow) installing-workflow: no periods in S3 bucket names 7cc8b2f (workflow) production-deployments: recommend disabling grafana signups a5f92eb (workflow) monitoring: document grafana and influxdb persistence (#713) c0410c6 (workflow) components: document the monitoring stack 4eea426 (workflow) Azure: remove service principal steps c65fae6 (workflow) Azure: note for kubernetes get-credentials a5d71e2 (workflow) Azure: Fix storage key and add note cccde15 (workflow) api/v2.3: add TLS API examples and index v2.3 API 5a37885 (workflow) managing-workflow: Add scaling the routers to the production deployment notes. c0285ed (workflow) aws: update for latest k8s version available Maintenance \u00b6 0ed0404 (builder) - Dockerfile: update deis/base to v0.3.6 d7f5ff0 (builder) - glide: bump golang.org/x/crypto to b822463 22106d2 (controller) - requirements: update Django to 1.10.5 1c12587 (controller) - Dockerfile: update deis/base to v0.3.6 (#1197) 4e45ef5 (controller) - requirements: update requests to 2.12.5 9faa4b2 (controller) - dev_requirements: update coverage to 4.3.4 4b7db76 (controller) - requirements: update pyldap to 2.4.28 d6b188d (dockerbuilder) - dev_requirements: upgrade flake8 to 3.2.1 82f77c3 (dockerbuilder) - Dockerfile: update deis/base to v0.3.6 40f647e (fluentd) - Dockerfile: update deis/base to v0.3.6 f7afeb7 (logger) - Dockerfile: update deis/base to v0.3.6 14342eb (minio) - Dockerfile: update deis/base to v0.3.6 8969f32 (monitor) - Dockerfile: update Grafana to 4.0.2 acb12e7 (monitor) - Dockerfile: update deis/base to v0.3.6 ca8a140 (monitor) - Dockerfile: update Influxdb to 1.1.1 287dd60 (monitor) - Dockerfile: update Influxdb to 1.1.1 7c3ca4b (nsq) - Dockerfile: update deis/base to v0.3.6 d04a77b (postgres) - Dockerfile: update deis/base to v0.3.6 9f2e1b1 (redis) - Dockerfile: update deis/base to v0.3.6 bb6bba4 (registry-token-refresher) - Dockerfile: update deis/base to v0.3.6 dfb2cae (router) - Dockerfile: update deis/base to v0.3.6 7638ca7 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v93 ac0192f (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v150 3f4ccc4 (slugbuilder) - buildpacks: update heroku-buildpack-python to v97 c40c6a0 (slugbuilder) - buildpacks: update heroku-buildpack-php to v117 2df92c0 (workflow) roadmap: update product roadmap 1d12348 (workflow) vagrant: update kubernetes release tarball to v1.5.1(workflow) f50916b (workflow-manager) - Dockerfile: update deis/base to v0.3.6 7960130 (workflow-cli) glide: update controller sdk to 9520b6c ba0d452 (workflow-e2e) glide: run glide up to get latest packages (#347)","title":"v2.11.0"},{"location":"changelogs/v2.11.0/#workflow-v2100-v2110","text":"","title":"Workflow v2.10.0 -&gt; v2.11.0"},{"location":"changelogs/v2.11.0/#releases","text":"builder v2.6.1 -> v2.7.1 controller v2.10.0 -> v2.11.0 dockerbuilder v2.5.2 -> v2.6.0 fluentd v2.6.0 -> v2.6.1 logger v2.4.1 -> v2.4.2 minio v2.3.4 -> v2.3.5 monitor v2.7.0 -> v2.7.1 nsq v2.2.5 -> v2.2.6 postgres v2.5.0 -> v2.5.1 redis v2.2.4 -> v2.2.5 registry v2.3.2 -> v2.3.3 registry-token-refresher v1.1.0 -> v1.1.1 router v2.8.1 -> v2.9.0 slugbuilder v2.4.8 -> v2.4.9 workflow v2.10.0 -> v2.11.0 workflow-cli v2.10.0 -> v2.11.0 workflow-e2e v2.8.0 -> v2.9.0 workflow-manager v2.4.4 -> v2.4.5","title":"Releases"},{"location":"changelogs/v2.11.0/#features","text":"bd97e3e (builder) - cleaner: delete from object store fcc5bb0 (builder) - Makefile: set docker build flags via environment variable ae03152 (controller) - settings: Get timezone from environment variable (#1196) 48cd872 (controller) - Makefile: set docker build flags via environment variable 003e8dd (dockerbuilder) - Makefile: set docker build flags via environment variable a1e28c8 (fluentd) - Makefile: set docker build flags via environment variable 8ce9845 (logger) - Makefile: set docker build flags via environment variable b2fc347 (minio) - Makefile: set docker build flags via environment variable bfdf091 (monitor) - charts: add optional persistence storage to influxdb and grafana 138fb11 (monitor) - charts: add optional persistence storage to influxdb and grafana c58fde6 (monitor) - Makefile: set docker build flags via environment variable b32fe54 (nsq) - Makefile: set docker build flags via environment variable 524fdf5 (postgres) - Makefile: set docker build flags via environment variable 0cf0deb (redis) - Makefile: set docker build flags via environment variable 4f46069 (registry) - Makefile: set docker build flags via environment variable faf2eb2 (registry-token-refresher) - Makefile: set docker build flags via environment variable 4ca3a74 (router) - router: make default app configurable 5dba76c (router) - router: make server_token flag configurable cf87e27 (router) - Makefile: set docker build flags via environment variable 30d2caa (slugbuilder) - Makefile: set docker build flags via environment variable 3ef0a86 (workflow) Makefile: set docker build flags via environment variable 6307677 (workflow) charts: add optional persistence storage to influxdb and grafana (#699) 9b09080 (workflow-manager) - Makefile: set docker build flags via environment variable cc60fa0 (workflow-cli) Makefile: set docker build flags via environment variable 70797cb (workflow-e2e) limits-cmd: accept new limits:set value type","title":"Features"},{"location":"changelogs/v2.11.0/#refactors","text":"7bb769f (dockerbuilder) - deploy.py: placate new flake8 linter checks 88f7007 (workflow) upgrading-workflow: use -w 0 flag when base64 encoding 3e65eba (workflow) quickstart: use markdown-include to de-duplicate quickstart info","title":"Refactors"},{"location":"changelogs/v2.11.0/#fixes","text":"634bfe9 (builder) - charts: reference registry-proxy on 127.0.0.1 84b6342 (controller) - charts: pipeline time_zone value to quote func 3f860bf (controller) - Dockerfile: force gunzip of copyright archive e8f0284 (controller) - Makefile: build docker image with --no-cache by default bdb5acd (controller) - api: add certificate private key validator migration (#1199) da408b3 (controller) - charts: reference registry-proxy on 127.0.0.1 (#1239) f14a6db (dockerbuilder) - Dockerfile: fix gunzip -f c9f6e01 (postgres) - 001_setup_envdir.sh: inspect actual var instead of literal string 5aafbac (registry) - create-bucket: set BUCKET_NAME for swift 96f0c61 (router) - charts: remove deployment and service annotations 6d0d344 (slugbuilder) - download_buildpack: define name of buildpack 2817dbc (workflow) azure: use regular storage instead of premium 8691955 (workflow) azure/quickstart: fix Azure link in the menu 0d647e5 (workflow) applications: fixup --headers usage e6c9e23 (workflow) tuning-component-settings: move LDAP settings under Controller","title":"Fixes"},{"location":"changelogs/v2.11.0/#documentation","text":"6cbd175 (builder) - *: Fix typo in README.md 7911fac (builder) - *: update main README.md 51879b2 (controller) - README: specify correct python version 1345f2c (controller) - README: update database usage in tests (#1233) 64eeff1 (logger) - README.md: update Deis Workflow reference 9bcbcfd (monitor) - README.md: update Deis Workflow reference 963c100 (nsq) - README.md: update Deis Workflow reference d9882fa (redis) - README.md: update Deis Workflow reference 9293f37 (workflow-cli) README: add latest stable release URL 16034cc (workflow) releases: omit obsolete requirement for a charts PR c61eedb (workflow) releases: move workflow docs release after changelog PR d430e42 (workflow) azure: streamline azure boot process a71c0da (workflow) installing-workflow: no periods in S3 bucket names 7cc8b2f (workflow) production-deployments: recommend disabling grafana signups a5f92eb (workflow) monitoring: document grafana and influxdb persistence (#713) c0410c6 (workflow) components: document the monitoring stack 4eea426 (workflow) Azure: remove service principal steps c65fae6 (workflow) Azure: note for kubernetes get-credentials a5d71e2 (workflow) Azure: Fix storage key and add note cccde15 (workflow) api/v2.3: add TLS API examples and index v2.3 API 5a37885 (workflow) managing-workflow: Add scaling the routers to the production deployment notes. c0285ed (workflow) aws: update for latest k8s version available","title":"Documentation"},{"location":"changelogs/v2.11.0/#maintenance","text":"0ed0404 (builder) - Dockerfile: update deis/base to v0.3.6 d7f5ff0 (builder) - glide: bump golang.org/x/crypto to b822463 22106d2 (controller) - requirements: update Django to 1.10.5 1c12587 (controller) - Dockerfile: update deis/base to v0.3.6 (#1197) 4e45ef5 (controller) - requirements: update requests to 2.12.5 9faa4b2 (controller) - dev_requirements: update coverage to 4.3.4 4b7db76 (controller) - requirements: update pyldap to 2.4.28 d6b188d (dockerbuilder) - dev_requirements: upgrade flake8 to 3.2.1 82f77c3 (dockerbuilder) - Dockerfile: update deis/base to v0.3.6 40f647e (fluentd) - Dockerfile: update deis/base to v0.3.6 f7afeb7 (logger) - Dockerfile: update deis/base to v0.3.6 14342eb (minio) - Dockerfile: update deis/base to v0.3.6 8969f32 (monitor) - Dockerfile: update Grafana to 4.0.2 acb12e7 (monitor) - Dockerfile: update deis/base to v0.3.6 ca8a140 (monitor) - Dockerfile: update Influxdb to 1.1.1 287dd60 (monitor) - Dockerfile: update Influxdb to 1.1.1 7c3ca4b (nsq) - Dockerfile: update deis/base to v0.3.6 d04a77b (postgres) - Dockerfile: update deis/base to v0.3.6 9f2e1b1 (redis) - Dockerfile: update deis/base to v0.3.6 bb6bba4 (registry-token-refresher) - Dockerfile: update deis/base to v0.3.6 dfb2cae (router) - Dockerfile: update deis/base to v0.3.6 7638ca7 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v93 ac0192f (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v150 3f4ccc4 (slugbuilder) - buildpacks: update heroku-buildpack-python to v97 c40c6a0 (slugbuilder) - buildpacks: update heroku-buildpack-php to v117 2df92c0 (workflow) roadmap: update product roadmap 1d12348 (workflow) vagrant: update kubernetes release tarball to v1.5.1(workflow) f50916b (workflow-manager) - Dockerfile: update deis/base to v0.3.6 7960130 (workflow-cli) glide: update controller sdk to 9520b6c ba0d452 (workflow-e2e) glide: run glide up to get latest packages (#347)","title":"Maintenance"},{"location":"changelogs/v2.12.0/","text":"Workflow v2.11.0 -> v2.12.0 \u00b6 Releases \u00b6 builder v2.7.1 -> v2.8.0 controller v2.11.0 -> v2.12.0 dockerbuilder v2.6.0 -> v2.7.1 fluentd v2.6.1 -> v2.7.0 monitor v2.7.1 -> v2.8.0 postgres v2.5.1 -> v2.5.2 registry v2.3.3 -> v2.3.4 router v2.9.0 -> v2.11.0 slugbuilder v2.4.9 -> v2.4.10 slugrunner v2.2.4 -> v2.3.0 workflow v2.11.0 -> v2.12.0 workflow-cli v2.11.0 -> v2.12.0 workflow-e2e v2.9.0 -> v2.10.0 Features \u00b6 b91c8a0 (builder) - gitreceive: add app envvars to DOCKER_BUILD_ARGS 357f9a1 (builder) - gitreceive: fix type of dockerBuildArgs 2c1316a (dockerbuilder) - deploy: support DOCKER_BUILD_ARGS envvar 0681d7e (dockerbuilder) - deploy: Use empty default if DOCKER_BUILD_ARGS env var is not set a3ed520 (fluentd) - elasticsearch: add support for \"reload_connections\" option 503ca0e (monitor) - grafana: allow user to install plugins 74449a6 (router) - charts: add resource requests to chart d241b74 (router) - proxyBuffers: Add app-level proxy buffer config options 2b9074f (router) - proxyBuffers: Set at global level; override at app level 98796f8 (slugrunner) - Makefile: set docker build flags via environment variable d3e0d74 (workflow-e2e) - tests: add config:set spec with dockerfile app Refactors \u00b6 3b7fcef (builder) - pkg: placate new go metalinter warnings 84753d2 (router) - charts: disable host_port/enabled by default 9ecea1f (workflow) - chart: remove upgrade-job.yaml (#748) f5e7199 (workflow) - router: disable router hostPort usage by default Fixes \u00b6 b3b1d20 (builder) - Dockerfile: force gunzip of license files e1e3452 (builder) - gitreceive/build.go: watch pods in the appropriate namespace 7f121a4 (builder) - .travis.yml: declare env vars on one line 98f50c5 (controller) - models/app: recreate proc types on switch from Dockerfile to buildpack 8480f69 (controller) - app.py: use current namespace instead of \"deis\" bfadce8 (controller) - charts: default registration mode to \"admin_only\" 13b2463 (dockerbuilder) - deploy: inject DOCKER_BUILD_ARGS into the Dockerfile 861100b (fluentd) - Dockerfile: force gunzip of license files 5188f77 (postgres) - create_bucket: avoid S3 InvalidLocationConstraint error 2ada84f (postgres) - .travis.yml: declare env vars on one line 86a30d7 (registry) - .travis.yml: declare env vars on one line a885078 (registry) - create-bucket: avoid S3 InvalidLocationConstraint error 5df84f1 (router) - Dockerfile: force gunzip of license files fa9c217 (router) - style: Apply mandatory formatting fixes f2d7ee5 (router) - .travis.yml: Make travis apply style checks 65b7487 (router) - charts: quote annotation values e7bb879 (workflow) - quickstart: fix kops typo 1c506d7 (workflow) - quickstart: update azure quickstart docs 7d63d07 (workflow) - charts: default registration mode to \"admin_only\" (#758) 02e9437 (workflow) - quickstart: prepend Azure envvars with AZURE_ 6f5d0ca (workflow) - aws/boot: don't overwrite kops with kubectl Documentation \u00b6 3e8ff74 (router) - README: Reflect newer install/hack/deploy processes 67d5d8b (workflow) - src/quickstart/provider/aws: Use kops instead of kube-up.sh for workflow clusters on AWs 2217993 (workflow) - src/quickstart/provider/aws: docs(src/quickstart/provider/aws) Changes from code review. 18d24d9 (workflow) - platform-monitoring.md: update grafana un/pw set instructions 5c16b82 (workflow) - src/quickstart/provider/aws: docs(src/quickstart/provider/aws) Changes from code review. ea8c7a6 (workflow) - src/quickstart/provider/aws: Changes from code review. e6d36a6 (workflow) - src/roadmap/releases.md: simplify docs in global changelog step (#722) 2511d0a (workflow) - managing-workflow: docs(managing-workflow) Document k8s annotation for AWS ELB idle timeout 427e49a (workflow) - tuning-component-settings: elaborate with practical examples (#749) df70aa5 (workflow) - installing: specify helm v2.1.3 as minimum everywhere Maintenance \u00b6 e7eafb9 (builder) - Makefile: update docker-go-dev to v0.22.0 f3e13b3 (builder) - glide: bump golang.org/x/crypto to 453249f e69a9a4 (controller) - requirements: update jmespath to 0.9.1 99c11d9 (controller) - requirements: update requests to 2.13.0 74d16af (controller) - requirements: update backoff library afbca0d (controller) - requirements: update jsonschema library 5174fea (controller) - dev_requirements: update flake8 linter library 96576dd (controller) - requirements: update django-auth-ldap to 1.2.9 8c8261d (controller) - requirements: update djangorestframework to 3.5.4 894a324 (controller) - requirements: update requests-toolbelt to 0.7.1 52a7650 (dockerbuilder) - dev_requirements: update flake8 linter library 6997f06 (dockerbuilder) - .travis.yml: update python to 3.5.x 23d2da2 (fluentd) - Dockerfile: update fluentd to 0.14.13 614fd40 (postgres) - Dockerfile: bump PG_VERSION to 9.4.11-1.pgdg16.04+1 46f6e1d (router) - Makefile: update docker-go-dev to v0.22.0 8de0045 (router) - nginx: update nginx to 1.11.9 1cde072 (router) - Makefile: Modernize dev/hack deployment f7a202e (router) - Makefile: Remove minimally useful clean targets abb7a8e (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v98 d255d7b (slugbuilder) - buildpacks: update heroku-buildpack-clojure to v76 97218ad (slugbuilder) - buildpacks: update heroku-buildpack-go to v60 1f35b41 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v21 327d2bb (slugbuilder) - buildpacks: update heroku-buildpack-java to v50 b3844cb (slugbuilder) - buildpacks: update heroku-buildpack-php to v119 e392787 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v153 0798cd6 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v75 6abe59d (slugbuilder) - buildpacks: update heroku-buildpack-go to v62 d453264 (slugbuilder) - buildpacks: update heroku-buildpack-java to v51 4d92580 (slugbuilder) - buildpacks: update heroku-buildpack-python to v99 ead5bbb (slugbuilder) - buildpacks: update heroku-buildpack-scala to v76 a8b2844 (slugbuilder) - buildpacks: update heroku-buildpack-php to v120 8aff8c6 (workflow-cli) - Dockerfile: update go-dev to v0.22.0","title":"v2.12.0"},{"location":"changelogs/v2.12.0/#workflow-v2110-v2120","text":"","title":"Workflow v2.11.0 -&gt; v2.12.0"},{"location":"changelogs/v2.12.0/#releases","text":"builder v2.7.1 -> v2.8.0 controller v2.11.0 -> v2.12.0 dockerbuilder v2.6.0 -> v2.7.1 fluentd v2.6.1 -> v2.7.0 monitor v2.7.1 -> v2.8.0 postgres v2.5.1 -> v2.5.2 registry v2.3.3 -> v2.3.4 router v2.9.0 -> v2.11.0 slugbuilder v2.4.9 -> v2.4.10 slugrunner v2.2.4 -> v2.3.0 workflow v2.11.0 -> v2.12.0 workflow-cli v2.11.0 -> v2.12.0 workflow-e2e v2.9.0 -> v2.10.0","title":"Releases"},{"location":"changelogs/v2.12.0/#features","text":"b91c8a0 (builder) - gitreceive: add app envvars to DOCKER_BUILD_ARGS 357f9a1 (builder) - gitreceive: fix type of dockerBuildArgs 2c1316a (dockerbuilder) - deploy: support DOCKER_BUILD_ARGS envvar 0681d7e (dockerbuilder) - deploy: Use empty default if DOCKER_BUILD_ARGS env var is not set a3ed520 (fluentd) - elasticsearch: add support for \"reload_connections\" option 503ca0e (monitor) - grafana: allow user to install plugins 74449a6 (router) - charts: add resource requests to chart d241b74 (router) - proxyBuffers: Add app-level proxy buffer config options 2b9074f (router) - proxyBuffers: Set at global level; override at app level 98796f8 (slugrunner) - Makefile: set docker build flags via environment variable d3e0d74 (workflow-e2e) - tests: add config:set spec with dockerfile app","title":"Features"},{"location":"changelogs/v2.12.0/#refactors","text":"3b7fcef (builder) - pkg: placate new go metalinter warnings 84753d2 (router) - charts: disable host_port/enabled by default 9ecea1f (workflow) - chart: remove upgrade-job.yaml (#748) f5e7199 (workflow) - router: disable router hostPort usage by default","title":"Refactors"},{"location":"changelogs/v2.12.0/#fixes","text":"b3b1d20 (builder) - Dockerfile: force gunzip of license files e1e3452 (builder) - gitreceive/build.go: watch pods in the appropriate namespace 7f121a4 (builder) - .travis.yml: declare env vars on one line 98f50c5 (controller) - models/app: recreate proc types on switch from Dockerfile to buildpack 8480f69 (controller) - app.py: use current namespace instead of \"deis\" bfadce8 (controller) - charts: default registration mode to \"admin_only\" 13b2463 (dockerbuilder) - deploy: inject DOCKER_BUILD_ARGS into the Dockerfile 861100b (fluentd) - Dockerfile: force gunzip of license files 5188f77 (postgres) - create_bucket: avoid S3 InvalidLocationConstraint error 2ada84f (postgres) - .travis.yml: declare env vars on one line 86a30d7 (registry) - .travis.yml: declare env vars on one line a885078 (registry) - create-bucket: avoid S3 InvalidLocationConstraint error 5df84f1 (router) - Dockerfile: force gunzip of license files fa9c217 (router) - style: Apply mandatory formatting fixes f2d7ee5 (router) - .travis.yml: Make travis apply style checks 65b7487 (router) - charts: quote annotation values e7bb879 (workflow) - quickstart: fix kops typo 1c506d7 (workflow) - quickstart: update azure quickstart docs 7d63d07 (workflow) - charts: default registration mode to \"admin_only\" (#758) 02e9437 (workflow) - quickstart: prepend Azure envvars with AZURE_ 6f5d0ca (workflow) - aws/boot: don't overwrite kops with kubectl","title":"Fixes"},{"location":"changelogs/v2.12.0/#documentation","text":"3e8ff74 (router) - README: Reflect newer install/hack/deploy processes 67d5d8b (workflow) - src/quickstart/provider/aws: Use kops instead of kube-up.sh for workflow clusters on AWs 2217993 (workflow) - src/quickstart/provider/aws: docs(src/quickstart/provider/aws) Changes from code review. 18d24d9 (workflow) - platform-monitoring.md: update grafana un/pw set instructions 5c16b82 (workflow) - src/quickstart/provider/aws: docs(src/quickstart/provider/aws) Changes from code review. ea8c7a6 (workflow) - src/quickstart/provider/aws: Changes from code review. e6d36a6 (workflow) - src/roadmap/releases.md: simplify docs in global changelog step (#722) 2511d0a (workflow) - managing-workflow: docs(managing-workflow) Document k8s annotation for AWS ELB idle timeout 427e49a (workflow) - tuning-component-settings: elaborate with practical examples (#749) df70aa5 (workflow) - installing: specify helm v2.1.3 as minimum everywhere","title":"Documentation"},{"location":"changelogs/v2.12.0/#maintenance","text":"e7eafb9 (builder) - Makefile: update docker-go-dev to v0.22.0 f3e13b3 (builder) - glide: bump golang.org/x/crypto to 453249f e69a9a4 (controller) - requirements: update jmespath to 0.9.1 99c11d9 (controller) - requirements: update requests to 2.13.0 74d16af (controller) - requirements: update backoff library afbca0d (controller) - requirements: update jsonschema library 5174fea (controller) - dev_requirements: update flake8 linter library 96576dd (controller) - requirements: update django-auth-ldap to 1.2.9 8c8261d (controller) - requirements: update djangorestframework to 3.5.4 894a324 (controller) - requirements: update requests-toolbelt to 0.7.1 52a7650 (dockerbuilder) - dev_requirements: update flake8 linter library 6997f06 (dockerbuilder) - .travis.yml: update python to 3.5.x 23d2da2 (fluentd) - Dockerfile: update fluentd to 0.14.13 614fd40 (postgres) - Dockerfile: bump PG_VERSION to 9.4.11-1.pgdg16.04+1 46f6e1d (router) - Makefile: update docker-go-dev to v0.22.0 8de0045 (router) - nginx: update nginx to 1.11.9 1cde072 (router) - Makefile: Modernize dev/hack deployment f7a202e (router) - Makefile: Remove minimally useful clean targets abb7a8e (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v98 d255d7b (slugbuilder) - buildpacks: update heroku-buildpack-clojure to v76 97218ad (slugbuilder) - buildpacks: update heroku-buildpack-go to v60 1f35b41 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v21 327d2bb (slugbuilder) - buildpacks: update heroku-buildpack-java to v50 b3844cb (slugbuilder) - buildpacks: update heroku-buildpack-php to v119 e392787 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v153 0798cd6 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v75 6abe59d (slugbuilder) - buildpacks: update heroku-buildpack-go to v62 d453264 (slugbuilder) - buildpacks: update heroku-buildpack-java to v51 4d92580 (slugbuilder) - buildpacks: update heroku-buildpack-python to v99 ead5bbb (slugbuilder) - buildpacks: update heroku-buildpack-scala to v76 a8b2844 (slugbuilder) - buildpacks: update heroku-buildpack-php to v120 8aff8c6 (workflow-cli) - Dockerfile: update go-dev to v0.22.0","title":"Maintenance"},{"location":"changelogs/v2.13.0/","text":"Workflow v2.12.0 -> v2.13.0 \u00b6 Releases \u00b6 builder v2.8.0 -> v2.10.1 controller v2.12.0 -> v2.13.0 dockerbuilder v2.7.1 -> v2.7.2 fluentd v2.7.0 -> v2.8.0 logger v2.4.2 -> v2.4.3 monitor v2.8.0 -> v2.8.1 nsq v2.2.6 -> v2.2.7 postgres v2.5.2 -> v2.5.3 registry v2.3.4 -> v2.4.0 registry-token-refresher v1.1.1 -> v1.1.2 router v2.11.0 -> v2.12.0 slugbuilder v2.4.10 -> v2.4.11 workflow v2.12.0 -> v2.13.0 workflow-cli v2.12.0 -> v2.13.0 workflow-e2e v2.10.0 -> v2.11.0 workflow-manager v2.4.5 -> v2.5.0 Features \u00b6 7d928d8 (builder) - podselector: add pod selector for builder job 67cfd5d (builder) - podselector: update charts bf9747d (builder) - podselector: update parameter format to match other annotation 01db893 (builder) - ingress: Experimental Native Ingress 50a1592 (controller) - config.py: Add ability to setup default tags 726a587 (controller) - ingress: Feature work for experimental native ingress 0e117b1 (controller) - api: allow app names up to 63 characters in length (#1198) 2e8ec75 (controller) - Makefile,rootfs: run unit and style tests in container a2bbd90 (dockerbuilder) - Makefile: run style tests in container 0325f2d (fluentd) - out_deis.rb: allow disabling deis logs and metrics to nsq 451c846 (nsq) - Makefile: add test target d39ea43 (registry) - Makefile: add test-style target a8c0fa7 (registry-proxy) - Makefile: set docker build flags via environment variable badc232 (router) - ingress: Experimental Native Ingress bbf8dee (router) - chart: add aws-specific idle timeout annotation to router service 9136b81 (router) - ingress: Experimental Native Ingress 23db7df (workflow) - controller: feat(controller) default tags 259a3f8 (workflow) - using_dockerfiles: document build args feature flag 2692d66 (workflow) - ingress: Experimental Native Ingress eb1c025 (workflow) - ingress: Support enable/disable conditions in Workflow chart 89982ee (workflow-cli) - cmd: add config:list --diff 3750f53 (workflow-e2e) - Makefile: add test target eaa74c7 (workflow-manager) - clusters: added versions API route endpoints (#107) Refactors \u00b6 e0765bf (builder) - ssh keys: remove support for DSA 641f70d (builder) - k8s_util: make users opt into DOCKER_BUILD_ARGS 807fe82 (controller) - utils: use python 3.5 asyncio keywords 3027766 (monitor) - ci: refactor monitor ci dc7c247 (nsq) - ci: remove manifests dir d5dd212 (workflow) - quickstart: swap out Vagrant with Minikube 50ec2a2 (workflow-e2e) - tests: update tests for new registration mode default Fixes \u00b6 9a2a1b4 (builder) - ingress: Adding newline to builder-service.yaml 56abf92 (builder) - gitreceive: fix checkForEnv logic 598f1a1 (builder) - gitreceive/config.go: correct envconfig typo 1ff9245 (builder) - builder: truncate slugbuilder and dockerbuilder pod name length 1156475 (controller) - serializers.py: update PROCTYPE_MATCH to disallow uppercase characters (#1261) a8002a2 (controller) - api: split command arguments by space if entrypoint is not /bin/bash -c (#1264) 2dce7cd (controller) - settings/production: convert \"false\" to boolean correctly 2569391 (logger) - log: fix panic error when building app log message a1e3fef (monitor) - telegraf: fix(telegraf) ensure off-cluster influxdb url is quoted 4ac5d56 (monitor) - influx, grafana: Add logic around pvc storage class 49a81f2 (monitor) - charts/monitor/values.yaml: add logger_redis_location key/value f36f1e9 (postgres) - contrib/ci/*: fix scripts 0d5ad68 (registry) - charts: Set sessionAffinity in registry service 6771695 (registry-token-refresher) - travis.yml: declare env vars on one line 5f33f36 (workflow) - managing-app-lifecycle: fix missing hyperlink 91e7f76 (workflow) - tuning-component-settings: convert toml to yaml e20215b (workflow) - ingress: Documentation touch ups dfdf7af (workflow-cli) - cmd: check for invalid probe types 140ded9 (workflow-e2e) - tests/auth: no interactive register for admin Documentation \u00b6 cd016e9 (controller) - api,scheduler: fix \"timeout\" typos 03a3e4c (monitor) - README.md: add build badge f0e1016 (nsq) - README.md: add build badge 3a99656 (workflow) - upgrading-workflow: mention helm repo update 916f200 (workflow) - builder-nodeselector: add BUILDER_POD_NODE_SELECTOR document 32a1493 (workflow) - builder-nodeselector: correct grammar fdf76e4 (workflow) - managing-app-processes.md: update proc type naming guidelines (#769) 3df978c (workflow) - managing-app-configuration: update \"kubernetes-probes\" link 722795b (workflow) - configuring-load-balancers.md: mention forthcoming default (#768) 8980c62 (workflow) - src/applications/inter-app-communication.md: docs(src/applications/inter-app-communication.md) Add first draft cc02dcd (workflow) - configuring-registry.md: add examples (#779) dc43777 (workflow) - installing-workflow/index.md: update get pods output (#777) Maintenance \u00b6 703c249 (controller) - requirements: update idna to 2.4 2224594 (controller) - requirements: update psycopg2 to 2.7 1aed9e2 (controller) - requirements: update jsonfield to 2.0.0 49ec35d (controller) - requirements: update Django to 1.10.6 8d6126a (controller) - requirements: update gunicorn to 19.7.0 2d071f4 (controller) - requirements: update idna to 2.5 53d34de (controller) - requirements: update jsonfield to 2.0.1 0274973 (controller) - rootfs/requirements.txt: add pyasn1 fcae228 (controller) - requirements: update django-auth-ldap to 1.2.10 74372a5 (controller) - requirements: update jmespath to 0.9.2 530256c (controller) - requirements: update djangorestframework to 3.6.2 f01b846 (controller) - requirements: update psycopg2 to 2.7.1 429a645 (controller) - requirements: update gunicorn to 19.7.1 0caeb81 (controller) - Makefile: remove broken \"test-unit-quick\" target e8e6f58 (controller) - dev_requirements: use deis/requests-mock fork 7713ff3 (postgres) - Makefile: remove test-unit target 66b9f1c (registry) - Dockerfile: bump registry to v2.6.0 a795d72 (router) - ingress: Experimental Native Ingress bece9d5 (router) - ingress: Experimental Native Ingress ea4a68c (router) - nginx: update nginx to 1.11.10 be3029c (slugbuilder) - buildpacks: update heroku-buildpack-python to v102 d802b84 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v155 17cddde (workflow) - ingress: Remove extra spaces 21fe9f9 (workflow) - ingress: Fix example usage in docs to match new YAML 33a6251 (workflow) - ingress: Fix typo 9f5bcea (workflow) - ingress: Revert to using if statements in router b8e404c (workflow) - ingress: Documentation updates from code review dcac309 (workflow) - ingress: Typo in experimental 5d4866d (workflow) - upgrade: Upgrade kops to 1.5.3 3e09799 (workflow-e2e) - README.md: update build status badge","title":"v2.13.0"},{"location":"changelogs/v2.13.0/#workflow-v2120-v2130","text":"","title":"Workflow v2.12.0 -&gt; v2.13.0"},{"location":"changelogs/v2.13.0/#releases","text":"builder v2.8.0 -> v2.10.1 controller v2.12.0 -> v2.13.0 dockerbuilder v2.7.1 -> v2.7.2 fluentd v2.7.0 -> v2.8.0 logger v2.4.2 -> v2.4.3 monitor v2.8.0 -> v2.8.1 nsq v2.2.6 -> v2.2.7 postgres v2.5.2 -> v2.5.3 registry v2.3.4 -> v2.4.0 registry-token-refresher v1.1.1 -> v1.1.2 router v2.11.0 -> v2.12.0 slugbuilder v2.4.10 -> v2.4.11 workflow v2.12.0 -> v2.13.0 workflow-cli v2.12.0 -> v2.13.0 workflow-e2e v2.10.0 -> v2.11.0 workflow-manager v2.4.5 -> v2.5.0","title":"Releases"},{"location":"changelogs/v2.13.0/#features","text":"7d928d8 (builder) - podselector: add pod selector for builder job 67cfd5d (builder) - podselector: update charts bf9747d (builder) - podselector: update parameter format to match other annotation 01db893 (builder) - ingress: Experimental Native Ingress 50a1592 (controller) - config.py: Add ability to setup default tags 726a587 (controller) - ingress: Feature work for experimental native ingress 0e117b1 (controller) - api: allow app names up to 63 characters in length (#1198) 2e8ec75 (controller) - Makefile,rootfs: run unit and style tests in container a2bbd90 (dockerbuilder) - Makefile: run style tests in container 0325f2d (fluentd) - out_deis.rb: allow disabling deis logs and metrics to nsq 451c846 (nsq) - Makefile: add test target d39ea43 (registry) - Makefile: add test-style target a8c0fa7 (registry-proxy) - Makefile: set docker build flags via environment variable badc232 (router) - ingress: Experimental Native Ingress bbf8dee (router) - chart: add aws-specific idle timeout annotation to router service 9136b81 (router) - ingress: Experimental Native Ingress 23db7df (workflow) - controller: feat(controller) default tags 259a3f8 (workflow) - using_dockerfiles: document build args feature flag 2692d66 (workflow) - ingress: Experimental Native Ingress eb1c025 (workflow) - ingress: Support enable/disable conditions in Workflow chart 89982ee (workflow-cli) - cmd: add config:list --diff 3750f53 (workflow-e2e) - Makefile: add test target eaa74c7 (workflow-manager) - clusters: added versions API route endpoints (#107)","title":"Features"},{"location":"changelogs/v2.13.0/#refactors","text":"e0765bf (builder) - ssh keys: remove support for DSA 641f70d (builder) - k8s_util: make users opt into DOCKER_BUILD_ARGS 807fe82 (controller) - utils: use python 3.5 asyncio keywords 3027766 (monitor) - ci: refactor monitor ci dc7c247 (nsq) - ci: remove manifests dir d5dd212 (workflow) - quickstart: swap out Vagrant with Minikube 50ec2a2 (workflow-e2e) - tests: update tests for new registration mode default","title":"Refactors"},{"location":"changelogs/v2.13.0/#fixes","text":"9a2a1b4 (builder) - ingress: Adding newline to builder-service.yaml 56abf92 (builder) - gitreceive: fix checkForEnv logic 598f1a1 (builder) - gitreceive/config.go: correct envconfig typo 1ff9245 (builder) - builder: truncate slugbuilder and dockerbuilder pod name length 1156475 (controller) - serializers.py: update PROCTYPE_MATCH to disallow uppercase characters (#1261) a8002a2 (controller) - api: split command arguments by space if entrypoint is not /bin/bash -c (#1264) 2dce7cd (controller) - settings/production: convert \"false\" to boolean correctly 2569391 (logger) - log: fix panic error when building app log message a1e3fef (monitor) - telegraf: fix(telegraf) ensure off-cluster influxdb url is quoted 4ac5d56 (monitor) - influx, grafana: Add logic around pvc storage class 49a81f2 (monitor) - charts/monitor/values.yaml: add logger_redis_location key/value f36f1e9 (postgres) - contrib/ci/*: fix scripts 0d5ad68 (registry) - charts: Set sessionAffinity in registry service 6771695 (registry-token-refresher) - travis.yml: declare env vars on one line 5f33f36 (workflow) - managing-app-lifecycle: fix missing hyperlink 91e7f76 (workflow) - tuning-component-settings: convert toml to yaml e20215b (workflow) - ingress: Documentation touch ups dfdf7af (workflow-cli) - cmd: check for invalid probe types 140ded9 (workflow-e2e) - tests/auth: no interactive register for admin","title":"Fixes"},{"location":"changelogs/v2.13.0/#documentation","text":"cd016e9 (controller) - api,scheduler: fix \"timeout\" typos 03a3e4c (monitor) - README.md: add build badge f0e1016 (nsq) - README.md: add build badge 3a99656 (workflow) - upgrading-workflow: mention helm repo update 916f200 (workflow) - builder-nodeselector: add BUILDER_POD_NODE_SELECTOR document 32a1493 (workflow) - builder-nodeselector: correct grammar fdf76e4 (workflow) - managing-app-processes.md: update proc type naming guidelines (#769) 3df978c (workflow) - managing-app-configuration: update \"kubernetes-probes\" link 722795b (workflow) - configuring-load-balancers.md: mention forthcoming default (#768) 8980c62 (workflow) - src/applications/inter-app-communication.md: docs(src/applications/inter-app-communication.md) Add first draft cc02dcd (workflow) - configuring-registry.md: add examples (#779) dc43777 (workflow) - installing-workflow/index.md: update get pods output (#777)","title":"Documentation"},{"location":"changelogs/v2.13.0/#maintenance","text":"703c249 (controller) - requirements: update idna to 2.4 2224594 (controller) - requirements: update psycopg2 to 2.7 1aed9e2 (controller) - requirements: update jsonfield to 2.0.0 49ec35d (controller) - requirements: update Django to 1.10.6 8d6126a (controller) - requirements: update gunicorn to 19.7.0 2d071f4 (controller) - requirements: update idna to 2.5 53d34de (controller) - requirements: update jsonfield to 2.0.1 0274973 (controller) - rootfs/requirements.txt: add pyasn1 fcae228 (controller) - requirements: update django-auth-ldap to 1.2.10 74372a5 (controller) - requirements: update jmespath to 0.9.2 530256c (controller) - requirements: update djangorestframework to 3.6.2 f01b846 (controller) - requirements: update psycopg2 to 2.7.1 429a645 (controller) - requirements: update gunicorn to 19.7.1 0caeb81 (controller) - Makefile: remove broken \"test-unit-quick\" target e8e6f58 (controller) - dev_requirements: use deis/requests-mock fork 7713ff3 (postgres) - Makefile: remove test-unit target 66b9f1c (registry) - Dockerfile: bump registry to v2.6.0 a795d72 (router) - ingress: Experimental Native Ingress bece9d5 (router) - ingress: Experimental Native Ingress ea4a68c (router) - nginx: update nginx to 1.11.10 be3029c (slugbuilder) - buildpacks: update heroku-buildpack-python to v102 d802b84 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v155 17cddde (workflow) - ingress: Remove extra spaces 21fe9f9 (workflow) - ingress: Fix example usage in docs to match new YAML 33a6251 (workflow) - ingress: Fix typo 9f5bcea (workflow) - ingress: Revert to using if statements in router b8e404c (workflow) - ingress: Documentation updates from code review dcac309 (workflow) - ingress: Typo in experimental 5d4866d (workflow) - upgrade: Upgrade kops to 1.5.3 3e09799 (workflow-e2e) - README.md: update build status badge","title":"Maintenance"},{"location":"changelogs/v2.14.0/","text":"Workflow v2.13.0 -> v2.14.0 \u00b6 Releases \u00b6 controller v2.13.0 -> v2.14.0 fluentd v2.8.0 -> v2.9.0 monitor v2.8.1 -> v2.9.0 redis v2.2.5 -> v2.2.6 registry-proxy v1.1.1 -> v1.3.0 router v2.12.0 -> v2.12.1 slugbuilder v2.4.11 -> v2.4.12 workflow v2.13.0 -> v2.14.0 workflow-cli v2.13.0 -> v2.14.0 workflow-e2e v2.10.0 -> v2.11.0 Features \u00b6 c515df3 (fluentd) - chart: Extend values.yaml file af04466 (monitor) - grafana: Allow users to set signup flag in chart a8c0fa7 (registry-proxy) - Makefile: set docker build flags via environment variable 292a3d4 (workflow) - ingress: document deis-builder DNS records 3750f53 (workflow-e2e) - Makefile: add test target Refactors \u00b6 08f4c69 (controller) - ci: remove travis, update build status (#1287) 59cce25 (fluentd) - README: update link to deis graphic 6b7d85a (fluentd) - makefile: Update makefile to work with new chart structure d59bedc (fluentd) - ci: remove _scripts; add badge 0fcea4f (monitor) - _scripts: remove unused scripts 511fa8c (redis) - README: switch to wabs container 5c7624c (redis) - ci: remove travis; add badge cea7734 (router) - ci: remove travis; add badge e8de27c (slugbuilder) - ci: remove travis; update badge bd0b1d9 (workflow) - azure/boot: export AZURE_DNS_PREFIX and use $HOME 8526e49 (workflow) - ci: rm travis and unused scripts (#803) 008615a (workflow-cli) - Jenkinsfile: disable win agent 50ec2a2 (workflow-e2e) - tests: update tests for new registration mode default Fixes \u00b6 960e899 (controller) - ingress-test: Fixing make test-style a9674a3 (fluentd) - charts: fix(charts) add quote around daemon_environment value 73effea (monitor) - telegraf/rootfs/start-telegraf: address shellcheck/style err 76134f7 (redis) - rootfs/Dockerfile: force gunzip of copyright archive e559768 (router) - charts: remove b64enc from dhparam 05866f6 (workflow) - hostname: Fixing hostname line 140ded9 (workflow-e2e) - tests/auth: no interactive register for admin Documentation \u00b6 32cd737 (controller) - api: update doc pointers for Django 1.11 7d2c0ba (controller) - README: remove old testing prerequisites addf549 (workflow) - gke/boot: Add info on obtaining credentials 29a86b0 (workflow) - system-requirements: warn users away from broken k8s versions 8c223b5 (workflow) - platform-logging: Add section on custom fluentd plugins 218985f (workflow) - monitoring: Update docs to reflect monitor chart changes Maintenance \u00b6 1f93f21 (controller) - requirements: update Django to 1.11 LTS 88846bf (controller) - requirements: update pytz to 2017.2 99061ff (controller) - requirements: update django-guardian to v1.4.8 49e741e (controller) - ingress: Adding unit tests 88bfcbd (controller) - requirements: update pyOpenSSL to v17.0.0 7a9c3e6 (controller) - dev_requirements: update codecov to v2.0.9 8ed937d (controller) - requirements: update django-auth-ldap to v1.2.11 51ac827 (controller) - requirements: update backoff library to v1.4.2 b8560e0 (router) - Dockerfile: update nginx to 1.11.13 21aa475 (router) - Dockerfile: update nginx to 1.12.0 stable 2f7705c (router) - Dockerfile: update nginx to 1.13.0 4a802e4 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v101 fb567ac (slugbuilder) - buildpacks: update heroku-buildpack-go to v64 3c14ac2 (slugbuilder) - buildpacks: update heroku-buildpack-php to v121 32de3c1 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v159 3e09799 (workflow-e2e) - README.md: update build status badge","title":"v2.14.0"},{"location":"changelogs/v2.14.0/#workflow-v2130-v2140","text":"","title":"Workflow v2.13.0 -&gt; v2.14.0"},{"location":"changelogs/v2.14.0/#releases","text":"controller v2.13.0 -> v2.14.0 fluentd v2.8.0 -> v2.9.0 monitor v2.8.1 -> v2.9.0 redis v2.2.5 -> v2.2.6 registry-proxy v1.1.1 -> v1.3.0 router v2.12.0 -> v2.12.1 slugbuilder v2.4.11 -> v2.4.12 workflow v2.13.0 -> v2.14.0 workflow-cli v2.13.0 -> v2.14.0 workflow-e2e v2.10.0 -> v2.11.0","title":"Releases"},{"location":"changelogs/v2.14.0/#features","text":"c515df3 (fluentd) - chart: Extend values.yaml file af04466 (monitor) - grafana: Allow users to set signup flag in chart a8c0fa7 (registry-proxy) - Makefile: set docker build flags via environment variable 292a3d4 (workflow) - ingress: document deis-builder DNS records 3750f53 (workflow-e2e) - Makefile: add test target","title":"Features"},{"location":"changelogs/v2.14.0/#refactors","text":"08f4c69 (controller) - ci: remove travis, update build status (#1287) 59cce25 (fluentd) - README: update link to deis graphic 6b7d85a (fluentd) - makefile: Update makefile to work with new chart structure d59bedc (fluentd) - ci: remove _scripts; add badge 0fcea4f (monitor) - _scripts: remove unused scripts 511fa8c (redis) - README: switch to wabs container 5c7624c (redis) - ci: remove travis; add badge cea7734 (router) - ci: remove travis; add badge e8de27c (slugbuilder) - ci: remove travis; update badge bd0b1d9 (workflow) - azure/boot: export AZURE_DNS_PREFIX and use $HOME 8526e49 (workflow) - ci: rm travis and unused scripts (#803) 008615a (workflow-cli) - Jenkinsfile: disable win agent 50ec2a2 (workflow-e2e) - tests: update tests for new registration mode default","title":"Refactors"},{"location":"changelogs/v2.14.0/#fixes","text":"960e899 (controller) - ingress-test: Fixing make test-style a9674a3 (fluentd) - charts: fix(charts) add quote around daemon_environment value 73effea (monitor) - telegraf/rootfs/start-telegraf: address shellcheck/style err 76134f7 (redis) - rootfs/Dockerfile: force gunzip of copyright archive e559768 (router) - charts: remove b64enc from dhparam 05866f6 (workflow) - hostname: Fixing hostname line 140ded9 (workflow-e2e) - tests/auth: no interactive register for admin","title":"Fixes"},{"location":"changelogs/v2.14.0/#documentation","text":"32cd737 (controller) - api: update doc pointers for Django 1.11 7d2c0ba (controller) - README: remove old testing prerequisites addf549 (workflow) - gke/boot: Add info on obtaining credentials 29a86b0 (workflow) - system-requirements: warn users away from broken k8s versions 8c223b5 (workflow) - platform-logging: Add section on custom fluentd plugins 218985f (workflow) - monitoring: Update docs to reflect monitor chart changes","title":"Documentation"},{"location":"changelogs/v2.14.0/#maintenance","text":"1f93f21 (controller) - requirements: update Django to 1.11 LTS 88846bf (controller) - requirements: update pytz to 2017.2 99061ff (controller) - requirements: update django-guardian to v1.4.8 49e741e (controller) - ingress: Adding unit tests 88bfcbd (controller) - requirements: update pyOpenSSL to v17.0.0 7a9c3e6 (controller) - dev_requirements: update codecov to v2.0.9 8ed937d (controller) - requirements: update django-auth-ldap to v1.2.11 51ac827 (controller) - requirements: update backoff library to v1.4.2 b8560e0 (router) - Dockerfile: update nginx to 1.11.13 21aa475 (router) - Dockerfile: update nginx to 1.12.0 stable 2f7705c (router) - Dockerfile: update nginx to 1.13.0 4a802e4 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v101 fb567ac (slugbuilder) - buildpacks: update heroku-buildpack-go to v64 3c14ac2 (slugbuilder) - buildpacks: update heroku-buildpack-php to v121 32de3c1 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v159 3e09799 (workflow-e2e) - README.md: update build status badge","title":"Maintenance"},{"location":"changelogs/v2.15.0/","text":"Workflow v2.14.0 -> v2.15.0 \u00b6 Releases \u00b6 builder v2.10.1 -> v2.11.0 controller v2.14.0 -> v2.15.0 dockerbuilder v2.7.2 -> v2.7.3 fluentd v2.9.0 -> v2.10.0 logger v2.4.3 -> v2.4.4 minio v2.3.5 -> v2.3.6 monitor v2.9.0 -> v2.10.0 nsq v2.2.7 -> v2.2.8 postgres v2.5.3 -> v2.5.4 redis v2.2.6 -> v2.2.7 registry v2.4.0 -> v2.4.2 registry-token-refresher v1.1.2 -> v1.1.3 router v2.12.1 -> v2.13.0 slugbuilder v2.4.12 -> v2.4.14 slugrunner v2.3.0 -> v2.3.1 workflow v2.14.0 -> v2.15.0 workflow-cli v2.14.0 -> v2.15.0 workflow-e2e v2.11.1 -> v2.12.0 workflow-manager v2.5.0 -> v2.5.1 Features \u00b6 c891804 (builder) - RBAC support c321669 (controller) - RBAC support 464bbd9 (fluentd) - RBAC support 560b73d (fluentd) - fluentd: add gelf plugin e655622 (fluentd) - charts: add rollingUpdate functionality ff4058d (monitor) - RBAC support de49c15 (monitor) - charts: add rollingUpdate functionality to telegraf daemonset ccf1364 (monitor) - deploy.mk: Add deploy.mk for using the chart to upgrade/install monitor c9769fe (router) - RBAC support 356374f (workflow) - RBAC support f9c6a4a (workflow-e2e) - chart: use upstream stable/spotify-docker-gc chart Refactors \u00b6 270f168 (builder) - ci: remove travis, update build status f832ba3 (builder) - LICENSE: switch to MIT license 9af9322 (controller) - LICENSE: switch to MIT license 86e3a4a (dockerbuilder) - ci: remove travis; update badge 6eb4387 (dockerbuilder) - LICENSE: switch to MIT license 502d8b2 (fluentd) - LICENSE: switch to MIT license 8e70aab (logger) - README: update link to deis graphic c54e4b4 (logger) - ci: remove travis; update badge 5ec9e6f (logger) - LICENSE: switch to MIT license 40bfd95 (minio) - ci: remove travis; update badge d9ba730 (minio) - LICENSE: switch to MIT license cf5c393 (monitor) - LICENSE: switch to MIT license 9655620 (nsq) - README: update deis graphic link 71f9cc9 (nsq) - LICENSE: switch to MIT license fc7d7a3 (postgres) - ci: remove travis; update badge e751af6 (postgres) - LICENSE: switch to MIT license 2cec33f (redis) - LICENSE: switch to MIT license a6894de (registry) - ci: remove travis; update badge fdfeb9b (registry) - LICENSE: switch to MIT license d494abf (registry-token-refresher) - ci: remove travis; update badge fe75c0d (registry-token-refresher) - LICENSE: switch to MIT license 093863f (router) - LICENSE: switch to MIT license a54877d (slugbuilder) - LICENSE: switch to MIT license ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license ffcd9b3 (workflow) - LICENSE: switch to MIT license a861b5e (workflow-cli) - LICENSE: switch to MIT license 34d4a68 (workflow-manager) - LICENSE: switch to MIT license Fixes \u00b6 ab68699 (monitor) - telegraf/Dockerfile: Update telegraf download to 1.3.0 35551af (postgres) - Dockerfile: pin azure-storage to version wal-e currently lusing 067e622 (registry) - boto: don't set AWS env vars when they're empty 2dddbe1 (workflow-cli) - .gitignore: ignore .DS_Store droppings Documentation \u00b6 7cc5a82 (router) - README: update charts link/reference Maintenance \u00b6 b4fe99e (controller) - requirements: update Django to v1.11.1 47a9583 (controller) - requirements: update DRF to v3.6.3 d869595 (controller) - requirements: update pyldap to v2.4.35 ac7baf2 (controller) - requirements: update requests to v2.14.2 d183306 (controller) - requirements: update requests-toolbelt to 0.8.0 989fe33 (controller) - requirements: update django-auth-ldap to v1.2.12 35ed09f (postgres) - Dockerfile: bump postgres-9.4 version, update azure storage import f0db059 (slugbuilder) - buildpacks: update heroku-buildpack-go to v65 ddeb83c (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v104 d957649 (slugbuilder) - buildpacks: update heroku-buildpack-python to v103 2cb83f2 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v163 6575cb0 (workflow) - remove the services url navigation 5cd8648 (workflow-e2e) - Dockerfile: bump k8s version","title":"v2.15.0"},{"location":"changelogs/v2.15.0/#workflow-v2140-v2150","text":"","title":"Workflow v2.14.0 -&gt; v2.15.0"},{"location":"changelogs/v2.15.0/#releases","text":"builder v2.10.1 -> v2.11.0 controller v2.14.0 -> v2.15.0 dockerbuilder v2.7.2 -> v2.7.3 fluentd v2.9.0 -> v2.10.0 logger v2.4.3 -> v2.4.4 minio v2.3.5 -> v2.3.6 monitor v2.9.0 -> v2.10.0 nsq v2.2.7 -> v2.2.8 postgres v2.5.3 -> v2.5.4 redis v2.2.6 -> v2.2.7 registry v2.4.0 -> v2.4.2 registry-token-refresher v1.1.2 -> v1.1.3 router v2.12.1 -> v2.13.0 slugbuilder v2.4.12 -> v2.4.14 slugrunner v2.3.0 -> v2.3.1 workflow v2.14.0 -> v2.15.0 workflow-cli v2.14.0 -> v2.15.0 workflow-e2e v2.11.1 -> v2.12.0 workflow-manager v2.5.0 -> v2.5.1","title":"Releases"},{"location":"changelogs/v2.15.0/#features","text":"c891804 (builder) - RBAC support c321669 (controller) - RBAC support 464bbd9 (fluentd) - RBAC support 560b73d (fluentd) - fluentd: add gelf plugin e655622 (fluentd) - charts: add rollingUpdate functionality ff4058d (monitor) - RBAC support de49c15 (monitor) - charts: add rollingUpdate functionality to telegraf daemonset ccf1364 (monitor) - deploy.mk: Add deploy.mk for using the chart to upgrade/install monitor c9769fe (router) - RBAC support 356374f (workflow) - RBAC support f9c6a4a (workflow-e2e) - chart: use upstream stable/spotify-docker-gc chart","title":"Features"},{"location":"changelogs/v2.15.0/#refactors","text":"270f168 (builder) - ci: remove travis, update build status f832ba3 (builder) - LICENSE: switch to MIT license 9af9322 (controller) - LICENSE: switch to MIT license 86e3a4a (dockerbuilder) - ci: remove travis; update badge 6eb4387 (dockerbuilder) - LICENSE: switch to MIT license 502d8b2 (fluentd) - LICENSE: switch to MIT license 8e70aab (logger) - README: update link to deis graphic c54e4b4 (logger) - ci: remove travis; update badge 5ec9e6f (logger) - LICENSE: switch to MIT license 40bfd95 (minio) - ci: remove travis; update badge d9ba730 (minio) - LICENSE: switch to MIT license cf5c393 (monitor) - LICENSE: switch to MIT license 9655620 (nsq) - README: update deis graphic link 71f9cc9 (nsq) - LICENSE: switch to MIT license fc7d7a3 (postgres) - ci: remove travis; update badge e751af6 (postgres) - LICENSE: switch to MIT license 2cec33f (redis) - LICENSE: switch to MIT license a6894de (registry) - ci: remove travis; update badge fdfeb9b (registry) - LICENSE: switch to MIT license d494abf (registry-token-refresher) - ci: remove travis; update badge fe75c0d (registry-token-refresher) - LICENSE: switch to MIT license 093863f (router) - LICENSE: switch to MIT license a54877d (slugbuilder) - LICENSE: switch to MIT license ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license ffcd9b3 (workflow) - LICENSE: switch to MIT license a861b5e (workflow-cli) - LICENSE: switch to MIT license 34d4a68 (workflow-manager) - LICENSE: switch to MIT license","title":"Refactors"},{"location":"changelogs/v2.15.0/#fixes","text":"ab68699 (monitor) - telegraf/Dockerfile: Update telegraf download to 1.3.0 35551af (postgres) - Dockerfile: pin azure-storage to version wal-e currently lusing 067e622 (registry) - boto: don't set AWS env vars when they're empty 2dddbe1 (workflow-cli) - .gitignore: ignore .DS_Store droppings","title":"Fixes"},{"location":"changelogs/v2.15.0/#documentation","text":"7cc5a82 (router) - README: update charts link/reference","title":"Documentation"},{"location":"changelogs/v2.15.0/#maintenance","text":"b4fe99e (controller) - requirements: update Django to v1.11.1 47a9583 (controller) - requirements: update DRF to v3.6.3 d869595 (controller) - requirements: update pyldap to v2.4.35 ac7baf2 (controller) - requirements: update requests to v2.14.2 d183306 (controller) - requirements: update requests-toolbelt to 0.8.0 989fe33 (controller) - requirements: update django-auth-ldap to v1.2.12 35ed09f (postgres) - Dockerfile: bump postgres-9.4 version, update azure storage import f0db059 (slugbuilder) - buildpacks: update heroku-buildpack-go to v65 ddeb83c (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v104 d957649 (slugbuilder) - buildpacks: update heroku-buildpack-python to v103 2cb83f2 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v163 6575cb0 (workflow) - remove the services url navigation 5cd8648 (workflow-e2e) - Dockerfile: bump k8s version","title":"Maintenance"},{"location":"changelogs/v2.16.0/","text":"Workflow v2.15.0 -> v2.16.0 \u00b6 Releases \u00b6 builder v2.11.0 -> v2.12.0 controller v2.15.0 -> v2.16.0 monitor v2.10.0 -> v2.10.1 slugrunner v2.3.0 -> v2.3.1 workflow v2.15.0 -> v2.16.0 workflow-cli v2.15.0 -> v2.16.0 workflow-e2e v2.11.1 -> v2.12.0 Features \u00b6 46002f4 (workflow-cli) - cmd: Support Base64 encoded SSH_KEY 88397a1 (workflow-cli) - cmd: test SSH_KEY mangling in ConfigSet f9c6a4a (workflow-e2e) - chart: use upstream stable/spotify-docker-gc chart Refactors \u00b6 ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license 345d5ae (workflow) - mkdocs.yml: alphabetize cloud providers in quickstart Fixes \u00b6 73f844b *: Remove RC4 based ciphers. 344b43e *: Fix linter issues c81dbf9 (controller) - controller: Persist ssl.enforce header on service creation 1f5e242 (workflow-cli) - cmd: fix(cmd) Fix proctype regex for setting limits f82cf83 (workflow-cli) - cmd: fix(cmd) Fix proctype regex for scaling Documentation \u00b6 25329be (workflow) - quickstart: update Azure ACS installation steps 4cfa9d5 (workflow) - *: rm no longer needed pipe to sed (#817) 5145f12 (workflow) - configuring-registry.md: add setup instructions for acr (#818) b456870 (workflow) - installing-workflow: helm init upgrade note (#819) 61a5cca (workflow) - chart-provenance.md: fix chart repo name (#830) 2a7f756 (workflow) - *: specify Helm v2.5.0 or later ef4bc3e (workflow) - *: updates/changelog for v2.16.0 release Maintenance \u00b6 c2fd577 (controller) - requirements: update Django to v1.11.2 fe6e6e5 (controller) - requirements: update pyldap to v2.4.35.1 cac5e60 (controller) - requirements: update jmespath to 0.9.3 1fcf61b (controller) - requirements: update backoff to 1.4.3 410e1d3 (controller) - requirements: update Django to v1.11.3 516a529 (monitor) - Dockerfile: update Grafana to 4.3.2 5cd8648 (workflow-e2e) - Dockerfile: bump k8s version","title":"v2.16.0"},{"location":"changelogs/v2.16.0/#workflow-v2150-v2160","text":"","title":"Workflow v2.15.0 -&gt; v2.16.0"},{"location":"changelogs/v2.16.0/#releases","text":"builder v2.11.0 -> v2.12.0 controller v2.15.0 -> v2.16.0 monitor v2.10.0 -> v2.10.1 slugrunner v2.3.0 -> v2.3.1 workflow v2.15.0 -> v2.16.0 workflow-cli v2.15.0 -> v2.16.0 workflow-e2e v2.11.1 -> v2.12.0","title":"Releases"},{"location":"changelogs/v2.16.0/#features","text":"46002f4 (workflow-cli) - cmd: Support Base64 encoded SSH_KEY 88397a1 (workflow-cli) - cmd: test SSH_KEY mangling in ConfigSet f9c6a4a (workflow-e2e) - chart: use upstream stable/spotify-docker-gc chart","title":"Features"},{"location":"changelogs/v2.16.0/#refactors","text":"ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license 345d5ae (workflow) - mkdocs.yml: alphabetize cloud providers in quickstart","title":"Refactors"},{"location":"changelogs/v2.16.0/#fixes","text":"73f844b *: Remove RC4 based ciphers. 344b43e *: Fix linter issues c81dbf9 (controller) - controller: Persist ssl.enforce header on service creation 1f5e242 (workflow-cli) - cmd: fix(cmd) Fix proctype regex for setting limits f82cf83 (workflow-cli) - cmd: fix(cmd) Fix proctype regex for scaling","title":"Fixes"},{"location":"changelogs/v2.16.0/#documentation","text":"25329be (workflow) - quickstart: update Azure ACS installation steps 4cfa9d5 (workflow) - *: rm no longer needed pipe to sed (#817) 5145f12 (workflow) - configuring-registry.md: add setup instructions for acr (#818) b456870 (workflow) - installing-workflow: helm init upgrade note (#819) 61a5cca (workflow) - chart-provenance.md: fix chart repo name (#830) 2a7f756 (workflow) - *: specify Helm v2.5.0 or later ef4bc3e (workflow) - *: updates/changelog for v2.16.0 release","title":"Documentation"},{"location":"changelogs/v2.16.0/#maintenance","text":"c2fd577 (controller) - requirements: update Django to v1.11.2 fe6e6e5 (controller) - requirements: update pyldap to v2.4.35.1 cac5e60 (controller) - requirements: update jmespath to 0.9.3 1fcf61b (controller) - requirements: update backoff to 1.4.3 410e1d3 (controller) - requirements: update Django to v1.11.3 516a529 (monitor) - Dockerfile: update Grafana to 4.3.2 5cd8648 (workflow-e2e) - Dockerfile: bump k8s version","title":"Maintenance"},{"location":"changelogs/v2.17.0/","text":"Workflow v2.16.0 -> v2.17.0 \u00b6 Releases \u00b6 controller v2.16.0 -> v2.17.1 router v2.13.0 -> v2.13.1 slugbuilder v2.4.14 -> v2.5.0 slugrunner v2.3.0 -> v2.4.0 workflow v2.16.0 -> v2.17.0 workflow-cli v2.16.0 -> v2.17.0 workflow-e2e v2.12.0 -> v2.12.1 Features \u00b6 4e0c17c (slugbuilder) - normalize_storage: use MINIO_BUCKET env-var 92ef1b7 (slugrunner) - get_object: use MINIO_BUCKET env-var Refactors \u00b6 ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license Fixes \u00b6 c02eb51 (controller) - api/models/app: Catch unhandled error (#1317) d5c70f4 (workflow-e2e) - apps_test.go: temporarily disable spec that fails on GKE Documentation \u00b6 f40f3cf (workflow) - changelogs: add builder release and workflow commit 5c83dd2 (workflow) - managing-app-processes: Fix 404 for HPA algorithm link (#846) Maintenance \u00b6 435aa2b (controller) - requirements: update django-auth-ldap to 1.2.14 76b1233 (controller) - requirements: update pyldap to 2.4.37 c17ad2c (controller) - requirements: update django-jsonfield to 2.0.2 732d4f4 (controller) - requirements: update django-guardian to 1.4.9 f914d98 (controller) - requirements: update pyOpenSSL to 17.2.0 48b1be1 (controller) - requirements: update requests to 2.18.2 b79a32a (controller) - dev_requirements: update coverage lib to 4.4.1 efefc5f (router) - Dockerfile: update nginx to 1.13.3 c1364b3 (slugbuilder) - buildpacks: update heroku-buildpack-go to v70 cb073da (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v22 f82db90 (slugbuilder) - buildpacks: update heroku-buildpack-java to v52 c260552 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v106 c4b586b (slugbuilder) - buildpacks: update heroku-buildpack-python to v109 ef63934 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v164 6ef590c (slugbuilder) - buildpacks: update heroku-buildpack-clojure to v77 3f3e4b9 (slugbuilder) - buildpacks: update heroku-buildpack-go to v71 8ded076 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v23 04a1649 (slugbuilder) - buildpacks: update heroku-buildpack-java to v53 22e02d2 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v110 e5ffff7 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v167 1e3f424 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v77","title":"v2.17.0"},{"location":"changelogs/v2.17.0/#workflow-v2160-v2170","text":"","title":"Workflow v2.16.0 -&gt; v2.17.0"},{"location":"changelogs/v2.17.0/#releases","text":"controller v2.16.0 -> v2.17.1 router v2.13.0 -> v2.13.1 slugbuilder v2.4.14 -> v2.5.0 slugrunner v2.3.0 -> v2.4.0 workflow v2.16.0 -> v2.17.0 workflow-cli v2.16.0 -> v2.17.0 workflow-e2e v2.12.0 -> v2.12.1","title":"Releases"},{"location":"changelogs/v2.17.0/#features","text":"4e0c17c (slugbuilder) - normalize_storage: use MINIO_BUCKET env-var 92ef1b7 (slugrunner) - get_object: use MINIO_BUCKET env-var","title":"Features"},{"location":"changelogs/v2.17.0/#refactors","text":"ce0e082 (slugrunner) - ci: remove travis; update badge 7e85553 (slugrunner) - LICENSE: switch to MIT license","title":"Refactors"},{"location":"changelogs/v2.17.0/#fixes","text":"c02eb51 (controller) - api/models/app: Catch unhandled error (#1317) d5c70f4 (workflow-e2e) - apps_test.go: temporarily disable spec that fails on GKE","title":"Fixes"},{"location":"changelogs/v2.17.0/#documentation","text":"f40f3cf (workflow) - changelogs: add builder release and workflow commit 5c83dd2 (workflow) - managing-app-processes: Fix 404 for HPA algorithm link (#846)","title":"Documentation"},{"location":"changelogs/v2.17.0/#maintenance","text":"435aa2b (controller) - requirements: update django-auth-ldap to 1.2.14 76b1233 (controller) - requirements: update pyldap to 2.4.37 c17ad2c (controller) - requirements: update django-jsonfield to 2.0.2 732d4f4 (controller) - requirements: update django-guardian to 1.4.9 f914d98 (controller) - requirements: update pyOpenSSL to 17.2.0 48b1be1 (controller) - requirements: update requests to 2.18.2 b79a32a (controller) - dev_requirements: update coverage lib to 4.4.1 efefc5f (router) - Dockerfile: update nginx to 1.13.3 c1364b3 (slugbuilder) - buildpacks: update heroku-buildpack-go to v70 cb073da (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v22 f82db90 (slugbuilder) - buildpacks: update heroku-buildpack-java to v52 c260552 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v106 c4b586b (slugbuilder) - buildpacks: update heroku-buildpack-python to v109 ef63934 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v164 6ef590c (slugbuilder) - buildpacks: update heroku-buildpack-clojure to v77 3f3e4b9 (slugbuilder) - buildpacks: update heroku-buildpack-go to v71 8ded076 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v23 04a1649 (slugbuilder) - buildpacks: update heroku-buildpack-java to v53 22e02d2 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v110 e5ffff7 (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v167 1e3f424 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v77","title":"Maintenance"},{"location":"changelogs/v2.2.0/","text":"Workflow v2.1.0 -> v2.2.0 \u00b6 Features \u00b6 b59bbbc (fluentd) - fluentd: Adding sumologic plugin support 424523c (logger) - storage: Add redis storage adapter 2da72a5 (logger) - redis: Optimize with more aggresive pipelining 0c82466 (logger) - storage: Make redis the default storage adapter 2f92eca (monitor) - telegraf, grafana: Start collecting redis metrics c9718e4 (charts) - logger: Add redis instance for use by logger 7d40069 (charts) - swift: add support for swift storage d6992e1 (charts) - telegraf: Configure telegraf to start fetching redis metrics 0ae9d90 (workflow-cli) - deis: add deis shortcuts command 2862f05 (workflow-cli) - colors: reserve magenta for controller log messages (#132) 8a61e63 (controller) - scheduler: add support for set based requirement filtering via the kubernetes API 47b5b08 (controller) - IDN: add support for international domains 32be50a (controller) - scheduler: sort env vars and secrets by keys for easier hashing c3c2494 (controller) - add Deployments support behind a feature flag edb0383 (controller) - scheduler: feat(scheduler) prepend [namespace] to Scheduler log message for better traceability 84b8080 (controller) - app: make deploy timeout configurable globally/per-app via DEIS_DEPLOY_TIMEOUT, default is 2 minutes Fixes \u00b6 65f8714 (dockerbuilder) - objectstore: set properly builder bucket file environment variable 9179923 (dockerbuilder) - deploy.py: handle chunked output errors 02112ed (dockerbuilder) - deploy.py: delay so stderr is logged before pod exits 93b9c5c (logger) - redis: Pass style checks 7144c4e (logger) - rc: Specify use of redis storage adapter 9dae9cc (monitor) - telegraf: Create nsq topic at startup a9b2275 (monitor) - telegraf: Update image default image tag in manifests 8fd5ada (monitor) - grafana: Fix blank dashboards from appearing in dropdown 7de06cc (monitor) - grafana: Redis cpu graph was not selecting right data 0492bf8 (charts) - database: Fix logic for selecting off-cluster db 6fd8407 (charts) - logger: Do not helm keep rc deis-logger-redis c425baf (workflow-cli) - ps: restarting a single pod created by Deployments was not working bcb8b01 (workflow-cli) - ps: give ps:restart a better understanding between RC and Deployment pods 4b2c6d4 (workflow-cli) - scale: dont call controller if there is no valid scale pattern 32177aa (workflow-cli) - settings: don't panic on empty settings file (#134) 6214d96 (controller) - scheduler: if one RC fails to scale then ensure all other RCs are at the right level 0bcea13 (controller) - scale: return error message in proper format 7d24923 (controller) - restart: wait for the pods to be scheduled 7647569 (controller) - scheduler: cast port to an int from environment (#857) b27c816 (controller) - boot: change group ownership of docker socket to deis (#804) d4415c9 (controller) - api: fail when rolling back to v1 (#762) 1ac6b54 (controller) - release: return port from get_port for non-routable process types a0567ea (controller) - api: remove command escaping from v1 (#822) f403efb (controller) - tests: sort domains in tests to get past occasional ordering problems which cause test failures Documentation \u00b6 dd2b505 (workflow) - logging,monitoring: Update platform-logging and monitoring docs with recent changes dfb6c8e (workflow) - install-workflow: note that k8s 1.2.x is required aa40a49 (workflow) - swift: Add swift as an object storage 3e7e865 (workflow) - deployments: add Deployments documentation ee03d28 (workflow) - apps: document DEIS_DEPLOY_TIMEOUT and the nuances around that Maintenance \u00b6 5c289c4 (slugbuilder) - buildpacks: update heroku-buildpack-go to v42 d5cdd0b (slugbuilder) - buildpacks: update heroku-buildpack-php to v108 85c8292 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v91 165105f (slugbuilder) - buildpacks: update heroku-buildpack-python to v81 9bbed87 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v71","title":"v2.2.0"},{"location":"changelogs/v2.2.0/#workflow-v210-v220","text":"","title":"Workflow v2.1.0 -&gt; v2.2.0"},{"location":"changelogs/v2.2.0/#features","text":"b59bbbc (fluentd) - fluentd: Adding sumologic plugin support 424523c (logger) - storage: Add redis storage adapter 2da72a5 (logger) - redis: Optimize with more aggresive pipelining 0c82466 (logger) - storage: Make redis the default storage adapter 2f92eca (monitor) - telegraf, grafana: Start collecting redis metrics c9718e4 (charts) - logger: Add redis instance for use by logger 7d40069 (charts) - swift: add support for swift storage d6992e1 (charts) - telegraf: Configure telegraf to start fetching redis metrics 0ae9d90 (workflow-cli) - deis: add deis shortcuts command 2862f05 (workflow-cli) - colors: reserve magenta for controller log messages (#132) 8a61e63 (controller) - scheduler: add support for set based requirement filtering via the kubernetes API 47b5b08 (controller) - IDN: add support for international domains 32be50a (controller) - scheduler: sort env vars and secrets by keys for easier hashing c3c2494 (controller) - add Deployments support behind a feature flag edb0383 (controller) - scheduler: feat(scheduler) prepend [namespace] to Scheduler log message for better traceability 84b8080 (controller) - app: make deploy timeout configurable globally/per-app via DEIS_DEPLOY_TIMEOUT, default is 2 minutes","title":"Features"},{"location":"changelogs/v2.2.0/#fixes","text":"65f8714 (dockerbuilder) - objectstore: set properly builder bucket file environment variable 9179923 (dockerbuilder) - deploy.py: handle chunked output errors 02112ed (dockerbuilder) - deploy.py: delay so stderr is logged before pod exits 93b9c5c (logger) - redis: Pass style checks 7144c4e (logger) - rc: Specify use of redis storage adapter 9dae9cc (monitor) - telegraf: Create nsq topic at startup a9b2275 (monitor) - telegraf: Update image default image tag in manifests 8fd5ada (monitor) - grafana: Fix blank dashboards from appearing in dropdown 7de06cc (monitor) - grafana: Redis cpu graph was not selecting right data 0492bf8 (charts) - database: Fix logic for selecting off-cluster db 6fd8407 (charts) - logger: Do not helm keep rc deis-logger-redis c425baf (workflow-cli) - ps: restarting a single pod created by Deployments was not working bcb8b01 (workflow-cli) - ps: give ps:restart a better understanding between RC and Deployment pods 4b2c6d4 (workflow-cli) - scale: dont call controller if there is no valid scale pattern 32177aa (workflow-cli) - settings: don't panic on empty settings file (#134) 6214d96 (controller) - scheduler: if one RC fails to scale then ensure all other RCs are at the right level 0bcea13 (controller) - scale: return error message in proper format 7d24923 (controller) - restart: wait for the pods to be scheduled 7647569 (controller) - scheduler: cast port to an int from environment (#857) b27c816 (controller) - boot: change group ownership of docker socket to deis (#804) d4415c9 (controller) - api: fail when rolling back to v1 (#762) 1ac6b54 (controller) - release: return port from get_port for non-routable process types a0567ea (controller) - api: remove command escaping from v1 (#822) f403efb (controller) - tests: sort domains in tests to get past occasional ordering problems which cause test failures","title":"Fixes"},{"location":"changelogs/v2.2.0/#documentation","text":"dd2b505 (workflow) - logging,monitoring: Update platform-logging and monitoring docs with recent changes dfb6c8e (workflow) - install-workflow: note that k8s 1.2.x is required aa40a49 (workflow) - swift: Add swift as an object storage 3e7e865 (workflow) - deployments: add Deployments documentation ee03d28 (workflow) - apps: document DEIS_DEPLOY_TIMEOUT and the nuances around that","title":"Documentation"},{"location":"changelogs/v2.2.0/#maintenance","text":"5c289c4 (slugbuilder) - buildpacks: update heroku-buildpack-go to v42 d5cdd0b (slugbuilder) - buildpacks: update heroku-buildpack-php to v108 85c8292 (slugbuilder) - buildpacks: update heroku-buildpack-nodejs to v91 165105f (slugbuilder) - buildpacks: update heroku-buildpack-python to v81 9bbed87 (slugbuilder) - buildpacks: update heroku-buildpack-scala to v71","title":"Maintenance"},{"location":"changelogs/v2.3.0/","text":"Workflow v2.2.0 -> v2.3.0 \u00b6 Features \u00b6 7fbeb3f router: move deis-router to use Deployments 69831ed workflow-manager: move deis-workflow-manager to use Deployments 31cbcc9 registry: move deis-registry to use Deployments 4173034 controller: move deis-controller to use Deployments 106e022 builder: move deis-builder to use Deployments 1692748 test: add TEST env variable to workflow e2e chart 78e77cb workflow-dev: re-introduce registry-proxy 38c80bb registry: Add support for private registry 79a26ec *: add helm-keep to all Deployments, like router already has ed96f15 makefile: add deploy command to deploy image to k8s (#396) a849301 makefile: add formating and linting tests (#394) 2f5642a registry: Add support for external registry ecfcea6 api: added auth/whoami endpoint (#737) ba12d09 boot: background the loading of DB data into Kubernetes 63c8f4d app: during ps:restart run pod delete in parallel ccf988b apps: scale / deploy run all process types in parallel instead of sequantially 7473e16 regsitry: Add support for private registry 76ea246 IDN: add support for international domains 7003286 Dockerfile: verify nginx pgp key (#219) 1f652ae builder: add pre-compile/post-compile hooks 827a411 builder: inject ENV_DIR into the environment 4e49625 auth: basic auth for /v3/doctor/{id} API endpoint (#88) 84206b2 deis doctor includes lots of k8s data a8e23b6 registry: Add docs for configuring private registry 540c4ec update: update docs to reflect v2.3.0 5615bb4 ci: send emails to slack on e2e failure (#133) 6e2954d shortcuts: add shortcuts test f59bb66 Jenkinsfile: no retry prompt if master 8168ea1 cmd: add auth:whoami --all 5e78fc4 Jenkinsfile: override 'sh' to add colorized output fb6ed28 Jenkinsfile: get actual PR commit, if PR 1199b9e ci: add codecov (#146) caf1fd0 git: add more flags to the git command (#141) Fixes \u00b6 93098d6 registry: registry token refresher shouldn't be uninstalled when using in-cluster e0e5712 k8s_util: proxy registry host/port information to dockerbuilder 766d73a release: old release shouldn't be deleted if new release fails cf16d56 scheduler: only get logs for run pods when possible a2c00ed app: round the log message wait time using bankers rounding 4f9efb0 pull: release and build should be deleted on failed deis pull e36f796 registry: User should be able to pull the image from internal registry e99b852 boot: show a warning instead of error if a Deployment is in progress when Deis Workflow is starting up 02d9bb2 scheduler: check if an event stream was returned before pop()ing it ffef759 scheduler: lower case CPU limits and upper case first char in Memory limits for Kubernetes 17a0ef0 registry: catch docker timeouts and show a nicer error 1d24ed6 registry: Use proper hostname for dockerhub images 418eef7 registry: Add unit tests a4d58d8 validation: success threshold can only be equal to one when setting liveness probe. Error properly d7c4632 models: add more sensible ordering to various API responses f3bbc11 app: add verbose_name to App model due to a DRF 3.4.1 fix a044e94 scale: return a 404 instead of 400 when scale uses a proc type that does not exist 6d6a10e middleware: remove unused server side version check (#937) bab3632 controller: only load latest config 8de5f6c secret: handle the secret value if it is None 614feb7 deploy.py: remove insecure-registry requirement 38f839a rootfs: check if recovery.conf is present 920afe5 router: BodySize config can be \"0\" 152680b builder: remove CACHE_DIR from /bin/release 6aa120a jobs: run periodic jobs once at start time (#89) 7fd06ce quickstart: fix link to buildpack documentation e8dd0b5 releases: remove old milestone step 89e4177 tests: set owner of files created by containers to the local user (#151) c655ea0 test-style: make fmt fail style-test and fix existing formatting errors (#135) f94b05f CI: don't allow untrusted commands when uploading (#154) 9d52c27 git: fix linting error (#159) 1f412af CI: False doesn't abort build (#158) 8c843a6 CI: add false to retry loop (#162) Documentation \u00b6 ed7c6de PR Template: switch from refs to requires as per new syntax dc4e0ba README: add debian installation instructions (#837) feef1e4 dockerfiles: Add Bash to requirements list of Dockerfile/image a3bd63b dockerfiles: Re-word bash requirement annotation e7a25b5 applications: reword deployments description 1cc7347 applications: add pre-compile/post-compile hook docs 2a63431 configuring-postgres: fix typo (of -> or) 835c9f3 applications: fix up grammar under \"Compile Hooks\" 3cbe544 roadmap: rewrite for new release process cb8c8d1 installing-workflow: remove insecure-registry documentation 9404953 reference: add /v2/auth/whoami endpoint e28bc0f releases: add deisrel command to query released components 85d34d5 applications: explain how to add user ssh key a3c749b installing: add k8s 1.3.4+ as supported 272a8af releases: paste CHANGELOG into tag annotation e4065f7 release: restore seed-repo milestone step e84fb14 releases: tag workflow-* repositories d637f06 styles: remove light shadow from doc text links Maintenance \u00b6 a327912 *: remove old charts that reference pre 2.0.0 release c82f3eb workflow-v2.3.0: Release workflow and workflow-e2e version 2.3.0 c102d81 Makefile: update docker-go-dev to 0.14.0 (#393) c4c00bc requirements: update requests-toolbelt to 0.7.0 122d2de requirements: update ndg-httpsclient to 0.4.2 b606adb requirements: update Django REST Framework to 3.4.0 2196b58 requirements: update Django to 1.9.8 f530e2b requirements: update to docker-py 1.9.0 c19cdfc dev_requirements: update coverage lib to 4.2.0 745d6d0 requirements: Update to DRF 3.4.1 72f0df8 requirements: move from django-cors-headers to django-cors-middleware f6bfbeb api: bump API version to v2.2.0 58a837a Dockerfile: update pip to 8.1.2 a948381 *: update docker-go-dev and switch to using new linter (#220) a5e8416 english language: upgrade != total uninstall cc4f07e *: upgrade docker-go-dev and use new linter (#155) 87820c4 glide: update controller-sdk-go","title":"v2.3.0"},{"location":"changelogs/v2.3.0/#workflow-v220-v230","text":"","title":"Workflow v2.2.0 -&gt; v2.3.0"},{"location":"changelogs/v2.3.0/#features","text":"7fbeb3f router: move deis-router to use Deployments 69831ed workflow-manager: move deis-workflow-manager to use Deployments 31cbcc9 registry: move deis-registry to use Deployments 4173034 controller: move deis-controller to use Deployments 106e022 builder: move deis-builder to use Deployments 1692748 test: add TEST env variable to workflow e2e chart 78e77cb workflow-dev: re-introduce registry-proxy 38c80bb registry: Add support for private registry 79a26ec *: add helm-keep to all Deployments, like router already has ed96f15 makefile: add deploy command to deploy image to k8s (#396) a849301 makefile: add formating and linting tests (#394) 2f5642a registry: Add support for external registry ecfcea6 api: added auth/whoami endpoint (#737) ba12d09 boot: background the loading of DB data into Kubernetes 63c8f4d app: during ps:restart run pod delete in parallel ccf988b apps: scale / deploy run all process types in parallel instead of sequantially 7473e16 regsitry: Add support for private registry 76ea246 IDN: add support for international domains 7003286 Dockerfile: verify nginx pgp key (#219) 1f652ae builder: add pre-compile/post-compile hooks 827a411 builder: inject ENV_DIR into the environment 4e49625 auth: basic auth for /v3/doctor/{id} API endpoint (#88) 84206b2 deis doctor includes lots of k8s data a8e23b6 registry: Add docs for configuring private registry 540c4ec update: update docs to reflect v2.3.0 5615bb4 ci: send emails to slack on e2e failure (#133) 6e2954d shortcuts: add shortcuts test f59bb66 Jenkinsfile: no retry prompt if master 8168ea1 cmd: add auth:whoami --all 5e78fc4 Jenkinsfile: override 'sh' to add colorized output fb6ed28 Jenkinsfile: get actual PR commit, if PR 1199b9e ci: add codecov (#146) caf1fd0 git: add more flags to the git command (#141)","title":"Features"},{"location":"changelogs/v2.3.0/#fixes","text":"93098d6 registry: registry token refresher shouldn't be uninstalled when using in-cluster e0e5712 k8s_util: proxy registry host/port information to dockerbuilder 766d73a release: old release shouldn't be deleted if new release fails cf16d56 scheduler: only get logs for run pods when possible a2c00ed app: round the log message wait time using bankers rounding 4f9efb0 pull: release and build should be deleted on failed deis pull e36f796 registry: User should be able to pull the image from internal registry e99b852 boot: show a warning instead of error if a Deployment is in progress when Deis Workflow is starting up 02d9bb2 scheduler: check if an event stream was returned before pop()ing it ffef759 scheduler: lower case CPU limits and upper case first char in Memory limits for Kubernetes 17a0ef0 registry: catch docker timeouts and show a nicer error 1d24ed6 registry: Use proper hostname for dockerhub images 418eef7 registry: Add unit tests a4d58d8 validation: success threshold can only be equal to one when setting liveness probe. Error properly d7c4632 models: add more sensible ordering to various API responses f3bbc11 app: add verbose_name to App model due to a DRF 3.4.1 fix a044e94 scale: return a 404 instead of 400 when scale uses a proc type that does not exist 6d6a10e middleware: remove unused server side version check (#937) bab3632 controller: only load latest config 8de5f6c secret: handle the secret value if it is None 614feb7 deploy.py: remove insecure-registry requirement 38f839a rootfs: check if recovery.conf is present 920afe5 router: BodySize config can be \"0\" 152680b builder: remove CACHE_DIR from /bin/release 6aa120a jobs: run periodic jobs once at start time (#89) 7fd06ce quickstart: fix link to buildpack documentation e8dd0b5 releases: remove old milestone step 89e4177 tests: set owner of files created by containers to the local user (#151) c655ea0 test-style: make fmt fail style-test and fix existing formatting errors (#135) f94b05f CI: don't allow untrusted commands when uploading (#154) 9d52c27 git: fix linting error (#159) 1f412af CI: False doesn't abort build (#158) 8c843a6 CI: add false to retry loop (#162)","title":"Fixes"},{"location":"changelogs/v2.3.0/#documentation","text":"ed7c6de PR Template: switch from refs to requires as per new syntax dc4e0ba README: add debian installation instructions (#837) feef1e4 dockerfiles: Add Bash to requirements list of Dockerfile/image a3bd63b dockerfiles: Re-word bash requirement annotation e7a25b5 applications: reword deployments description 1cc7347 applications: add pre-compile/post-compile hook docs 2a63431 configuring-postgres: fix typo (of -> or) 835c9f3 applications: fix up grammar under \"Compile Hooks\" 3cbe544 roadmap: rewrite for new release process cb8c8d1 installing-workflow: remove insecure-registry documentation 9404953 reference: add /v2/auth/whoami endpoint e28bc0f releases: add deisrel command to query released components 85d34d5 applications: explain how to add user ssh key a3c749b installing: add k8s 1.3.4+ as supported 272a8af releases: paste CHANGELOG into tag annotation e4065f7 release: restore seed-repo milestone step e84fb14 releases: tag workflow-* repositories d637f06 styles: remove light shadow from doc text links","title":"Documentation"},{"location":"changelogs/v2.3.0/#maintenance","text":"a327912 *: remove old charts that reference pre 2.0.0 release c82f3eb workflow-v2.3.0: Release workflow and workflow-e2e version 2.3.0 c102d81 Makefile: update docker-go-dev to 0.14.0 (#393) c4c00bc requirements: update requests-toolbelt to 0.7.0 122d2de requirements: update ndg-httpsclient to 0.4.2 b606adb requirements: update Django REST Framework to 3.4.0 2196b58 requirements: update Django to 1.9.8 f530e2b requirements: update to docker-py 1.9.0 c19cdfc dev_requirements: update coverage lib to 4.2.0 745d6d0 requirements: Update to DRF 3.4.1 72f0df8 requirements: move from django-cors-headers to django-cors-middleware f6bfbeb api: bump API version to v2.2.0 58a837a Dockerfile: update pip to 8.1.2 a948381 *: update docker-go-dev and switch to using new linter (#220) a5e8416 english language: upgrade != total uninstall cc4f07e *: upgrade docker-go-dev and use new linter (#155) 87820c4 glide: update controller-sdk-go","title":"Maintenance"},{"location":"changelogs/v2.4.0/","text":"Workflow v2.3.0 -> v2.4.0 \u00b6 Builder v2.3.0 -> v2.4.0 \u00b6 Features \u00b6 e292969 *: switch to using controller-sdk-go for controller interactions (#402) Fixes \u00b6 d340772 pod: log pod error status and message instead of pod struct 0690f89 _tests: remove out of date functional tests (#406) e791c1d gitreceive: change target name to Workflow Controller v2.3.1 -> v2.4.0 \u00b6 Features \u00b6 a7cff7e models: add routable flag to Config (#934) cebd736 scheduler: add scheduler tests that do not go through normal api tests (#965) 2a41942 healthcheck: Add support to create healthcheck per proctype Requires workflow-cli#160 3e988ea model: Add new model to store settings Fixes \u00b6 54f0f75 app: adjust async for better usage and to account for asyncio bug 855bb59 scheduler: create application config (env secrets) outside of deploy / scale to reduce k8s thrasing 996be37 mock: mock scheduler could not gracefully handle the concurrent deploy / scale 7da5212 run: return a 400 if command is empty (#952) c91f361 passwd: raise 400 when password is not a parameter (#850) 544f492 scheduler: in scheduler::run check if pod state is an object or a string before acing on it (#957) a4ee5a8 health: Add healthchecks only for routable apps or proctypes 37ea65c Makefile: add deis namespace to make deploy (#969) 7f19c48 scheduler: make app un-routable (#974) 6cfeba0 scheduler: when user asks for limits beyond their allowance then error out faster (#975) 7a152a6 scheduler: allow Deployment \"in progress\" to be bypassed in case of errors or timeout (#978) bf82529 registry: retry pull/push/tag 3 times - should help with slow networks and slow registries (#979) Documentation \u00b6 cc6617e README.md: add postgresql prereq Maintenance \u00b6 e0a3f02 requirements: Django REST Framework 3.4.3 77dbf94 travis: cache pip in travis runs (#944) b66948d requirements: requests update to 2.11.0 (#962) 6e6d257 requirements: update to django-guardian 1.4.5 (#964) 87a92f6 requirements: update backoff 1.3.1 (#963) c6e3eb3 migrations: create a migration for various alterations that do not touch schema (#967) a16aa8c requirements: Update Django REST Framework to 3.4.4 (#976) Database v2.2.1 -> v2.2.2 \u00b6 Maintenance \u00b6 022f2c5 Update the postgres version Dockerbuilder v2.3.0 -> v2.3.1 \u00b6 Maintenance \u00b6 31065a3 Dockerfile: update deis/base to 0.3.0 Monitoring v2.2.0 -> v2.3.0 \u00b6 Features \u00b6 527d4dd dashboards: create dashboards for all deis components Fixes \u00b6 3b15224 ini: a stray quote was causing INI parsing to break a21e7e4 start-grafana: Create dashboard directory when starting grafana Documentation \u00b6 2548941 readme: Provide a configuration section in grafana readme Router v2.3.0 -> v2.4.0 \u00b6 Features \u00b6 01cf487 *: Update nginx to 1.11.2 571dfea router: Get the annotations from the deployment object instead of RC 59e753c maintenance: Add support for maintenance mode for apps Fixes \u00b6 1769d2d model: Improve regex for SSL ciphers e085023 routable: Use correct label key for routable c00da10 model: Specify a default ssl cipher list Documentation \u00b6 7cbf93e readme: Clarify that routable services must expose port 80 Maintenance \u00b6 541b19b .gitignore: Update to ignore deis-router-deployment.tmp.yaml Slugbuilder v2.3.0 -> v2.3.1 \u00b6 Maintenance \u00b6 815d0a7 buildpacks: update heroku-buildpack-go to v44 7b34cb5 buildpacks: update heroku-buildpack-scala to v72 f647afe buildpacks: update php buildpack Workflow CLI v2.3.0 -> v2.4.0 \u00b6 Features \u00b6 f37432b Jenkinsfile: send COMPONENT_REPO param to e2e job dfe19e0 logging: extract logging to its own package and write tests (#166) 7b4c48d cmd: add deis routing 37cdb52 healthcheck: Add support for healthcheck per proctype 4df89d2 maintenance: Add support for maintenance mode for apps 7a9ebf4 Jenkinsfile: wipe vendor dir if bootstrap fails 47def28 Makefile: add git branch and sha information to the uploaded blob 2103657 *: allow configuration flag (#169) Fixes \u00b6 6745e75 version: move all version logic to git (#167) 4f2d342 healthcheck: Don't fail if there is no healthcheck for a proctype ba9d5d7 CI: don't cache latest binaries (#175) 36df5d4 CI: delete artifacts when cleaning up (#179) Workflow Documentation v2.3.0 -> v2.4.0 \u00b6 Features \u00b6 af7cf12 healthcheck: Add docs for applying healthchecks per proctype d84c0a1 troubleshooting: add troubleshooting applications 7477ae7 docs: add documentation for limits 4ea0719 CLI: document new behavior of variable (#440) c41f71e maintenance: Add docs for maintenance mode support Fixes \u00b6 fde9a81 installing: Add configuring registry docs to doc tree 4480831 applications: use admonition styling d097233 user: supply a kubectl patch function to simplify registration mode setting Documentation \u00b6 fb9db75 applications: add deis routing docs 12fd1d7 registration: update registration for 2.3 behavior (#448) 8d271ca upgrading: expand and clarify workflow upgrade instructions (#447) 5fdf2da storage: cleanup storage docs (#454) Maintenance \u00b6 88167c5 roadmap: update roadmap for 2.x (#417) 8befc2a docs: update docs to reflect fixed issue (#455) Workflow E2E Tests v2.3.0 -> v2.4.0 \u00b6 Features \u00b6 6f76da5 procfile: create a build with a procfile 94a884a skip: make procfile test pending 09c1c33 tests: add deis routing e2e tests (#304) Fixes \u00b6 7e0d1cc CLI: log cli version after installing to check revision (#284) 47a6907 deployments: proc type regex changed due to Deployments b22274e limits: ask for 500m instead of 1024 cores in the limits CPU test 2cd045a Makefile: add retrying to workflow CLI download a56611c docker-test-integration: show curl errors (#311) 807d110 auth: update to new missing config error message (#301) Maintenance \u00b6 ce08b1c travis: Remove .travis.yml Workflow Manager v2.3.1 -> v2.4.0 \u00b6 Fixes \u00b6 7d859f5 feature(data): add deployments, daemonsets to cluster data (#95) 31fe3bc cluster_id is vulnerable to race condition when called concurrently (#94) 2582640 bug(k8s): unintentional variable shadowing (#92)","title":"v2.4.0"},{"location":"changelogs/v2.4.0/#workflow-v230-v240","text":"","title":"Workflow v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#builder-v230-v240","text":"","title":"Builder v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features","text":"e292969 *: switch to using controller-sdk-go for controller interactions (#402)","title":"Features"},{"location":"changelogs/v2.4.0/#fixes","text":"d340772 pod: log pod error status and message instead of pod struct 0690f89 _tests: remove out of date functional tests (#406) e791c1d gitreceive: change target name to Workflow","title":"Fixes"},{"location":"changelogs/v2.4.0/#controller-v231-v240","text":"","title":"Controller v2.3.1 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features_1","text":"a7cff7e models: add routable flag to Config (#934) cebd736 scheduler: add scheduler tests that do not go through normal api tests (#965) 2a41942 healthcheck: Add support to create healthcheck per proctype Requires workflow-cli#160 3e988ea model: Add new model to store settings","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_1","text":"54f0f75 app: adjust async for better usage and to account for asyncio bug 855bb59 scheduler: create application config (env secrets) outside of deploy / scale to reduce k8s thrasing 996be37 mock: mock scheduler could not gracefully handle the concurrent deploy / scale 7da5212 run: return a 400 if command is empty (#952) c91f361 passwd: raise 400 when password is not a parameter (#850) 544f492 scheduler: in scheduler::run check if pod state is an object or a string before acing on it (#957) a4ee5a8 health: Add healthchecks only for routable apps or proctypes 37ea65c Makefile: add deis namespace to make deploy (#969) 7f19c48 scheduler: make app un-routable (#974) 6cfeba0 scheduler: when user asks for limits beyond their allowance then error out faster (#975) 7a152a6 scheduler: allow Deployment \"in progress\" to be bypassed in case of errors or timeout (#978) bf82529 registry: retry pull/push/tag 3 times - should help with slow networks and slow registries (#979)","title":"Fixes"},{"location":"changelogs/v2.4.0/#documentation","text":"cc6617e README.md: add postgresql prereq","title":"Documentation"},{"location":"changelogs/v2.4.0/#maintenance","text":"e0a3f02 requirements: Django REST Framework 3.4.3 77dbf94 travis: cache pip in travis runs (#944) b66948d requirements: requests update to 2.11.0 (#962) 6e6d257 requirements: update to django-guardian 1.4.5 (#964) 87a92f6 requirements: update backoff 1.3.1 (#963) c6e3eb3 migrations: create a migration for various alterations that do not touch schema (#967) a16aa8c requirements: Update Django REST Framework to 3.4.4 (#976)","title":"Maintenance"},{"location":"changelogs/v2.4.0/#database-v221-v222","text":"","title":"Database v2.2.1 -&gt; v2.2.2"},{"location":"changelogs/v2.4.0/#maintenance_1","text":"022f2c5 Update the postgres version","title":"Maintenance"},{"location":"changelogs/v2.4.0/#dockerbuilder-v230-v231","text":"","title":"Dockerbuilder v2.3.0 -&gt; v2.3.1"},{"location":"changelogs/v2.4.0/#maintenance_2","text":"31065a3 Dockerfile: update deis/base to 0.3.0","title":"Maintenance"},{"location":"changelogs/v2.4.0/#monitoring-v220-v230","text":"","title":"Monitoring v2.2.0 -&gt; v2.3.0"},{"location":"changelogs/v2.4.0/#features_2","text":"527d4dd dashboards: create dashboards for all deis components","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_2","text":"3b15224 ini: a stray quote was causing INI parsing to break a21e7e4 start-grafana: Create dashboard directory when starting grafana","title":"Fixes"},{"location":"changelogs/v2.4.0/#documentation_1","text":"2548941 readme: Provide a configuration section in grafana readme","title":"Documentation"},{"location":"changelogs/v2.4.0/#router-v230-v240","text":"","title":"Router v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features_3","text":"01cf487 *: Update nginx to 1.11.2 571dfea router: Get the annotations from the deployment object instead of RC 59e753c maintenance: Add support for maintenance mode for apps","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_3","text":"1769d2d model: Improve regex for SSL ciphers e085023 routable: Use correct label key for routable c00da10 model: Specify a default ssl cipher list","title":"Fixes"},{"location":"changelogs/v2.4.0/#documentation_2","text":"7cbf93e readme: Clarify that routable services must expose port 80","title":"Documentation"},{"location":"changelogs/v2.4.0/#maintenance_3","text":"541b19b .gitignore: Update to ignore deis-router-deployment.tmp.yaml","title":"Maintenance"},{"location":"changelogs/v2.4.0/#slugbuilder-v230-v231","text":"","title":"Slugbuilder v2.3.0 -&gt; v2.3.1"},{"location":"changelogs/v2.4.0/#maintenance_4","text":"815d0a7 buildpacks: update heroku-buildpack-go to v44 7b34cb5 buildpacks: update heroku-buildpack-scala to v72 f647afe buildpacks: update php buildpack","title":"Maintenance"},{"location":"changelogs/v2.4.0/#workflow-cli-v230-v240","text":"","title":"Workflow CLI v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features_4","text":"f37432b Jenkinsfile: send COMPONENT_REPO param to e2e job dfe19e0 logging: extract logging to its own package and write tests (#166) 7b4c48d cmd: add deis routing 37cdb52 healthcheck: Add support for healthcheck per proctype 4df89d2 maintenance: Add support for maintenance mode for apps 7a9ebf4 Jenkinsfile: wipe vendor dir if bootstrap fails 47def28 Makefile: add git branch and sha information to the uploaded blob 2103657 *: allow configuration flag (#169)","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_4","text":"6745e75 version: move all version logic to git (#167) 4f2d342 healthcheck: Don't fail if there is no healthcheck for a proctype ba9d5d7 CI: don't cache latest binaries (#175) 36df5d4 CI: delete artifacts when cleaning up (#179)","title":"Fixes"},{"location":"changelogs/v2.4.0/#workflow-documentation-v230-v240","text":"","title":"Workflow Documentation v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features_5","text":"af7cf12 healthcheck: Add docs for applying healthchecks per proctype d84c0a1 troubleshooting: add troubleshooting applications 7477ae7 docs: add documentation for limits 4ea0719 CLI: document new behavior of variable (#440) c41f71e maintenance: Add docs for maintenance mode support","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_5","text":"fde9a81 installing: Add configuring registry docs to doc tree 4480831 applications: use admonition styling d097233 user: supply a kubectl patch function to simplify registration mode setting","title":"Fixes"},{"location":"changelogs/v2.4.0/#documentation_3","text":"fb9db75 applications: add deis routing docs 12fd1d7 registration: update registration for 2.3 behavior (#448) 8d271ca upgrading: expand and clarify workflow upgrade instructions (#447) 5fdf2da storage: cleanup storage docs (#454)","title":"Documentation"},{"location":"changelogs/v2.4.0/#maintenance_5","text":"88167c5 roadmap: update roadmap for 2.x (#417) 8befc2a docs: update docs to reflect fixed issue (#455)","title":"Maintenance"},{"location":"changelogs/v2.4.0/#workflow-e2e-tests-v230-v240","text":"","title":"Workflow E2E Tests v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#features_6","text":"6f76da5 procfile: create a build with a procfile 94a884a skip: make procfile test pending 09c1c33 tests: add deis routing e2e tests (#304)","title":"Features"},{"location":"changelogs/v2.4.0/#fixes_6","text":"7e0d1cc CLI: log cli version after installing to check revision (#284) 47a6907 deployments: proc type regex changed due to Deployments b22274e limits: ask for 500m instead of 1024 cores in the limits CPU test 2cd045a Makefile: add retrying to workflow CLI download a56611c docker-test-integration: show curl errors (#311) 807d110 auth: update to new missing config error message (#301)","title":"Fixes"},{"location":"changelogs/v2.4.0/#maintenance_6","text":"ce08b1c travis: Remove .travis.yml","title":"Maintenance"},{"location":"changelogs/v2.4.0/#workflow-manager-v231-v240","text":"","title":"Workflow Manager v2.3.1 -&gt; v2.4.0"},{"location":"changelogs/v2.4.0/#fixes_7","text":"7d859f5 feature(data): add deployments, daemonsets to cluster data (#95) 31fe3bc cluster_id is vulnerable to race condition when called concurrently (#94) 2582640 bug(k8s): unintentional variable shadowing (#92)","title":"Fixes"},{"location":"changelogs/v2.4.1/","text":"Workflow v2.4.0 -> v2.4.1 \u00b6 Maintenance \u00b6 af1c969 workflow-v2.4.1: releasing workflow-v2.4.1(-e2e) Fixes \u00b6 3f3be4d controller: scheduler: check if RC exists during a deploy before trying to use Deployments #996","title":"v2.4.1"},{"location":"changelogs/v2.4.1/#workflow-v240-v241","text":"","title":"Workflow v2.4.0 -&gt; v2.4.1"},{"location":"changelogs/v2.4.1/#maintenance","text":"af1c969 workflow-v2.4.1: releasing workflow-v2.4.1(-e2e)","title":"Maintenance"},{"location":"changelogs/v2.4.1/#fixes","text":"3f3be4d controller: scheduler: check if RC exists during a deploy before trying to use Deployments #996","title":"Fixes"},{"location":"changelogs/v2.4.2/","text":"Workflow v2.4.0 -> v2.4.2 \u00b6 Controller v2.4.1 -> v2.4.2 \u00b6 Fixes \u00b6 eb2f32b registry: tell a user they need PORT when using off-cluster native iaas registry (#988) e9352a3 proctypes: update service after all the proctypes are deployed f7fb2f6 release: during cleanup let pod deletion 404 in case Kubernetes cleaned up as well (#1005)","title":"v2.4.2"},{"location":"changelogs/v2.4.2/#workflow-v240-v242","text":"","title":"Workflow v2.4.0 -&gt; v2.4.2"},{"location":"changelogs/v2.4.2/#controller-v241-v242","text":"","title":"Controller v2.4.1 -&gt; v2.4.2"},{"location":"changelogs/v2.4.2/#fixes","text":"eb2f32b registry: tell a user they need PORT when using off-cluster native iaas registry (#988) e9352a3 proctypes: update service after all the proctypes are deployed f7fb2f6 release: during cleanup let pod deletion 404 in case Kubernetes cleaned up as well (#1005)","title":"Fixes"},{"location":"changelogs/v2.5.0/","text":"Workflow v2.4.2 -> v2.5.0 \u00b6 Builder v2.4.0 -> v2.5.0 \u00b6 Features \u00b6 f99a28e slugbuilder-cache: Add CACHE_PATH variable 05522a0 source_version: add SOURCE_VERSION env var f2c28ef slugbuilder-cache: allow turning caching off completely 47432ea builder: delete cache if the cache is disabled (#422) Refactors \u00b6 797243e util_test: placate linter by replacing test PK Fixes \u00b6 65a7de8 README.md: correct coverage badge URL c776995 slugbuilder-cache: fix typo in comments (#417) Documentation \u00b6 6b04ee5 CONTRIBUTING: update contributing docs (#413) Maintenance \u00b6 db92af5 rootfs/Dockerfile: update to latest base image b916723 Makefile: update to go-dev 0.17.0 0e50147 glide: update Controller SDK (#423) Controller v2.4.2 -> v2.5.2 \u00b6 Features \u00b6 cc0a4d5 whitelist: Add support for IP whitelist 50811a2 api: add deis tls (#1004) 689df78 scheduler: add the ability to set KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS per application (#1026) 5c83d80 autoscale: add autoscaling support to application on per proc type basis (#1018) 1db6146 scheduler: use /scale endpoints for RC and Deployments to only update replicas during scale events (#1029) Refactors \u00b6 f7a3e02 hooks: remove push hook model as the builder stopped using it (#985) 4e0c5a3 scheduler: update_application_service had an unused name argument (#983) d155e92 apps: move AppSettings scheduler logic to App model for simplicity (#993) d3d18d2 scheduler: use scheduler module session singleton to add session mock (#1009) 7306202 scheduler: split up the scheduler code into individual resources and to be modular (#1016) 98d809a scheduler: scheduler passes the kubernetes endpoint to resources instead of getting it from global settings (#1039) Fixes \u00b6 d66c20c whitelist: Handle empty whitelist from user gracefully dbde253 tls: Update the value properly to work with morph 2f5c019 api: create TLS object on app create (#1043) 0d454ee middleware: move to 1.10 style middleware (#955) 899e008 models: add \"added\" log function, lowercase class name (#1017) ffa9040 certs: allow empty Common Name in certificates (#1024) 8408c1f healthcheck: update healthchecks for non default process type 1ca970b app: create image pull secrets outside of the async deploy loop (#1032) 7f16439 imagepullpolicy: Use correct environment variable for image pull policy 83df91e logs: app logs endpoint was returning binary string instead of a normal string (#1035) 3f3a228 scheduler: pass down the right variable for Deployment revision history limit (#1037) ad7fc55 app: rollback all process types to previous version when one (or more) process type fails a deploy (#1027) a303f25 release: change release cleanup to only remove secrets related to Deployments that are no longer active (#1038) ffc9f8c healthcheck: check if the healthchecks are failing on a new deploy Documentation \u00b6 757a8ae CONTRIBUTING: update contributing doc (#1006) Maintenance \u00b6 af7fe18 requirements: update Requests to 2.11.1 (#990) 5853532 rootfs/Dockerfile: update to latest base image 9ced97c requirements: Update DRF to 3.4.5 (#997) 6afa4f2 requirements: update DRF to 3.4.6 (#1007) a2b8428 requirements: update PyOpenSSL to 16.1.0 (#1022) cfe2f1c requirements: update to Django 1.10.1 (#1040) Dockerbuilder v2.3.1 -> v2.3.2 \u00b6 Features \u00b6 4273b5c tests: feat(tests) Add flake8 linting for python code (#91) Maintenance \u00b6 a67d22c Makefile: clean up and update makefile (#90) Logger v2.2.0 -> v2.3.0 \u00b6 Features \u00b6 d1ad7c1 pprof: Add pprof endpoint Documentation \u00b6 6596685 readme: Update readme with new architecture Maintenance \u00b6 d869a2e rootfs/Dockerfile: update to latest base image c79bb98 Makefile: update to go-dev 0.17.0 Minio v2.2.0 -> v2.2.1 \u00b6 Fixes \u00b6 22debea .travis.yml: unset DEIS_REGISTRY before building image Maintenance \u00b6 4e55f42 Makefile: update to go-dev 0.17.0 a686c8a rootfs/Dockerfile: update to latest base image 4a5315c glide: update glide files Monitoring v2.3.0 -> v2.4.0 \u00b6 Refactors \u00b6 1dfc015 deis component health: Refactored deis components health dashboards Maintenance \u00b6 254249a Dockerfile: update to latest base image Registry v2.2.0 -> v2.2.1 \u00b6 Maintenance \u00b6 412b4e2 Makefile: update to go-dev 0.17.0 4b14708 .travis.yml: use current Go 1.7 compiler 10d8308 rootfs/Dockerfile: update to latest base image Router v2.4.0 -> v2.5.0 \u00b6 Features \u00b6 bd25b82 router: add app SSL config Refactors \u00b6 a7da253 fix new linter errors ef9a5bf Dockerfile: copy the router binary after building ngnix binary Maintenance \u00b6 ea7fffc Makefile: update to go-dev 0.17.0 8c3aded rootfs/Dockerfile: update to latest base image Slugbuilder v2.3.1 -> v2.4.1 \u00b6 Features \u00b6 4d634a3 Makefile: add --pull flag to docker-build b6a2f12 cache: allow cache to be persisted Fixes \u00b6 37c5109 build.sh: switch to build_root before running hooks dcad3f0 build: check if release yaml is nil before accessing hash (#105) Documentation \u00b6 116da05 readme: fix formatting in readme d05c3e4 build.sh: simplify and formalize cache message 49fecd9 CONTRIBUTING: update contributing doc (#107) Maintenance \u00b6 c6f948a buildpacks: update heroku-buildpack-go to v46 Slugrunner v2.2.0 -> v2.2.1 \u00b6 Refactors \u00b6 6b0c90d init: remove sdutil, which is no longer used (#51) Fixes \u00b6 166bddd init: check for valid YAML before accessing hash (#50) 2d86e6c Makefile: ensure to use \"latest\" build of cedar:14 Documentation \u00b6 d87b04e CONTRIBUTING: update contributing doc (#53) Workflow CLI v2.4.0 -> v2.5.1 \u00b6 Features \u00b6 78118eb CI: refactor CI to build and then pass around a test image (#181) aded419 CI: upload CLI to seperate buckets (#190) 3cb4ad3 whitelist: Add support for ip whitlising for app ec466d7 autoscale: add the ability to define autoscale rules per process type on an app (#208) 84de668 cmd: add deis tls eefb125 Makefile: build using dockefile and slim image size (#215) a4dea17 Makefile: add build-stable target 618939c users: show admins when listing users (#205) 01ca8f8 version: add deis version --all (#217) Refactors \u00b6 912ad85 Jenkinsfile: remove shell output hack Fixes \u00b6 8653f92 whitelist: format the deis whitelist properly 82b6368 settings: remove duplicated 'v' in user agent (#188) d5a004c tests: start adding unit tests (#183) 272b1cd routing, maintenance: check for existence of pointer before reading it. (#195) db38964 git: properly log errors from git (#199) 09ca839 CI: don't upload to old bucket and declare varaibles locally (#211) f9d85a0 ps: use new sdk for sorted processes (#210) d49acf0 CI: define more variables locally (#212) 9b3980a limits: remove short cpu flag (#216) e10caf6 cmd: fix help string when git remote already exists Documentation \u00b6 260d826 CONTRIBUTING: link contributing documentation to website (#185) Maintenance \u00b6 850ee9c glide: update Controller SDK (#220) Workflow Documentation v2.4.1 -> v2.5.0 \u00b6 Features \u00b6 2e92c77 contributing: add more details to issue reporting (#472) a27f00f whitelist: Add docs for specifying application whitelist using deis client b8b3eed autoscale: add documentation for the autoscale functionality (#483) Fixes \u00b6 e066502 quickstart: remove references to downgrade 6f2639a quickstart: specify how to get hostname (#469) 219179f managing-workflow: fix broken link 0a1c57d apps: KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS is now also per app (#486) Documentation \u00b6 d7db3d4 triaging-issues: describe new priority labels 2c753c2 using-docker-images: use example-dockerfile-http as sample dockerfile application instead of helloworld. (#482) 6c1f4fd ssl-certificates: add docs on deis tls:enable 5e055f0 fix: add --namespace=deis to Controlling Registration Modes c112a46 update: using-docker-images.md 5f46769 src/roadmap/releases.md: add step for releasing cli stable 1e79b46 upgrading-workflow.md: remove errant/redundant command b721180 styles: docs(styles) sticky footer to avoid overlap with sidebar c54c2ec styles: docs(styles) fix mobile menu scroll issues Maintenance \u00b6 bd306d4 release: Workflow 2.4.1 (#463) 4afda70 release: Workflow 2.4.2 4694454 changelogs: add top-level for changelogs f383c43 changelogs: add v2.0.0 changelog 176d080 changelog: add v2.1.0 changelog 9ab4ba8 changelog: add v2.2.0 changelog ebac67f changelog: add v2.3.0 changelog 1da032d changelog: add v2.4.0 changelog db9bb8d changelog: add v2.4.2 changelog 0d43482 changelog: add headings for clarity d18dec4 changelog: update release process for new changelog page a2d58aa changelogs: add v2.4.1 changelog bd4db54 api-docs: add v2.3 API docs (#485) Workflow E2E Tests v2.4.0 -> v2.5.2 \u00b6 Features \u00b6 a2ed8b2 docker: add DEBUG option to hang build (#312) 30c8fd3 procfile: unskip builds procfile test 95f4eb9 docker-test-integration.sh: try curling cli from multiple buckets 9c294e3 maintenance: Add test for maintenance mode 013709e whitelist: Add tests for deis whitelist 5bc8cb0 tests: add deis tls tests (#316) 0f2df78 docker-test-integration.sh: check if 'stable' Refactors \u00b6 2da83d9 Dockerfile: don't use alpine, it has known DNS issues (#313) Fixes \u00b6 8a2d858 healthcheck: use correct port the image exposes Maintenance \u00b6 424f625 Makefile: update docker-go-dev to 0.17.0 88ad38f glide.lock: update ginkgo, gomega, controller-sdk-go Workflow Manager v2.4.0 -> v2.4.1 \u00b6 Documentation \u00b6 25f5b32 README.md: add codecov.io badge Maintenance \u00b6 940ced5 Makefile: update to go-dev 0.17.0 d9b0326 rootfs/Dockerfile: update to latest base image","title":"v2.5.0"},{"location":"changelogs/v2.5.0/#workflow-v242-v250","text":"","title":"Workflow v2.4.2 -&gt; v2.5.0"},{"location":"changelogs/v2.5.0/#builder-v240-v250","text":"","title":"Builder v2.4.0 -&gt; v2.5.0"},{"location":"changelogs/v2.5.0/#features","text":"f99a28e slugbuilder-cache: Add CACHE_PATH variable 05522a0 source_version: add SOURCE_VERSION env var f2c28ef slugbuilder-cache: allow turning caching off completely 47432ea builder: delete cache if the cache is disabled (#422)","title":"Features"},{"location":"changelogs/v2.5.0/#refactors","text":"797243e util_test: placate linter by replacing test PK","title":"Refactors"},{"location":"changelogs/v2.5.0/#fixes","text":"65a7de8 README.md: correct coverage badge URL c776995 slugbuilder-cache: fix typo in comments (#417)","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation","text":"6b04ee5 CONTRIBUTING: update contributing docs (#413)","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance","text":"db92af5 rootfs/Dockerfile: update to latest base image b916723 Makefile: update to go-dev 0.17.0 0e50147 glide: update Controller SDK (#423)","title":"Maintenance"},{"location":"changelogs/v2.5.0/#controller-v242-v252","text":"","title":"Controller v2.4.2 -&gt; v2.5.2"},{"location":"changelogs/v2.5.0/#features_1","text":"cc0a4d5 whitelist: Add support for IP whitelist 50811a2 api: add deis tls (#1004) 689df78 scheduler: add the ability to set KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS per application (#1026) 5c83d80 autoscale: add autoscaling support to application on per proc type basis (#1018) 1db6146 scheduler: use /scale endpoints for RC and Deployments to only update replicas during scale events (#1029)","title":"Features"},{"location":"changelogs/v2.5.0/#refactors_1","text":"f7a3e02 hooks: remove push hook model as the builder stopped using it (#985) 4e0c5a3 scheduler: update_application_service had an unused name argument (#983) d155e92 apps: move AppSettings scheduler logic to App model for simplicity (#993) d3d18d2 scheduler: use scheduler module session singleton to add session mock (#1009) 7306202 scheduler: split up the scheduler code into individual resources and to be modular (#1016) 98d809a scheduler: scheduler passes the kubernetes endpoint to resources instead of getting it from global settings (#1039)","title":"Refactors"},{"location":"changelogs/v2.5.0/#fixes_1","text":"d66c20c whitelist: Handle empty whitelist from user gracefully dbde253 tls: Update the value properly to work with morph 2f5c019 api: create TLS object on app create (#1043) 0d454ee middleware: move to 1.10 style middleware (#955) 899e008 models: add \"added\" log function, lowercase class name (#1017) ffa9040 certs: allow empty Common Name in certificates (#1024) 8408c1f healthcheck: update healthchecks for non default process type 1ca970b app: create image pull secrets outside of the async deploy loop (#1032) 7f16439 imagepullpolicy: Use correct environment variable for image pull policy 83df91e logs: app logs endpoint was returning binary string instead of a normal string (#1035) 3f3a228 scheduler: pass down the right variable for Deployment revision history limit (#1037) ad7fc55 app: rollback all process types to previous version when one (or more) process type fails a deploy (#1027) a303f25 release: change release cleanup to only remove secrets related to Deployments that are no longer active (#1038) ffc9f8c healthcheck: check if the healthchecks are failing on a new deploy","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation_1","text":"757a8ae CONTRIBUTING: update contributing doc (#1006)","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_1","text":"af7fe18 requirements: update Requests to 2.11.1 (#990) 5853532 rootfs/Dockerfile: update to latest base image 9ced97c requirements: Update DRF to 3.4.5 (#997) 6afa4f2 requirements: update DRF to 3.4.6 (#1007) a2b8428 requirements: update PyOpenSSL to 16.1.0 (#1022) cfe2f1c requirements: update to Django 1.10.1 (#1040)","title":"Maintenance"},{"location":"changelogs/v2.5.0/#dockerbuilder-v231-v232","text":"","title":"Dockerbuilder v2.3.1 -&gt; v2.3.2"},{"location":"changelogs/v2.5.0/#features_2","text":"4273b5c tests: feat(tests) Add flake8 linting for python code (#91)","title":"Features"},{"location":"changelogs/v2.5.0/#maintenance_2","text":"a67d22c Makefile: clean up and update makefile (#90)","title":"Maintenance"},{"location":"changelogs/v2.5.0/#logger-v220-v230","text":"","title":"Logger v2.2.0 -&gt; v2.3.0"},{"location":"changelogs/v2.5.0/#features_3","text":"d1ad7c1 pprof: Add pprof endpoint","title":"Features"},{"location":"changelogs/v2.5.0/#documentation_2","text":"6596685 readme: Update readme with new architecture","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_3","text":"d869a2e rootfs/Dockerfile: update to latest base image c79bb98 Makefile: update to go-dev 0.17.0","title":"Maintenance"},{"location":"changelogs/v2.5.0/#minio-v220-v221","text":"","title":"Minio v2.2.0 -&gt; v2.2.1"},{"location":"changelogs/v2.5.0/#fixes_2","text":"22debea .travis.yml: unset DEIS_REGISTRY before building image","title":"Fixes"},{"location":"changelogs/v2.5.0/#maintenance_4","text":"4e55f42 Makefile: update to go-dev 0.17.0 a686c8a rootfs/Dockerfile: update to latest base image 4a5315c glide: update glide files","title":"Maintenance"},{"location":"changelogs/v2.5.0/#monitoring-v230-v240","text":"","title":"Monitoring v2.3.0 -&gt; v2.4.0"},{"location":"changelogs/v2.5.0/#refactors_2","text":"1dfc015 deis component health: Refactored deis components health dashboards","title":"Refactors"},{"location":"changelogs/v2.5.0/#maintenance_5","text":"254249a Dockerfile: update to latest base image","title":"Maintenance"},{"location":"changelogs/v2.5.0/#registry-v220-v221","text":"","title":"Registry v2.2.0 -&gt; v2.2.1"},{"location":"changelogs/v2.5.0/#maintenance_6","text":"412b4e2 Makefile: update to go-dev 0.17.0 4b14708 .travis.yml: use current Go 1.7 compiler 10d8308 rootfs/Dockerfile: update to latest base image","title":"Maintenance"},{"location":"changelogs/v2.5.0/#router-v240-v250","text":"","title":"Router v2.4.0 -&gt; v2.5.0"},{"location":"changelogs/v2.5.0/#features_4","text":"bd25b82 router: add app SSL config","title":"Features"},{"location":"changelogs/v2.5.0/#refactors_3","text":"a7da253 fix new linter errors ef9a5bf Dockerfile: copy the router binary after building ngnix binary","title":"Refactors"},{"location":"changelogs/v2.5.0/#maintenance_7","text":"ea7fffc Makefile: update to go-dev 0.17.0 8c3aded rootfs/Dockerfile: update to latest base image","title":"Maintenance"},{"location":"changelogs/v2.5.0/#slugbuilder-v231-v241","text":"","title":"Slugbuilder v2.3.1 -&gt; v2.4.1"},{"location":"changelogs/v2.5.0/#features_5","text":"4d634a3 Makefile: add --pull flag to docker-build b6a2f12 cache: allow cache to be persisted","title":"Features"},{"location":"changelogs/v2.5.0/#fixes_3","text":"37c5109 build.sh: switch to build_root before running hooks dcad3f0 build: check if release yaml is nil before accessing hash (#105)","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation_3","text":"116da05 readme: fix formatting in readme d05c3e4 build.sh: simplify and formalize cache message 49fecd9 CONTRIBUTING: update contributing doc (#107)","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_8","text":"c6f948a buildpacks: update heroku-buildpack-go to v46","title":"Maintenance"},{"location":"changelogs/v2.5.0/#slugrunner-v220-v221","text":"","title":"Slugrunner v2.2.0 -&gt; v2.2.1"},{"location":"changelogs/v2.5.0/#refactors_4","text":"6b0c90d init: remove sdutil, which is no longer used (#51)","title":"Refactors"},{"location":"changelogs/v2.5.0/#fixes_4","text":"166bddd init: check for valid YAML before accessing hash (#50) 2d86e6c Makefile: ensure to use \"latest\" build of cedar:14","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation_4","text":"d87b04e CONTRIBUTING: update contributing doc (#53)","title":"Documentation"},{"location":"changelogs/v2.5.0/#workflow-cli-v240-v251","text":"","title":"Workflow CLI v2.4.0 -&gt; v2.5.1"},{"location":"changelogs/v2.5.0/#features_6","text":"78118eb CI: refactor CI to build and then pass around a test image (#181) aded419 CI: upload CLI to seperate buckets (#190) 3cb4ad3 whitelist: Add support for ip whitlising for app ec466d7 autoscale: add the ability to define autoscale rules per process type on an app (#208) 84de668 cmd: add deis tls eefb125 Makefile: build using dockefile and slim image size (#215) a4dea17 Makefile: add build-stable target 618939c users: show admins when listing users (#205) 01ca8f8 version: add deis version --all (#217)","title":"Features"},{"location":"changelogs/v2.5.0/#refactors_5","text":"912ad85 Jenkinsfile: remove shell output hack","title":"Refactors"},{"location":"changelogs/v2.5.0/#fixes_5","text":"8653f92 whitelist: format the deis whitelist properly 82b6368 settings: remove duplicated 'v' in user agent (#188) d5a004c tests: start adding unit tests (#183) 272b1cd routing, maintenance: check for existence of pointer before reading it. (#195) db38964 git: properly log errors from git (#199) 09ca839 CI: don't upload to old bucket and declare varaibles locally (#211) f9d85a0 ps: use new sdk for sorted processes (#210) d49acf0 CI: define more variables locally (#212) 9b3980a limits: remove short cpu flag (#216) e10caf6 cmd: fix help string when git remote already exists","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation_5","text":"260d826 CONTRIBUTING: link contributing documentation to website (#185)","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_9","text":"850ee9c glide: update Controller SDK (#220)","title":"Maintenance"},{"location":"changelogs/v2.5.0/#workflow-documentation-v241-v250","text":"","title":"Workflow Documentation v2.4.1 -&gt; v2.5.0"},{"location":"changelogs/v2.5.0/#features_7","text":"2e92c77 contributing: add more details to issue reporting (#472) a27f00f whitelist: Add docs for specifying application whitelist using deis client b8b3eed autoscale: add documentation for the autoscale functionality (#483)","title":"Features"},{"location":"changelogs/v2.5.0/#fixes_6","text":"e066502 quickstart: remove references to downgrade 6f2639a quickstart: specify how to get hostname (#469) 219179f managing-workflow: fix broken link 0a1c57d apps: KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS is now also per app (#486)","title":"Fixes"},{"location":"changelogs/v2.5.0/#documentation_6","text":"d7db3d4 triaging-issues: describe new priority labels 2c753c2 using-docker-images: use example-dockerfile-http as sample dockerfile application instead of helloworld. (#482) 6c1f4fd ssl-certificates: add docs on deis tls:enable 5e055f0 fix: add --namespace=deis to Controlling Registration Modes c112a46 update: using-docker-images.md 5f46769 src/roadmap/releases.md: add step for releasing cli stable 1e79b46 upgrading-workflow.md: remove errant/redundant command b721180 styles: docs(styles) sticky footer to avoid overlap with sidebar c54c2ec styles: docs(styles) fix mobile menu scroll issues","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_10","text":"bd306d4 release: Workflow 2.4.1 (#463) 4afda70 release: Workflow 2.4.2 4694454 changelogs: add top-level for changelogs f383c43 changelogs: add v2.0.0 changelog 176d080 changelog: add v2.1.0 changelog 9ab4ba8 changelog: add v2.2.0 changelog ebac67f changelog: add v2.3.0 changelog 1da032d changelog: add v2.4.0 changelog db9bb8d changelog: add v2.4.2 changelog 0d43482 changelog: add headings for clarity d18dec4 changelog: update release process for new changelog page a2d58aa changelogs: add v2.4.1 changelog bd4db54 api-docs: add v2.3 API docs (#485)","title":"Maintenance"},{"location":"changelogs/v2.5.0/#workflow-e2e-tests-v240-v252","text":"","title":"Workflow E2E Tests v2.4.0 -&gt; v2.5.2"},{"location":"changelogs/v2.5.0/#features_8","text":"a2ed8b2 docker: add DEBUG option to hang build (#312) 30c8fd3 procfile: unskip builds procfile test 95f4eb9 docker-test-integration.sh: try curling cli from multiple buckets 9c294e3 maintenance: Add test for maintenance mode 013709e whitelist: Add tests for deis whitelist 5bc8cb0 tests: add deis tls tests (#316) 0f2df78 docker-test-integration.sh: check if 'stable'","title":"Features"},{"location":"changelogs/v2.5.0/#refactors_6","text":"2da83d9 Dockerfile: don't use alpine, it has known DNS issues (#313)","title":"Refactors"},{"location":"changelogs/v2.5.0/#fixes_7","text":"8a2d858 healthcheck: use correct port the image exposes","title":"Fixes"},{"location":"changelogs/v2.5.0/#maintenance_11","text":"424f625 Makefile: update docker-go-dev to 0.17.0 88ad38f glide.lock: update ginkgo, gomega, controller-sdk-go","title":"Maintenance"},{"location":"changelogs/v2.5.0/#workflow-manager-v240-v241","text":"","title":"Workflow Manager v2.4.0 -&gt; v2.4.1"},{"location":"changelogs/v2.5.0/#documentation_7","text":"25f5b32 README.md: add codecov.io badge","title":"Documentation"},{"location":"changelogs/v2.5.0/#maintenance_12","text":"940ced5 Makefile: update to go-dev 0.17.0 d9b0326 rootfs/Dockerfile: update to latest base image","title":"Maintenance"},{"location":"changelogs/v2.6.0/","text":"Workflow v2.5.0 -> v2.6.0 \u00b6 Builder v2.5.0 -> v2.5.1 \u00b6 Fixes \u00b6 392ef7d Makefile: update deploy target to use deployments (#424) 933c124 conf: strip newlines from builder key (#425) Maintenance \u00b6 b1a0ef6 Dockerfile: update base image to v0.3.4 ac829c0 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#434) Controller v2.5.2 -> v2.6.0 \u00b6 Features \u00b6 f5d1454 api: inject release metadata into application (#1080) Refactors \u00b6 13de6e6 Dockerfile: ditch the pip cache for a slightly smaller image (#1051) 3e1f9d6 scheduler: add HTTP functions in KubeHTTPClient (#1019) 8d287b9 scheduler: move image pull policy settings from scheduler to App model and remove SLUG_RUNNER_IMAGE_PULL_POLICY (#1053) 02718a3 app: centralise all application configuration handling in App model to be used by run, deploy and scale (#1061) 22f96eb scheduler: add more Pod tests in scheduler and add create() to Pod resource (#1079) 13c1711 Dockerfile: use base 0.3.2, smaller packages and better cleanup (#1088) Fixes \u00b6 4f5f944 views: make sure domain is set it in cert attach operation (#1046) 29d51d9 scheduler: show more information when there is a HTTP error in Kubernetes (#1041) 3d3676b release: call proper RC scale instead of a missing (old) method (#1055) 60c6a5f procfile: route the traffic to web proctype always if its present in procfile d7e626c whitelist: remove the whitelist from annoations if its empty b8aa206 api: check if release.build is NoneType (#1078) ad182b2 api: cast DEPLOY_BATCHES and DEPLOY_TIMEOUT to int (#1076) 7aaee55 Makefile: remove double usage of --noinput (#1083) Maintenance \u00b6 667ba1f requirements: update django-guardian to 1.4.6 (#1050) 640d220 requirements: chore(requirements) Update to docker-py 1.10.2 (#1056) 8559fb0 tests: port app logs test from deis/deis#5005 (#1064) 06c7695 scheduler: move log lines to before a raise so DEBUG info is actually caught (#1067) aaccdf7 tests: improve test coverage for HPA (#1081) 4d7591c requirements: update docker-py to 1.10.3 (#1086) e9a9e7a tests: improve Pod scheduler tests (#1085) 260b1e4 requirements: update DRF to 3.4.7 (#1087) Dockerbuilder v2.3.2 -> v2.3.3 \u00b6 Maintenance \u00b6 1bd4727 requirements: chore(requirements) Update to docker-py 1.10.2 28c31d4 requirements: update docker-py to 1.10.3 (#94) f013504 Dockerfile: update base image to v0.3.4 070d5cb Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#96) Fluentd v2.2.0 -> v2.4.1 \u00b6 Features \u00b6 900a31b Dockerfile: upgrade fluentd and pin versions 1529614 config: Allows for building custom plugins c9a3d8f Allow configuring custom plugins/stores/filters for fluentd Fixes \u00b6 eeda904 conf: Remove time_format from sources d5b8580 sources: allow users to specify what logs they want to capture 56f4d67 boot: fix missing container symlinks eeda904 conf: Remove time_format from sources d5b8580 sources: allow users to specify what logs they want to capture 56f4d67 boot: fix missing container symlinks Maintenance \u00b6 bf242e2 deis: Allow users to disable the deis output plugin 30911be Dockerfile: update base image to v0.3.4 36f90ae Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#54) bf242e2 deis: Allow users to disable the deis output plugin Documentation \u00b6 49d8d29 Document custom plugin environment variables. Logger v2.3.0 -> v2.3.1 \u00b6 Fixes \u00b6 9bd19a3 weblog: fix up CPU issues Documentation \u00b6 9eb022d README: docs(README) update docs Maintenance \u00b6 6a865ee Dockerfile: update base image to v0.3.4 Minio v2.2.1 -> v2.3.0 \u00b6 Features \u00b6 430d6d2 pkg: update the pkg to latest and get ip using downward api Maintenance \u00b6 ac80262 Dockerfile: update base image to v0.3.4 Monitoring v2.4.0 -> v2.5.1 \u00b6 Features \u00b6 ab1d467 influxdb: upgrade influxdb and telegraph to 1.0 Maintenance \u00b6 1a10082 telegraf,grafana,influx: Update to 0.3.4 base d596b08 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#144) 3aea2a7 config: Remove calls to quote NSQ v2.2.0 -> v2.2.2 \u00b6 Fixes \u00b6 8e1e208 Adding set -eo pipefail to start up script Maintenance \u00b6 ef2bb5d Dockerfile: update base image to v0.3.4 Redis v2.2.0 -> v2.2.2 \u00b6 Fixes \u00b6 3659efb Dockerfile: missing && in Dockerfile makes apt not so happy (#5) Refactors \u00b6 7e62f08 Makefile: remove obsolete \"docker tag -f\" flag Maintenance \u00b6 545c46b Dockerfile: update base image to v0.3.4 21c376d Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#4) Registry v2.2.1 -> v2.2.2 \u00b6 Maintenance \u00b6 c9150b9 Dockerfile: update base image to v0.3.4 32a7400 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#67) Registry Proxy v1.0.0 -> v1.1.0 \u00b6 Fixes \u00b6 5f69fe0 nginx: set worker_processes to auto Maintenance \u00b6 89687b0 rootfs: bump version to v1.1.0-dev 70a8a8b rootfs: bump version to v1.1.0 Router v2.5.0 -> v2.6.2 \u00b6 Features \u00b6 151916e nginx: Allow sending nginx X-Request-Id and X-Correlation-Id headers. Refactors \u00b6 b33c18c glide: use the official kubernetes client (#259) Fixes \u00b6 a729799 nginx: Enable builder PROXY PROTOCOL support 0d9b119 ngnix: handle X-Forwarded-Port and X-Forwarded-Proto properly Documentation \u00b6 b20eba0 README: Correct errant references to RC in annotations table Maintenance \u00b6 4afbcc6 Dockerfile: update base image to v0.3.4 5a6b004 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#262) e38a69b nginx: update nginx to 1.11.4 (#252) 246bdc5 Dockerfile: bump deis/base to v0.3.2 Slugbuilder v2.4.1 -> v2.4.3 \u00b6 Refactors \u00b6 24e0ce9 Dockerfile: simplify chown commands Fixes \u00b6 37c5109 build.sh: switch to build_root before running hooks Maintenance \u00b6 2a7769d Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#113) 0ff387f buildpacks: update heroku-buildpack-go to v48 4eada8d buildpacks: update heroku-buildpack-php to v110 fcb645b buildpacks: update heroku-buildpack-python to v82 69abae5 buildpacks: update heroku-buildpack-gradle to v18 d6445a6 buildpacks: update heroku-buildpack-java to v46 30ce52f buildpacks: update heroku-buildpack-go to v49 7e4e9cc buildpacks: update heroku-buildpack-php to v112 Slugbuilder v2.2.1 -> v2.2.2 \u00b6 Maintenance \u00b6 098d05a Dockerfile: consolidate a few chmod and chown into one layer (#54) Workflow CLI v2.5.1 -> v2.6.0 \u00b6 Features \u00b6 c760eb1 cmd: only print version mismatch warning once (#223) a330059 git: clean up git package and write tests (#227) Refactors \u00b6 85f2df2 Dockerfile: remove deprecated --strip-vcs flag Fixes \u00b6 6b13756 CI: explicitly set codecov git SHA (#221) 2bb4cde Jenkinsfile: un-parallelize lint and test tasks Documentation \u00b6 c04610d README.md: update bucket location 8745328 readme: adding codecov badge (#249) Maintenance \u00b6 1041d9e Dockerfile: update go-dev and go toolchain Workflow Documentation v2.5.0 -> v2.6.0 \u00b6 Features \u00b6 a3a25c0 scripts: build every tagged version of workflow docs 9ae8f9c apps: add information about IMAGE_PULL_POLICY globally and per app (#504) Refactors \u00b6 495e1a1 configuring-registry: clarify ECR registry variables Fixes \u00b6 fb5d378 releases: deisrel no longer requires $OLD_SHA and $OLD_RELEASE cb23b43 components: link to architecture, not itself (#499) c95c24b configuring-registry: add missing IAM link 6509c41 docs: add documentation on resetting a password using the cli. (#507) 7b88723 docs: change the references from RC's to deploments 54df10a deisrel: update the deisrel command to generate changelog 0e56d8a gutenbuild: do not build any pre-release tags 80f0551 gutenbuild: ensure we are on master before building 1e87307 gutenbuild: prepend grep string with -- 26d8a40 gutenbuild: use dev_build_dest for second build Documentation \u00b6 8b542a1 upgrade: reminder to upgrade deis client 0ef84bc slugbuilder-cache: add CACHE_PATH variable a349d20 slugbuilder-cache: add usage documentation 1f09a8c slugbuilder-cache: add application tuning variable ec42f7b src/roadmap/releases.md: remove publish component release step a971a25 CONTRIBUTING: update contributing documentation (#498) d0a43b5 tuning: update storage default for logger 5720dce src/managing-workflow/upgrading-workflow.md: document nodes >= 2 for upgrade 5705489 src/roadmap/releases.md: link to pipeline flow diagrams 0da5297 managing-workflow: Document PROXY protocol configuration b5f2d99 releases: add missing details and reword CI flow reference Maintenance \u00b6 7faaaa7 release: update roadmap for 2.5 e8c5d3f src/roadmap/releases.md: update jenkins-jobs var name 2655c90 scripts: remove old release tools and CHANGELOG Workflow E2E Tests v2.5.2 -> v2.5.3 \u00b6 Fixes \u00b6 4f00c8b tests: re-enable tls tests (#326) Worklfow Manager v2.4.1 -> v2.4.2 \u00b6 Maintenance \u00b6 350f7c3 Dockerfile: update base image to v0.3.4","title":"v2.6.0"},{"location":"changelogs/v2.6.0/#workflow-v250-v260","text":"","title":"Workflow v2.5.0 -&gt; v2.6.0"},{"location":"changelogs/v2.6.0/#builder-v250-v251","text":"","title":"Builder v2.5.0 -&gt; v2.5.1"},{"location":"changelogs/v2.6.0/#fixes","text":"392ef7d Makefile: update deploy target to use deployments (#424) 933c124 conf: strip newlines from builder key (#425)","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance","text":"b1a0ef6 Dockerfile: update base image to v0.3.4 ac829c0 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#434)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#controller-v252-v260","text":"","title":"Controller v2.5.2 -&gt; v2.6.0"},{"location":"changelogs/v2.6.0/#features","text":"f5d1454 api: inject release metadata into application (#1080)","title":"Features"},{"location":"changelogs/v2.6.0/#refactors","text":"13de6e6 Dockerfile: ditch the pip cache for a slightly smaller image (#1051) 3e1f9d6 scheduler: add HTTP functions in KubeHTTPClient (#1019) 8d287b9 scheduler: move image pull policy settings from scheduler to App model and remove SLUG_RUNNER_IMAGE_PULL_POLICY (#1053) 02718a3 app: centralise all application configuration handling in App model to be used by run, deploy and scale (#1061) 22f96eb scheduler: add more Pod tests in scheduler and add create() to Pod resource (#1079) 13c1711 Dockerfile: use base 0.3.2, smaller packages and better cleanup (#1088)","title":"Refactors"},{"location":"changelogs/v2.6.0/#fixes_1","text":"4f5f944 views: make sure domain is set it in cert attach operation (#1046) 29d51d9 scheduler: show more information when there is a HTTP error in Kubernetes (#1041) 3d3676b release: call proper RC scale instead of a missing (old) method (#1055) 60c6a5f procfile: route the traffic to web proctype always if its present in procfile d7e626c whitelist: remove the whitelist from annoations if its empty b8aa206 api: check if release.build is NoneType (#1078) ad182b2 api: cast DEPLOY_BATCHES and DEPLOY_TIMEOUT to int (#1076) 7aaee55 Makefile: remove double usage of --noinput (#1083)","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance_1","text":"667ba1f requirements: update django-guardian to 1.4.6 (#1050) 640d220 requirements: chore(requirements) Update to docker-py 1.10.2 (#1056) 8559fb0 tests: port app logs test from deis/deis#5005 (#1064) 06c7695 scheduler: move log lines to before a raise so DEBUG info is actually caught (#1067) aaccdf7 tests: improve test coverage for HPA (#1081) 4d7591c requirements: update docker-py to 1.10.3 (#1086) e9a9e7a tests: improve Pod scheduler tests (#1085) 260b1e4 requirements: update DRF to 3.4.7 (#1087)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#dockerbuilder-v232-v233","text":"","title":"Dockerbuilder v2.3.2 -&gt; v2.3.3"},{"location":"changelogs/v2.6.0/#maintenance_2","text":"1bd4727 requirements: chore(requirements) Update to docker-py 1.10.2 28c31d4 requirements: update docker-py to 1.10.3 (#94) f013504 Dockerfile: update base image to v0.3.4 070d5cb Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#96)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#fluentd-v220-v241","text":"","title":"Fluentd v2.2.0 -&gt; v2.4.1"},{"location":"changelogs/v2.6.0/#features_1","text":"900a31b Dockerfile: upgrade fluentd and pin versions 1529614 config: Allows for building custom plugins c9a3d8f Allow configuring custom plugins/stores/filters for fluentd","title":"Features"},{"location":"changelogs/v2.6.0/#fixes_2","text":"eeda904 conf: Remove time_format from sources d5b8580 sources: allow users to specify what logs they want to capture 56f4d67 boot: fix missing container symlinks eeda904 conf: Remove time_format from sources d5b8580 sources: allow users to specify what logs they want to capture 56f4d67 boot: fix missing container symlinks","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance_3","text":"bf242e2 deis: Allow users to disable the deis output plugin 30911be Dockerfile: update base image to v0.3.4 36f90ae Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#54) bf242e2 deis: Allow users to disable the deis output plugin","title":"Maintenance"},{"location":"changelogs/v2.6.0/#documentation","text":"49d8d29 Document custom plugin environment variables.","title":"Documentation"},{"location":"changelogs/v2.6.0/#logger-v230-v231","text":"","title":"Logger v2.3.0 -&gt; v2.3.1"},{"location":"changelogs/v2.6.0/#fixes_3","text":"9bd19a3 weblog: fix up CPU issues","title":"Fixes"},{"location":"changelogs/v2.6.0/#documentation_1","text":"9eb022d README: docs(README) update docs","title":"Documentation"},{"location":"changelogs/v2.6.0/#maintenance_4","text":"6a865ee Dockerfile: update base image to v0.3.4","title":"Maintenance"},{"location":"changelogs/v2.6.0/#minio-v221-v230","text":"","title":"Minio v2.2.1 -&gt; v2.3.0"},{"location":"changelogs/v2.6.0/#features_2","text":"430d6d2 pkg: update the pkg to latest and get ip using downward api","title":"Features"},{"location":"changelogs/v2.6.0/#maintenance_5","text":"ac80262 Dockerfile: update base image to v0.3.4","title":"Maintenance"},{"location":"changelogs/v2.6.0/#monitoring-v240-v251","text":"","title":"Monitoring v2.4.0 -&gt; v2.5.1"},{"location":"changelogs/v2.6.0/#features_3","text":"ab1d467 influxdb: upgrade influxdb and telegraph to 1.0","title":"Features"},{"location":"changelogs/v2.6.0/#maintenance_6","text":"1a10082 telegraf,grafana,influx: Update to 0.3.4 base d596b08 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#144) 3aea2a7 config: Remove calls to quote","title":"Maintenance"},{"location":"changelogs/v2.6.0/#nsq-v220-v222","text":"","title":"NSQ v2.2.0 -&gt; v2.2.2"},{"location":"changelogs/v2.6.0/#fixes_4","text":"8e1e208 Adding set -eo pipefail to start up script","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance_7","text":"ef2bb5d Dockerfile: update base image to v0.3.4","title":"Maintenance"},{"location":"changelogs/v2.6.0/#redis-v220-v222","text":"","title":"Redis v2.2.0 -&gt; v2.2.2"},{"location":"changelogs/v2.6.0/#fixes_5","text":"3659efb Dockerfile: missing && in Dockerfile makes apt not so happy (#5)","title":"Fixes"},{"location":"changelogs/v2.6.0/#refactors_1","text":"7e62f08 Makefile: remove obsolete \"docker tag -f\" flag","title":"Refactors"},{"location":"changelogs/v2.6.0/#maintenance_8","text":"545c46b Dockerfile: update base image to v0.3.4 21c376d Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#4)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#registry-v221-v222","text":"","title":"Registry v2.2.1 -&gt; v2.2.2"},{"location":"changelogs/v2.6.0/#maintenance_9","text":"c9150b9 Dockerfile: update base image to v0.3.4 32a7400 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#67)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#registry-proxy-v100-v110","text":"","title":"Registry Proxy v1.0.0 -&gt; v1.1.0"},{"location":"changelogs/v2.6.0/#fixes_6","text":"5f69fe0 nginx: set worker_processes to auto","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance_10","text":"89687b0 rootfs: bump version to v1.1.0-dev 70a8a8b rootfs: bump version to v1.1.0","title":"Maintenance"},{"location":"changelogs/v2.6.0/#router-v250-v262","text":"","title":"Router v2.5.0 -&gt; v2.6.2"},{"location":"changelogs/v2.6.0/#features_4","text":"151916e nginx: Allow sending nginx X-Request-Id and X-Correlation-Id headers.","title":"Features"},{"location":"changelogs/v2.6.0/#refactors_2","text":"b33c18c glide: use the official kubernetes client (#259)","title":"Refactors"},{"location":"changelogs/v2.6.0/#fixes_7","text":"a729799 nginx: Enable builder PROXY PROTOCOL support 0d9b119 ngnix: handle X-Forwarded-Port and X-Forwarded-Proto properly","title":"Fixes"},{"location":"changelogs/v2.6.0/#documentation_2","text":"b20eba0 README: Correct errant references to RC in annotations table","title":"Documentation"},{"location":"changelogs/v2.6.0/#maintenance_11","text":"4afbcc6 Dockerfile: update base image to v0.3.4 5a6b004 Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#262) e38a69b nginx: update nginx to 1.11.4 (#252) 246bdc5 Dockerfile: bump deis/base to v0.3.2","title":"Maintenance"},{"location":"changelogs/v2.6.0/#slugbuilder-v241-v243","text":"","title":"Slugbuilder v2.4.1 -&gt; v2.4.3"},{"location":"changelogs/v2.6.0/#refactors_3","text":"24e0ce9 Dockerfile: simplify chown commands","title":"Refactors"},{"location":"changelogs/v2.6.0/#fixes_8","text":"37c5109 build.sh: switch to build_root before running hooks","title":"Fixes"},{"location":"changelogs/v2.6.0/#maintenance_12","text":"2a7769d Dockerfile: cleanup after installation a bit more than before and keep copyright / license files (#113) 0ff387f buildpacks: update heroku-buildpack-go to v48 4eada8d buildpacks: update heroku-buildpack-php to v110 fcb645b buildpacks: update heroku-buildpack-python to v82 69abae5 buildpacks: update heroku-buildpack-gradle to v18 d6445a6 buildpacks: update heroku-buildpack-java to v46 30ce52f buildpacks: update heroku-buildpack-go to v49 7e4e9cc buildpacks: update heroku-buildpack-php to v112","title":"Maintenance"},{"location":"changelogs/v2.6.0/#slugbuilder-v221-v222","text":"","title":"Slugbuilder v2.2.1 -&gt; v2.2.2"},{"location":"changelogs/v2.6.0/#maintenance_13","text":"098d05a Dockerfile: consolidate a few chmod and chown into one layer (#54)","title":"Maintenance"},{"location":"changelogs/v2.6.0/#workflow-cli-v251-v260","text":"","title":"Workflow CLI v2.5.1 -&gt; v2.6.0"},{"location":"changelogs/v2.6.0/#features_5","text":"c760eb1 cmd: only print version mismatch warning once (#223) a330059 git: clean up git package and write tests (#227)","title":"Features"},{"location":"changelogs/v2.6.0/#refactors_4","text":"85f2df2 Dockerfile: remove deprecated --strip-vcs flag","title":"Refactors"},{"location":"changelogs/v2.6.0/#fixes_9","text":"6b13756 CI: explicitly set codecov git SHA (#221) 2bb4cde Jenkinsfile: un-parallelize lint and test tasks","title":"Fixes"},{"location":"changelogs/v2.6.0/#documentation_3","text":"c04610d README.md: update bucket location 8745328 readme: adding codecov badge (#249)","title":"Documentation"},{"location":"changelogs/v2.6.0/#maintenance_14","text":"1041d9e Dockerfile: update go-dev and go toolchain","title":"Maintenance"},{"location":"changelogs/v2.6.0/#workflow-documentation-v250-v260","text":"","title":"Workflow Documentation v2.5.0 -&gt; v2.6.0"},{"location":"changelogs/v2.6.0/#features_6","text":"a3a25c0 scripts: build every tagged version of workflow docs 9ae8f9c apps: add information about IMAGE_PULL_POLICY globally and per app (#504)","title":"Features"},{"location":"changelogs/v2.6.0/#refactors_5","text":"495e1a1 configuring-registry: clarify ECR registry variables","title":"Refactors"},{"location":"changelogs/v2.6.0/#fixes_10","text":"fb5d378 releases: deisrel no longer requires $OLD_SHA and $OLD_RELEASE cb23b43 components: link to architecture, not itself (#499) c95c24b configuring-registry: add missing IAM link 6509c41 docs: add documentation on resetting a password using the cli. (#507) 7b88723 docs: change the references from RC's to deploments 54df10a deisrel: update the deisrel command to generate changelog 0e56d8a gutenbuild: do not build any pre-release tags 80f0551 gutenbuild: ensure we are on master before building 1e87307 gutenbuild: prepend grep string with -- 26d8a40 gutenbuild: use dev_build_dest for second build","title":"Fixes"},{"location":"changelogs/v2.6.0/#documentation_4","text":"8b542a1 upgrade: reminder to upgrade deis client 0ef84bc slugbuilder-cache: add CACHE_PATH variable a349d20 slugbuilder-cache: add usage documentation 1f09a8c slugbuilder-cache: add application tuning variable ec42f7b src/roadmap/releases.md: remove publish component release step a971a25 CONTRIBUTING: update contributing documentation (#498) d0a43b5 tuning: update storage default for logger 5720dce src/managing-workflow/upgrading-workflow.md: document nodes >= 2 for upgrade 5705489 src/roadmap/releases.md: link to pipeline flow diagrams 0da5297 managing-workflow: Document PROXY protocol configuration b5f2d99 releases: add missing details and reword CI flow reference","title":"Documentation"},{"location":"changelogs/v2.6.0/#maintenance_15","text":"7faaaa7 release: update roadmap for 2.5 e8c5d3f src/roadmap/releases.md: update jenkins-jobs var name 2655c90 scripts: remove old release tools and CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.6.0/#workflow-e2e-tests-v252-v253","text":"","title":"Workflow E2E Tests v2.5.2 -&gt; v2.5.3"},{"location":"changelogs/v2.6.0/#fixes_11","text":"4f00c8b tests: re-enable tls tests (#326)","title":"Fixes"},{"location":"changelogs/v2.6.0/#worklfow-manager-v241-v242","text":"","title":"Worklfow Manager v2.4.1 -&gt; v2.4.2"},{"location":"changelogs/v2.6.0/#maintenance_16","text":"350f7c3 Dockerfile: update base image to v0.3.4","title":"Maintenance"},{"location":"changelogs/v2.7.0/","text":"Workflow v2.6.0 -> v2.7.0 \u00b6 Builder v2.5.1 -> v2.5.2 \u00b6 Refactors \u00b6 3a6c891 controller: use the env config instead of directly getting from environment Fixes \u00b6 dd4f1b0 travis: remove vendor dir from cache 4a4044e sshd: Typo in the timeout message. Maintenance \u00b6 1196719 CHANGELOG: remove changelog Controller v2.6.0 -> v2.7.0 \u00b6 Features \u00b6 d63fe7f errors: give more context on what model is involved when 404 Not Found is involved (#1096) Refactors \u00b6 9baa3d3 registry: remove simpleflock and depend on Docker 1.9 minimum (#1090) Fixes \u00b6 12b5bfd key: ssh key name has to be unique now - migration included that appends a number (#1098) 8f943d9 version: Use a different version number for each release 451622b app: an app can now be removed from the database even if the namespace for it was already deleted (#1101) 9f6cb94 urls: terminate url regex with $ so that there is no cascading attempts at URLs (#1103) aa6e0f3 secret: create objectstore secret before calling scheduler deploy 53e118e procfile: validate the proctypes during build itself Maintenance \u00b6 67c5471 scheduler: move lower level deploy helpers into their respective resources (#1092) 7ba556b CHANGELOG: remove changelog (#1091) f724afe requirements: update Django to 1.10.2 9582496 requirements: update pytz to 2016.7 (#1102) Dockerbuilder v2.3.3 -> v2.4.0 \u00b6 Features \u00b6 e8763ba registry: Allow FROM to refer to the off-cluster docker registry. Refactors \u00b6 aa183bf Dockerfile: remove musl and musl-dev Maintenance \u00b6 b980335 CHANGELOG: remove changelog Minio v2.3.0 -> v2.3.1 \u00b6 Refactors \u00b6 56e25fb boot: remove unused template and POD_IP references Maintenance \u00b6 b233465 CHANGELOG: remove CHANGELOG Monitoring v2.5.1 -> v2.6.0 \u00b6 Maintenance \u00b6 08e8bae CHANGELOG: remove CHANGELOG 31f9a9e telegraf: Use the new kubernetes input plugin NSQ v2.2.2 -> v2.2.3 \u00b6 Fixes \u00b6 f675e23 Removing unneeded node address information. Router v2.6.2 -> v2.6.3 \u00b6 Fixes \u00b6 e77deec nginx: allow setting ErrorLogLevel to 'debug' 85d4a96 docs: correct annotation key for maxWorkerConnections 5efc248 nginx: known model shouldn't be refreshed if Nginx reload failed. 7c1f99d model: check if CertMapping exists Documentation \u00b6 60bf8c1 readme: remove reference to make dev-registry Maintenance \u00b6 2fc5d77 CHANGELOG: remove CHANGELOG Slugbuilder v2.4.3 -> v2.4.4 \u00b6 Maintenance \u00b6 6186982 CHANGELOG: remove CHANGELOG 4ef1326 buildpacks: update heroku-buildpack-go to v50 Workflow Charts v2.6.0 -> v2.7.0 \u00b6 Features \u00b6 00ec320 scripts: automate some of workflow release 37de884 telegraf: Use kubernetes telegraf plugin Fixes \u00b6 e22104e router,e2e: normalize strings for automation 9225708 charts: make grafana creds configurable and remove unused minio POD_IP env 16784ef workflow-dev: bump router's livenessProbe initial delay 1cac30b helm-keep: Add helm-keep annotations to all the services Maintenance \u00b6 091edb4 CHANGELOG: remove CHANGELOG 9581bd6 workflow-v2.6.0: releasing workflow-v2.6.0(-e2e) 19e5e35 workflow-v2.7.0: releasing workflow-v2.7.0(-e2e) Workflow CLI v2.6.1 -> v2.7.0 \u00b6 Features \u00b6 0391c6c keys: add an optional name support for keys:add (#257) Fixes \u00b6 1622cf6 deis.go: do not add top level command to cmdArgs 4aa36eb healthcheck: show all the healthchecks set when no proctype is specified 785a6b6 ssh: support ed25519 SSH keys 9c73132 ssh: please the gofmt gods Documentation \u00b6 dcdddaf readme: use just make for building binary on unix / darwin Maintenance \u00b6 427f8ee CHANGELOG: remove CHANGELOG Workflow Documentation v2.6.0 -> v2.7.0 \u00b6 Features \u00b6 e5bc58d reference-guide: add Deis v1 Migration Guide Fixes \u00b6 53f5134 docs: correct docs for limits:set --cpu flag (#537) 3ad28eb docs: update gke screenshot and text. (#540) 468f277 docs: minor spelling corrections (#543) 1ce3489 docs: minor spelling corrections (#541) 7259932 docs: minor spelling correction (#542) c362ecc docs: minor spelling corrections (#544) Documentation \u00b6 5553649 src/roadmap/releases.md: add registry-token-refresher to deisrel .json 5d87e32 relases: simplify Workflow release step 4 3139333 installing-workflow: add followup link to register a user Workflow E2E Tests v2.5.3 -> v2.6.0 \u00b6 Features \u00b6 b0f0e69 tests(config): add tests for config push/pull with LF and CRLF line endings. (#328) Fixes \u00b6 0722699 tests/git_push_test.go: bump deis run timeout Documentation \u00b6 723cbae README: update e2e chart name/installation Maintenance \u00b6 0183165 CHANGELOG: remove CHANGELOG (#327)","title":"v2.7.0"},{"location":"changelogs/v2.7.0/#workflow-v260-v270","text":"","title":"Workflow v2.6.0 -&gt; v2.7.0"},{"location":"changelogs/v2.7.0/#builder-v251-v252","text":"","title":"Builder v2.5.1 -&gt; v2.5.2"},{"location":"changelogs/v2.7.0/#refactors","text":"3a6c891 controller: use the env config instead of directly getting from environment","title":"Refactors"},{"location":"changelogs/v2.7.0/#fixes","text":"dd4f1b0 travis: remove vendor dir from cache 4a4044e sshd: Typo in the timeout message.","title":"Fixes"},{"location":"changelogs/v2.7.0/#maintenance","text":"1196719 CHANGELOG: remove changelog","title":"Maintenance"},{"location":"changelogs/v2.7.0/#controller-v260-v270","text":"","title":"Controller v2.6.0 -&gt; v2.7.0"},{"location":"changelogs/v2.7.0/#features","text":"d63fe7f errors: give more context on what model is involved when 404 Not Found is involved (#1096)","title":"Features"},{"location":"changelogs/v2.7.0/#refactors_1","text":"9baa3d3 registry: remove simpleflock and depend on Docker 1.9 minimum (#1090)","title":"Refactors"},{"location":"changelogs/v2.7.0/#fixes_1","text":"12b5bfd key: ssh key name has to be unique now - migration included that appends a number (#1098) 8f943d9 version: Use a different version number for each release 451622b app: an app can now be removed from the database even if the namespace for it was already deleted (#1101) 9f6cb94 urls: terminate url regex with $ so that there is no cascading attempts at URLs (#1103) aa6e0f3 secret: create objectstore secret before calling scheduler deploy 53e118e procfile: validate the proctypes during build itself","title":"Fixes"},{"location":"changelogs/v2.7.0/#maintenance_1","text":"67c5471 scheduler: move lower level deploy helpers into their respective resources (#1092) 7ba556b CHANGELOG: remove changelog (#1091) f724afe requirements: update Django to 1.10.2 9582496 requirements: update pytz to 2016.7 (#1102)","title":"Maintenance"},{"location":"changelogs/v2.7.0/#dockerbuilder-v233-v240","text":"","title":"Dockerbuilder v2.3.3 -&gt; v2.4.0"},{"location":"changelogs/v2.7.0/#features_1","text":"e8763ba registry: Allow FROM to refer to the off-cluster docker registry.","title":"Features"},{"location":"changelogs/v2.7.0/#refactors_2","text":"aa183bf Dockerfile: remove musl and musl-dev","title":"Refactors"},{"location":"changelogs/v2.7.0/#maintenance_2","text":"b980335 CHANGELOG: remove changelog","title":"Maintenance"},{"location":"changelogs/v2.7.0/#minio-v230-v231","text":"","title":"Minio v2.3.0 -&gt; v2.3.1"},{"location":"changelogs/v2.7.0/#refactors_3","text":"56e25fb boot: remove unused template and POD_IP references","title":"Refactors"},{"location":"changelogs/v2.7.0/#maintenance_3","text":"b233465 CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.7.0/#monitoring-v251-v260","text":"","title":"Monitoring v2.5.1 -&gt; v2.6.0"},{"location":"changelogs/v2.7.0/#maintenance_4","text":"08e8bae CHANGELOG: remove CHANGELOG 31f9a9e telegraf: Use the new kubernetes input plugin","title":"Maintenance"},{"location":"changelogs/v2.7.0/#nsq-v222-v223","text":"","title":"NSQ v2.2.2 -&gt; v2.2.3"},{"location":"changelogs/v2.7.0/#fixes_2","text":"f675e23 Removing unneeded node address information.","title":"Fixes"},{"location":"changelogs/v2.7.0/#router-v262-v263","text":"","title":"Router v2.6.2 -&gt; v2.6.3"},{"location":"changelogs/v2.7.0/#fixes_3","text":"e77deec nginx: allow setting ErrorLogLevel to 'debug' 85d4a96 docs: correct annotation key for maxWorkerConnections 5efc248 nginx: known model shouldn't be refreshed if Nginx reload failed. 7c1f99d model: check if CertMapping exists","title":"Fixes"},{"location":"changelogs/v2.7.0/#documentation","text":"60bf8c1 readme: remove reference to make dev-registry","title":"Documentation"},{"location":"changelogs/v2.7.0/#maintenance_5","text":"2fc5d77 CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.7.0/#slugbuilder-v243-v244","text":"","title":"Slugbuilder v2.4.3 -&gt; v2.4.4"},{"location":"changelogs/v2.7.0/#maintenance_6","text":"6186982 CHANGELOG: remove CHANGELOG 4ef1326 buildpacks: update heroku-buildpack-go to v50","title":"Maintenance"},{"location":"changelogs/v2.7.0/#workflow-charts-v260-v270","text":"","title":"Workflow Charts v2.6.0 -&gt; v2.7.0"},{"location":"changelogs/v2.7.0/#features_2","text":"00ec320 scripts: automate some of workflow release 37de884 telegraf: Use kubernetes telegraf plugin","title":"Features"},{"location":"changelogs/v2.7.0/#fixes_4","text":"e22104e router,e2e: normalize strings for automation 9225708 charts: make grafana creds configurable and remove unused minio POD_IP env 16784ef workflow-dev: bump router's livenessProbe initial delay 1cac30b helm-keep: Add helm-keep annotations to all the services","title":"Fixes"},{"location":"changelogs/v2.7.0/#maintenance_7","text":"091edb4 CHANGELOG: remove CHANGELOG 9581bd6 workflow-v2.6.0: releasing workflow-v2.6.0(-e2e) 19e5e35 workflow-v2.7.0: releasing workflow-v2.7.0(-e2e)","title":"Maintenance"},{"location":"changelogs/v2.7.0/#workflow-cli-v261-v270","text":"","title":"Workflow CLI v2.6.1 -&gt; v2.7.0"},{"location":"changelogs/v2.7.0/#features_3","text":"0391c6c keys: add an optional name support for keys:add (#257)","title":"Features"},{"location":"changelogs/v2.7.0/#fixes_5","text":"1622cf6 deis.go: do not add top level command to cmdArgs 4aa36eb healthcheck: show all the healthchecks set when no proctype is specified 785a6b6 ssh: support ed25519 SSH keys 9c73132 ssh: please the gofmt gods","title":"Fixes"},{"location":"changelogs/v2.7.0/#documentation_1","text":"dcdddaf readme: use just make for building binary on unix / darwin","title":"Documentation"},{"location":"changelogs/v2.7.0/#maintenance_8","text":"427f8ee CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.7.0/#workflow-documentation-v260-v270","text":"","title":"Workflow Documentation v2.6.0 -&gt; v2.7.0"},{"location":"changelogs/v2.7.0/#features_4","text":"e5bc58d reference-guide: add Deis v1 Migration Guide","title":"Features"},{"location":"changelogs/v2.7.0/#fixes_6","text":"53f5134 docs: correct docs for limits:set --cpu flag (#537) 3ad28eb docs: update gke screenshot and text. (#540) 468f277 docs: minor spelling corrections (#543) 1ce3489 docs: minor spelling corrections (#541) 7259932 docs: minor spelling correction (#542) c362ecc docs: minor spelling corrections (#544)","title":"Fixes"},{"location":"changelogs/v2.7.0/#documentation_2","text":"5553649 src/roadmap/releases.md: add registry-token-refresher to deisrel .json 5d87e32 relases: simplify Workflow release step 4 3139333 installing-workflow: add followup link to register a user","title":"Documentation"},{"location":"changelogs/v2.7.0/#workflow-e2e-tests-v253-v260","text":"","title":"Workflow E2E Tests v2.5.3 -&gt; v2.6.0"},{"location":"changelogs/v2.7.0/#features_5","text":"b0f0e69 tests(config): add tests for config push/pull with LF and CRLF line endings. (#328)","title":"Features"},{"location":"changelogs/v2.7.0/#fixes_7","text":"0722699 tests/git_push_test.go: bump deis run timeout","title":"Fixes"},{"location":"changelogs/v2.7.0/#documentation_3","text":"723cbae README: update e2e chart name/installation","title":"Documentation"},{"location":"changelogs/v2.7.0/#maintenance_9","text":"0183165 CHANGELOG: remove CHANGELOG (#327)","title":"Maintenance"},{"location":"changelogs/v2.8.0/","text":"Workflow v2.7.0 -> v2.8.0 \u00b6 Builder v2.5.4 -> v2.5.5 \u00b6 Fixes \u00b6 4745179 charts: Use the common storage secret Controller v2.7.1 -> v2.8.1 \u00b6 Fixes \u00b6 0d83024 deploy: add a global / per-app setting called PROCFILE_REMOVE_PROCS_ON_DEPLOY to allow turning off / on removal of processes on deploys (#1099) 1c0350a registration: allow admin user registration when the mode is admin_only 172d91b registration: Add support to change the default regsitration mode eb2104a release: Don't rollback if there is no build Documentation \u00b6 a230913 readme: fix links to virtualenv docs 946de66 readme: fix links to virtualenv docs 40e8be1 README: docs(README) Refer to postgres setup in Makefile f0fea19 README: Recommend installing python via pyenv Maintenance \u00b6 70a6853 tests: add test for ed25519 SSH keys d2ff507 tests: add hook tests for ECDSA and ED25519 SSH keys 796668a requirements: update PyOpenSSL to 16.2.0 (#1114) 58d5ae7 requirements: update docker-py to 1.10.4 (#1115) 1dd4093 requirements: update to DRF 3.5.1 (#1120) Dockerbuilder v2.4.1 -> v2.5.0 \u00b6 Features \u00b6 1df9223 deploy.py: add pull option Fluentd v2.4.2 -> v2.4.3 \u00b6 Features \u00b6 ceaa347 elasticsearch: Add support for dropping fluentd's own logs to stop an infinite death spiral Fixes \u00b6 d3523b3 boot/deis: Fix conditional for disabling deis output Logging v2.3.1 -> v2.3.2 \u00b6 Features \u00b6 9bf8520 charts: Add helm charts for logger Fixes \u00b6 2c838b3 server_test: skip TestServerClose Maintenance \u00b6 e36fe0f CHANGELOG: remove CHANGELOG Logger-Redis v2.2.2 -> v2.2.3 \u00b6 Features \u00b6 bf58552 charts: Add helm charts for redis Minio v2.3.1 -> v2.3.3 \u00b6 Features \u00b6 1f63beb charts: Add helm charts for minio Fixes \u00b6 7b1db94 docs: fix link location to deis documentation (#121) Monitoring v2.6.1 -> v2.6.2 \u00b6 Features \u00b6 adedd69 monitor: Allow for off cluster influxdb Fixes \u00b6 c177c70 grafana,telegraf: make curl fail on unsuccessful HTTP codes Maintenance \u00b6 e008741 grafana: Update dashboards for new telegraf NSQ v2.2.3 -> v2.2.4 \u00b6 Features \u00b6 6d01e7e charts: Add helm charts for nsq Postgres v2.2.5 -> v2.2.6 \u00b6 Fixes \u00b6 4bb00a1 charts: Use the common storage secret Registry v2.2.2 -> v2.2.4 \u00b6 Features \u00b6 5614cf7 charts: Add helm charts for registry Fixes \u00b6 e4bbb57 charts: Use the common storage secret Maintenance \u00b6 a46404c CHANGELOG: remove CHANGELOG Registry Proxy v1.1.0 -> v1.1.1 \u00b6 Features \u00b6 a9e1d48 charts: Add helm charts for registry proxy Maintenance \u00b6 62ad655 rootfs: bump version to v1.2.0-dev Registry Token Refresher v1.0.2 -> v1.0.3 \u00b6 Features \u00b6 ec09ac2 charts: Add helm charts for registry token refresher Router v2.6.3 -> v2.6.5 \u00b6 Features \u00b6 0241013 charts: Add helm charts for the router Fixes \u00b6 646b1c6 charts: bump router's livenessProbe initial delay Maintenance \u00b6 fbdc2c6 nginx: update nginx to 1.11.5 Slugbuilder v2.4.4 -> v2.4.5 \u00b6 Features \u00b6 844021a charts: Add helm charts for slugbuilder Slugrunner v2.2.2 -> v2.2.3 \u00b6 Features \u00b6 e4dc4ae charts: Add helm charts for slugrunner Maintenance \u00b6 d45accb CHANGELOG: remove CHANGELOG Workflow Documentation v2.7.0 -> v2.8.0 \u00b6 Features \u00b6 4196ca3 deploys: Add new configuration options to Controller introduced in controller/#1099 (#551) 659116d charts: Add helm charts for workflow bef1728 helm: Add instruction to install workflow using the new helm d793606 charts: Add support for external influxdb and changing registration mode Fixes \u00b6 330945d troubleshooting: remove reference to Workflow version 34d96c5 charts: Add workflow manager production urls for the release charts Documentation \u00b6 8c48e28 object-storage: document the required STORAGE_TYPE env var (#547) df70784 readme: adding workflow-manager to list of components (#549) 43ff1b6 installing/platform-logging: Update docs for off-cluster installs e1b6b0b Documentation changes, suggestions, fixes (#548) 8d8b7ec readme: add nsq to list of deis components (#550) 297307c upgrading-workflow: Add instructions to preserve platform SSL credentials (#561) f8841b7 Update boot.md 3c57d88 Fix minor typo (#572) Workflow CLI v2.7.0 -> v2.7.1 \u00b6 Features \u00b6 950e1ad Jenkinsfile: send slack channel to downstream test job Tests \u00b6 6c9c935 auth: add test for whoami --all (#261) Workflow E2E Tests v2.6.0 -> v2.6.1 \u00b6 Features \u00b6 bf3a560 charts: Add helm charts for workflow-e2e Workflow Manager v2.4.2 -> v2.4.3 \u00b6 Features \u00b6 80af9c3 charts: Add helm charts for workflow-manager Maintenance \u00b6 43f1251 CHANGELOG: remove CHANGELOG","title":"v2.8.0"},{"location":"changelogs/v2.8.0/#workflow-v270-v280","text":"","title":"Workflow v2.7.0 -&gt; v2.8.0"},{"location":"changelogs/v2.8.0/#builder-v254-v255","text":"","title":"Builder v2.5.4 -&gt; v2.5.5"},{"location":"changelogs/v2.8.0/#fixes","text":"4745179 charts: Use the common storage secret","title":"Fixes"},{"location":"changelogs/v2.8.0/#controller-v271-v281","text":"","title":"Controller v2.7.1 -&gt; v2.8.1"},{"location":"changelogs/v2.8.0/#fixes_1","text":"0d83024 deploy: add a global / per-app setting called PROCFILE_REMOVE_PROCS_ON_DEPLOY to allow turning off / on removal of processes on deploys (#1099) 1c0350a registration: allow admin user registration when the mode is admin_only 172d91b registration: Add support to change the default regsitration mode eb2104a release: Don't rollback if there is no build","title":"Fixes"},{"location":"changelogs/v2.8.0/#documentation","text":"a230913 readme: fix links to virtualenv docs 946de66 readme: fix links to virtualenv docs 40e8be1 README: docs(README) Refer to postgres setup in Makefile f0fea19 README: Recommend installing python via pyenv","title":"Documentation"},{"location":"changelogs/v2.8.0/#maintenance","text":"70a6853 tests: add test for ed25519 SSH keys d2ff507 tests: add hook tests for ECDSA and ED25519 SSH keys 796668a requirements: update PyOpenSSL to 16.2.0 (#1114) 58d5ae7 requirements: update docker-py to 1.10.4 (#1115) 1dd4093 requirements: update to DRF 3.5.1 (#1120)","title":"Maintenance"},{"location":"changelogs/v2.8.0/#dockerbuilder-v241-v250","text":"","title":"Dockerbuilder v2.4.1 -&gt; v2.5.0"},{"location":"changelogs/v2.8.0/#features","text":"1df9223 deploy.py: add pull option","title":"Features"},{"location":"changelogs/v2.8.0/#fluentd-v242-v243","text":"","title":"Fluentd v2.4.2 -&gt; v2.4.3"},{"location":"changelogs/v2.8.0/#features_1","text":"ceaa347 elasticsearch: Add support for dropping fluentd's own logs to stop an infinite death spiral","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_2","text":"d3523b3 boot/deis: Fix conditional for disabling deis output","title":"Fixes"},{"location":"changelogs/v2.8.0/#logging-v231-v232","text":"","title":"Logging v2.3.1 -&gt; v2.3.2"},{"location":"changelogs/v2.8.0/#features_2","text":"9bf8520 charts: Add helm charts for logger","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_3","text":"2c838b3 server_test: skip TestServerClose","title":"Fixes"},{"location":"changelogs/v2.8.0/#maintenance_1","text":"e36fe0f CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.8.0/#logger-redis-v222-v223","text":"","title":"Logger-Redis v2.2.2 -&gt; v2.2.3"},{"location":"changelogs/v2.8.0/#features_3","text":"bf58552 charts: Add helm charts for redis","title":"Features"},{"location":"changelogs/v2.8.0/#minio-v231-v233","text":"","title":"Minio v2.3.1 -&gt; v2.3.3"},{"location":"changelogs/v2.8.0/#features_4","text":"1f63beb charts: Add helm charts for minio","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_4","text":"7b1db94 docs: fix link location to deis documentation (#121)","title":"Fixes"},{"location":"changelogs/v2.8.0/#monitoring-v261-v262","text":"","title":"Monitoring v2.6.1 -&gt; v2.6.2"},{"location":"changelogs/v2.8.0/#features_5","text":"adedd69 monitor: Allow for off cluster influxdb","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_5","text":"c177c70 grafana,telegraf: make curl fail on unsuccessful HTTP codes","title":"Fixes"},{"location":"changelogs/v2.8.0/#maintenance_2","text":"e008741 grafana: Update dashboards for new telegraf","title":"Maintenance"},{"location":"changelogs/v2.8.0/#nsq-v223-v224","text":"","title":"NSQ v2.2.3 -&gt; v2.2.4"},{"location":"changelogs/v2.8.0/#features_6","text":"6d01e7e charts: Add helm charts for nsq","title":"Features"},{"location":"changelogs/v2.8.0/#postgres-v225-v226","text":"","title":"Postgres v2.2.5 -&gt; v2.2.6"},{"location":"changelogs/v2.8.0/#fixes_6","text":"4bb00a1 charts: Use the common storage secret","title":"Fixes"},{"location":"changelogs/v2.8.0/#registry-v222-v224","text":"","title":"Registry v2.2.2 -&gt; v2.2.4"},{"location":"changelogs/v2.8.0/#features_7","text":"5614cf7 charts: Add helm charts for registry","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_7","text":"e4bbb57 charts: Use the common storage secret","title":"Fixes"},{"location":"changelogs/v2.8.0/#maintenance_3","text":"a46404c CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.8.0/#registry-proxy-v110-v111","text":"","title":"Registry Proxy v1.1.0 -&gt; v1.1.1"},{"location":"changelogs/v2.8.0/#features_8","text":"a9e1d48 charts: Add helm charts for registry proxy","title":"Features"},{"location":"changelogs/v2.8.0/#maintenance_4","text":"62ad655 rootfs: bump version to v1.2.0-dev","title":"Maintenance"},{"location":"changelogs/v2.8.0/#registry-token-refresher-v102-v103","text":"","title":"Registry Token Refresher v1.0.2 -&gt; v1.0.3"},{"location":"changelogs/v2.8.0/#features_9","text":"ec09ac2 charts: Add helm charts for registry token refresher","title":"Features"},{"location":"changelogs/v2.8.0/#router-v263-v265","text":"","title":"Router v2.6.3 -&gt; v2.6.5"},{"location":"changelogs/v2.8.0/#features_10","text":"0241013 charts: Add helm charts for the router","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_8","text":"646b1c6 charts: bump router's livenessProbe initial delay","title":"Fixes"},{"location":"changelogs/v2.8.0/#maintenance_5","text":"fbdc2c6 nginx: update nginx to 1.11.5","title":"Maintenance"},{"location":"changelogs/v2.8.0/#slugbuilder-v244-v245","text":"","title":"Slugbuilder v2.4.4 -&gt; v2.4.5"},{"location":"changelogs/v2.8.0/#features_11","text":"844021a charts: Add helm charts for slugbuilder","title":"Features"},{"location":"changelogs/v2.8.0/#slugrunner-v222-v223","text":"","title":"Slugrunner v2.2.2 -&gt; v2.2.3"},{"location":"changelogs/v2.8.0/#features_12","text":"e4dc4ae charts: Add helm charts for slugrunner","title":"Features"},{"location":"changelogs/v2.8.0/#maintenance_6","text":"d45accb CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.8.0/#workflow-documentation-v270-v280","text":"","title":"Workflow Documentation v2.7.0 -&gt; v2.8.0"},{"location":"changelogs/v2.8.0/#features_13","text":"4196ca3 deploys: Add new configuration options to Controller introduced in controller/#1099 (#551) 659116d charts: Add helm charts for workflow bef1728 helm: Add instruction to install workflow using the new helm d793606 charts: Add support for external influxdb and changing registration mode","title":"Features"},{"location":"changelogs/v2.8.0/#fixes_9","text":"330945d troubleshooting: remove reference to Workflow version 34d96c5 charts: Add workflow manager production urls for the release charts","title":"Fixes"},{"location":"changelogs/v2.8.0/#documentation_1","text":"8c48e28 object-storage: document the required STORAGE_TYPE env var (#547) df70784 readme: adding workflow-manager to list of components (#549) 43ff1b6 installing/platform-logging: Update docs for off-cluster installs e1b6b0b Documentation changes, suggestions, fixes (#548) 8d8b7ec readme: add nsq to list of deis components (#550) 297307c upgrading-workflow: Add instructions to preserve platform SSL credentials (#561) f8841b7 Update boot.md 3c57d88 Fix minor typo (#572)","title":"Documentation"},{"location":"changelogs/v2.8.0/#workflow-cli-v270-v271","text":"","title":"Workflow CLI v2.7.0 -&gt; v2.7.1"},{"location":"changelogs/v2.8.0/#features_14","text":"950e1ad Jenkinsfile: send slack channel to downstream test job","title":"Features"},{"location":"changelogs/v2.8.0/#tests","text":"6c9c935 auth: add test for whoami --all (#261)","title":"Tests"},{"location":"changelogs/v2.8.0/#workflow-e2e-tests-v260-v261","text":"","title":"Workflow E2E Tests v2.6.0 -&gt; v2.6.1"},{"location":"changelogs/v2.8.0/#features_15","text":"bf3a560 charts: Add helm charts for workflow-e2e","title":"Features"},{"location":"changelogs/v2.8.0/#workflow-manager-v242-v243","text":"","title":"Workflow Manager v2.4.2 -&gt; v2.4.3"},{"location":"changelogs/v2.8.0/#features_16","text":"80af9c3 charts: Add helm charts for workflow-manager","title":"Features"},{"location":"changelogs/v2.8.0/#maintenance_7","text":"43f1251 CHANGELOG: remove CHANGELOG","title":"Maintenance"},{"location":"changelogs/v2.9.0/","text":"Workflow v2.8.0 -> v2.9.0 \u00b6 Releases \u00b6 builder v2.5.4 -> v2.6.1 charts v2.8.0 -> v2.9.0 controller v2.8.1 -> v2.9.0 dockerbuilder v2.5.0 -> v2.5.2 fluentd v2.4.3 -> v2.5.0 logger v2.3.2 -> v2.4.0 minio v2.3.3 -> v2.3.4 monitor v2.6.2 -> v2.7.0 nsq v2.2.4 -> v2.2.5 postgres v2.2.5 -> v2.4.4 redis v2.2.3 -> v2.2.4 registry v2.2.3 -> v2.3.1 registry-token-refresher v1.0.3 -> v1.0.4 router v2.6.5 -> v2.7.0 slugbuilder v2.4.5 -> v2.4.7 slugrunner v2.2.3 -> v2.2.4 workflow-cli v2.8.0 -> v2.9.1 workflow-e2e v2.6.1 -> v2.7.1 workflow-manager v2.4.3 -> v2.4.4 Features \u00b6 ea9e648 (charts) - workflow-dev: add preStop hook to postgres 26c78ee (controller) - limits-cmd: accept new limits:set value type bc4f452 (controller) - label-cmd: support new label cmd a01c455 (fluentd) - deis_out: Add time to record when publishing to nsq 7498fe5 (logger) - model/message_handler: Add time to log message output c105495 (minio) - travis: add codecov 444838e (postgres) - charts: add backup to preStop hook 19466c5 (router) - charts: Add support to add annotations during install 07747dd (workflow-cli) - cmd: allow config:set FOO=\"\" 029f39e (workflow-cli) - label-cmd: add Label cmd 8ab113f (workflow-cli) - label-cmd: update controller-sdk-go dependency 8955e7e (workflow-cli) - cmd/labels.go: sort labels when listing 874c9e0 (workflow-e2e) - label-cmd: add Label cmd Refactors \u00b6 67c0a3f (charts) - workflow-dev: make PGCTLTIMEOUT tunable a026223 (postgres) - rootfs: remove timeout to pg_ctl start fe9364e (postgres) - backup: bump default base backup interval to 4h 3af1129 (registry) - Dockerfile: use upstream registry image Fixes \u00b6 4745179 (builder) - charts: Use the common storage secret 5460be8 (builder) - slugbuilder: Dont expose the conifg as env vars during build c960478 (builder) - gitreceive: clarify the error message when release failed fcd7edd (builder) - charts: Don't use caps in the configmap keys 92f7751 (charts) - workflow-dev/tpl/deis-database-deployment.yaml: rename env var 5bc0305 (charts) - workflow-dev: rewrite to avoid whitespace errors 615b834 (controller) - boot: Ensure DEIS_DEBUG==true for debug output f3daff7 (controller) - proctype: Change the regex used for validating proctypes 828c13b (controller) - port: Port can be made optional for non-routable apps 4dd1a6c (controller) - timeout-debug-msg: unresolved variable (#1148) ffeb14a (controller) - api: ensure a 409 is raised when cancelling a user with downstream objects (#1147) 06211a2 (controller) - api: transfer all downstream resources along with app (#1146) 87ef21d (dockerbuilder) - charts: Don't use caps in the configmap keys 0b6d8a9 (dockerbuilder) - move to python3 f113aac (fluentd) - elastic search: Allow the elastic search plugin to index via namespace 4c72d59 (minio) - codecov: add test-cover target 4bb00a1 (postgres) - charts: Use the common storage secret 414c534 (postgres) - test-swift: remove reliance on local swift client b63909a (postgres) - test-minio: change DNS entry to minio b7a2d5b (postgres) - setup_envdir: remove AWS_REGION from WALE_S3_ENDPOINT d1744d5 (postgres) - setup_envdir: do not set AWS_ACCESS_KEY_ID if empty 3984d62 (postgres) - gcs: Use correct env variable for the gcs service account file path 7458672 (postgres) - charts: fix typo and stanza location 388c593 (postgres) - boto: specify the region while getting s3 connection 758632d (postgres) - setup-envdir: convert AWS_REGION to WALE_S3_ENDPOINT bc77951 (postgres) - create_bucket: try default s3 region on create error 8bf4c52 (postgres) - create_bucket: propagate us-east-1 to wal-e 76bf6d8 (redis) - charts: Use proper values for offcluster redis e4bbb57 (registry) - charts: Use the common storage secret 6e27041 (registry) - boto: specify the region while getting s3 connection 384bf31 (slugbuilder) - charts: Don't use caps in the configmap keys 5b053c8 (workflow-cli) - login: User should login by default when he registers 5b06f6b (workflow-e2e) - tests/labels_test.go: adjust spacing Documentation \u00b6 bd1a6f1 (charts) - README: remove dead Travis CI badge de94939 (charts) - add note about Helm classic deprecation 1f60736 (workflow-e2e) - README: swap out helmc for helm installation instructions Tests \u00b6 a5666f1 (controller) - scheduler: confirm \"network unreachable\" raises KubeHTTPException (#1142) 92a0f8e (controller) - label-cmd: add new label cmd test d2ab260 (workflow-cli) - label-cmd: add Label cmd test Maintenance \u00b6 d08070e (builder) - Dockerfile: update deis/base to 0.3.5 3fb031a (builder) - Makefile: update deis/go-dev to 0.20.0 a5d9525 (builder) - glide.yaml: update controller-sdk-go 0fbd407 (charts) - workflow-v2.9.0: releasing workflow-v2.9.0(-e2e) 46c72dd (controller) - requirements: update Django to 1.10.3 e81be7a (controller) - requirements: update docker-py to 1.10.6 e3d66aa (controller) - Dockerfile: update deis/base to 0.3.5 6cb0dd1 (controller) - requirements: update DRF to 3.5.2 db9d44c (controller) - requirements: update DRF to 3.5.3 5921ff1 (controller) - requirements: update requests lib to 2.12.1 11d0e4b (controller) - requirements: update backoff library 2ba4e2e (dockerbuilder) - Dockerfile: update docker-py to 1.10.6 04ad320 (dockerbuilder) - Dockerfile: update deis/base to 0.3.5 e5d8a25 (fluentd) - Dockerfile: update deis/base to 0.3.5 a756744 (logger) - tests: Add more tests to increase coverage bcf8bb4 (logger) - Dockerfile: update deis/base to 0.3.5 65c2d14 (logger) - Makefile: update deis/go-dev to 0.20.0 9d496b4 (minio) - Dockerfile: update deis/base to 0.3.5 d230c2b (minio) - Makefile: update deis/go-dev to 0.20.0 0369d15 (monitor) - grafana: Add improved kubernetes health dashboard 8c44281 (monitor) - grafana: Update to 3.1.1 7a730d9 (monitor) - Dockerfiles: update deis/base to 0.3.5 a35ed28 (nsq) - Dockerfile: update deis/base to 0.3.5 42225fd (postgres) - Dockerfile: bump to wal-e v1.0.1 99e5254 (postgres) - Dockerfile: bump PG_VERSION to 9.4.10-1.pgdg16.04+1 c8f3d28 (postgres) - Dockerfile: bump boto to 2.43.0 3f80837 (postgres) - Dockerfile: update deis/base to 0.3.5 8c85530 (postgres) - Makefile: update deis/go-dev to 0.20.0 6d8f6b4 (redis) - Dockerfile: update deis/base to 0.3.5 9f3e88f (registry) - Dockerfile: update deis/base to v0.3.5 edb65d5 (registry) - Makefile: update docker-go-dev to 0.20.0 5ef240b (registry-token-refresher) - Dockerfile: update deis/base to v0.3.5 1380b20 (registry-token-refresher) - Makefile: update deis/docker-go-dev to 0.20.0 ee40fe5 (router) - Makefile: bump docker-go-dev to 0.20.0 fd563fe (router) - Dockerfile: update deis/base to v0.3.5 99316f6 (router) - nginx: update nginx to 1.11.6 7960638 (slugbuilder) - buildpacks: update heroku-buildpack-php to v113 44f1194 (slugbuilder) - buildpacks: update heroku-buildpack-go to v52 f749395 (slugbuilder) - Makefile: bump deis/docker-go-dev to 0.20.0 8a62e05 (slugbuilder) - buildpacks: update heroku-buildpack-python to v83 bf8cd6d (slugbuilder) - buildpacks: update heroku-buildpack-php to v114 aefdf03 (slugbuilder) - buildpacks: update heroku-buildpack-python to v85 920815c (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v148 2bed510 (slugbuilder) - buildpacks: update heroku-buildpack-java to v48 3d308c8 (slugbuilder) - buildpacks: update heroku-buildpack-grails to v21 ba9a77d (slugrunner) - Makefile: update deis/docker-go-dev to 0.20.0 f290693 (workflow-cli) - glide: update controller-sdk-go package 5ed663b (workflow-e2e) - apps_test: Fix up logger tests for new log format 96c5779 (workflow-e2e) - Dockerfile: bump deis/docker-go-dev to 0.19.0 (#336) f9cbec4 (workflow-e2e) - Dockerfile: bump kubectl version df3684f (workflow-manager) - Dockerfile: bump deis/base to v0.3.5 e267d45 (workflow-manager) - Makefile: bump deis/docker-go-dev to 0.20.0 dea4480 (workflow-manager) - Makefile: update goswagger/swagger to 0.7.3","title":"v2.9.0"},{"location":"changelogs/v2.9.0/#workflow-v280-v290","text":"","title":"Workflow v2.8.0 -&gt; v2.9.0"},{"location":"changelogs/v2.9.0/#releases","text":"builder v2.5.4 -> v2.6.1 charts v2.8.0 -> v2.9.0 controller v2.8.1 -> v2.9.0 dockerbuilder v2.5.0 -> v2.5.2 fluentd v2.4.3 -> v2.5.0 logger v2.3.2 -> v2.4.0 minio v2.3.3 -> v2.3.4 monitor v2.6.2 -> v2.7.0 nsq v2.2.4 -> v2.2.5 postgres v2.2.5 -> v2.4.4 redis v2.2.3 -> v2.2.4 registry v2.2.3 -> v2.3.1 registry-token-refresher v1.0.3 -> v1.0.4 router v2.6.5 -> v2.7.0 slugbuilder v2.4.5 -> v2.4.7 slugrunner v2.2.3 -> v2.2.4 workflow-cli v2.8.0 -> v2.9.1 workflow-e2e v2.6.1 -> v2.7.1 workflow-manager v2.4.3 -> v2.4.4","title":"Releases"},{"location":"changelogs/v2.9.0/#features","text":"ea9e648 (charts) - workflow-dev: add preStop hook to postgres 26c78ee (controller) - limits-cmd: accept new limits:set value type bc4f452 (controller) - label-cmd: support new label cmd a01c455 (fluentd) - deis_out: Add time to record when publishing to nsq 7498fe5 (logger) - model/message_handler: Add time to log message output c105495 (minio) - travis: add codecov 444838e (postgres) - charts: add backup to preStop hook 19466c5 (router) - charts: Add support to add annotations during install 07747dd (workflow-cli) - cmd: allow config:set FOO=\"\" 029f39e (workflow-cli) - label-cmd: add Label cmd 8ab113f (workflow-cli) - label-cmd: update controller-sdk-go dependency 8955e7e (workflow-cli) - cmd/labels.go: sort labels when listing 874c9e0 (workflow-e2e) - label-cmd: add Label cmd","title":"Features"},{"location":"changelogs/v2.9.0/#refactors","text":"67c0a3f (charts) - workflow-dev: make PGCTLTIMEOUT tunable a026223 (postgres) - rootfs: remove timeout to pg_ctl start fe9364e (postgres) - backup: bump default base backup interval to 4h 3af1129 (registry) - Dockerfile: use upstream registry image","title":"Refactors"},{"location":"changelogs/v2.9.0/#fixes","text":"4745179 (builder) - charts: Use the common storage secret 5460be8 (builder) - slugbuilder: Dont expose the conifg as env vars during build c960478 (builder) - gitreceive: clarify the error message when release failed fcd7edd (builder) - charts: Don't use caps in the configmap keys 92f7751 (charts) - workflow-dev/tpl/deis-database-deployment.yaml: rename env var 5bc0305 (charts) - workflow-dev: rewrite to avoid whitespace errors 615b834 (controller) - boot: Ensure DEIS_DEBUG==true for debug output f3daff7 (controller) - proctype: Change the regex used for validating proctypes 828c13b (controller) - port: Port can be made optional for non-routable apps 4dd1a6c (controller) - timeout-debug-msg: unresolved variable (#1148) ffeb14a (controller) - api: ensure a 409 is raised when cancelling a user with downstream objects (#1147) 06211a2 (controller) - api: transfer all downstream resources along with app (#1146) 87ef21d (dockerbuilder) - charts: Don't use caps in the configmap keys 0b6d8a9 (dockerbuilder) - move to python3 f113aac (fluentd) - elastic search: Allow the elastic search plugin to index via namespace 4c72d59 (minio) - codecov: add test-cover target 4bb00a1 (postgres) - charts: Use the common storage secret 414c534 (postgres) - test-swift: remove reliance on local swift client b63909a (postgres) - test-minio: change DNS entry to minio b7a2d5b (postgres) - setup_envdir: remove AWS_REGION from WALE_S3_ENDPOINT d1744d5 (postgres) - setup_envdir: do not set AWS_ACCESS_KEY_ID if empty 3984d62 (postgres) - gcs: Use correct env variable for the gcs service account file path 7458672 (postgres) - charts: fix typo and stanza location 388c593 (postgres) - boto: specify the region while getting s3 connection 758632d (postgres) - setup-envdir: convert AWS_REGION to WALE_S3_ENDPOINT bc77951 (postgres) - create_bucket: try default s3 region on create error 8bf4c52 (postgres) - create_bucket: propagate us-east-1 to wal-e 76bf6d8 (redis) - charts: Use proper values for offcluster redis e4bbb57 (registry) - charts: Use the common storage secret 6e27041 (registry) - boto: specify the region while getting s3 connection 384bf31 (slugbuilder) - charts: Don't use caps in the configmap keys 5b053c8 (workflow-cli) - login: User should login by default when he registers 5b06f6b (workflow-e2e) - tests/labels_test.go: adjust spacing","title":"Fixes"},{"location":"changelogs/v2.9.0/#documentation","text":"bd1a6f1 (charts) - README: remove dead Travis CI badge de94939 (charts) - add note about Helm classic deprecation 1f60736 (workflow-e2e) - README: swap out helmc for helm installation instructions","title":"Documentation"},{"location":"changelogs/v2.9.0/#tests","text":"a5666f1 (controller) - scheduler: confirm \"network unreachable\" raises KubeHTTPException (#1142) 92a0f8e (controller) - label-cmd: add new label cmd test d2ab260 (workflow-cli) - label-cmd: add Label cmd test","title":"Tests"},{"location":"changelogs/v2.9.0/#maintenance","text":"d08070e (builder) - Dockerfile: update deis/base to 0.3.5 3fb031a (builder) - Makefile: update deis/go-dev to 0.20.0 a5d9525 (builder) - glide.yaml: update controller-sdk-go 0fbd407 (charts) - workflow-v2.9.0: releasing workflow-v2.9.0(-e2e) 46c72dd (controller) - requirements: update Django to 1.10.3 e81be7a (controller) - requirements: update docker-py to 1.10.6 e3d66aa (controller) - Dockerfile: update deis/base to 0.3.5 6cb0dd1 (controller) - requirements: update DRF to 3.5.2 db9d44c (controller) - requirements: update DRF to 3.5.3 5921ff1 (controller) - requirements: update requests lib to 2.12.1 11d0e4b (controller) - requirements: update backoff library 2ba4e2e (dockerbuilder) - Dockerfile: update docker-py to 1.10.6 04ad320 (dockerbuilder) - Dockerfile: update deis/base to 0.3.5 e5d8a25 (fluentd) - Dockerfile: update deis/base to 0.3.5 a756744 (logger) - tests: Add more tests to increase coverage bcf8bb4 (logger) - Dockerfile: update deis/base to 0.3.5 65c2d14 (logger) - Makefile: update deis/go-dev to 0.20.0 9d496b4 (minio) - Dockerfile: update deis/base to 0.3.5 d230c2b (minio) - Makefile: update deis/go-dev to 0.20.0 0369d15 (monitor) - grafana: Add improved kubernetes health dashboard 8c44281 (monitor) - grafana: Update to 3.1.1 7a730d9 (monitor) - Dockerfiles: update deis/base to 0.3.5 a35ed28 (nsq) - Dockerfile: update deis/base to 0.3.5 42225fd (postgres) - Dockerfile: bump to wal-e v1.0.1 99e5254 (postgres) - Dockerfile: bump PG_VERSION to 9.4.10-1.pgdg16.04+1 c8f3d28 (postgres) - Dockerfile: bump boto to 2.43.0 3f80837 (postgres) - Dockerfile: update deis/base to 0.3.5 8c85530 (postgres) - Makefile: update deis/go-dev to 0.20.0 6d8f6b4 (redis) - Dockerfile: update deis/base to 0.3.5 9f3e88f (registry) - Dockerfile: update deis/base to v0.3.5 edb65d5 (registry) - Makefile: update docker-go-dev to 0.20.0 5ef240b (registry-token-refresher) - Dockerfile: update deis/base to v0.3.5 1380b20 (registry-token-refresher) - Makefile: update deis/docker-go-dev to 0.20.0 ee40fe5 (router) - Makefile: bump docker-go-dev to 0.20.0 fd563fe (router) - Dockerfile: update deis/base to v0.3.5 99316f6 (router) - nginx: update nginx to 1.11.6 7960638 (slugbuilder) - buildpacks: update heroku-buildpack-php to v113 44f1194 (slugbuilder) - buildpacks: update heroku-buildpack-go to v52 f749395 (slugbuilder) - Makefile: bump deis/docker-go-dev to 0.20.0 8a62e05 (slugbuilder) - buildpacks: update heroku-buildpack-python to v83 bf8cd6d (slugbuilder) - buildpacks: update heroku-buildpack-php to v114 aefdf03 (slugbuilder) - buildpacks: update heroku-buildpack-python to v85 920815c (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v148 2bed510 (slugbuilder) - buildpacks: update heroku-buildpack-java to v48 3d308c8 (slugbuilder) - buildpacks: update heroku-buildpack-grails to v21 ba9a77d (slugrunner) - Makefile: update deis/docker-go-dev to 0.20.0 f290693 (workflow-cli) - glide: update controller-sdk-go package 5ed663b (workflow-e2e) - apps_test: Fix up logger tests for new log format 96c5779 (workflow-e2e) - Dockerfile: bump deis/docker-go-dev to 0.19.0 (#336) f9cbec4 (workflow-e2e) - Dockerfile: bump kubectl version df3684f (workflow-manager) - Dockerfile: bump deis/base to v0.3.5 e267d45 (workflow-manager) - Makefile: bump deis/docker-go-dev to 0.20.0 dea4480 (workflow-manager) - Makefile: update goswagger/swagger to 0.7.3","title":"Maintenance"},{"location":"changelogs/v2.9.1/","text":"Workflow v2.9.0 -> v2.9.1 \u00b6 Releases \u00b6 controller v2.9.0 -> v2.9.1 slugbuilder v2.4.7 -> v2.4.8 Fixes \u00b6 d723de6 (controller) - api: account for NoneType when resource is gone (#1178) ebeb922 (slugbuilder) - env_dir: Remove directories from the env dir passed to the compile e058fa2 (slugbuilder) - ssh: read the ssh key from dir instead of environment Maintenance \u00b6 673ce82 (slugbuilder) - buildpacks: update heroku-buildpack-php to v115 998b7ce (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v149 195c4f2 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v19 03ab39a (slugbuilder) - buildpacks: update heroku-buildpack-php to v116 51514b1 (slugbuilder) - buildpacks: update heroku-buildpack-go to v54","title":"v2.9.1"},{"location":"changelogs/v2.9.1/#workflow-v290-v291","text":"","title":"Workflow v2.9.0 -&gt; v2.9.1"},{"location":"changelogs/v2.9.1/#releases","text":"controller v2.9.0 -> v2.9.1 slugbuilder v2.4.7 -> v2.4.8","title":"Releases"},{"location":"changelogs/v2.9.1/#fixes","text":"d723de6 (controller) - api: account for NoneType when resource is gone (#1178) ebeb922 (slugbuilder) - env_dir: Remove directories from the env dir passed to the compile e058fa2 (slugbuilder) - ssh: read the ssh key from dir instead of environment","title":"Fixes"},{"location":"changelogs/v2.9.1/#maintenance","text":"673ce82 (slugbuilder) - buildpacks: update heroku-buildpack-php to v115 998b7ce (slugbuilder) - buildpacks: update heroku-buildpack-ruby to v149 195c4f2 (slugbuilder) - buildpacks: update heroku-buildpack-gradle to v19 03ab39a (slugbuilder) - buildpacks: update heroku-buildpack-php to v116 51514b1 (slugbuilder) - buildpacks: update heroku-buildpack-go to v54","title":"Maintenance"},{"location":"contributing/community/","text":"Community \u00b6 Deis software is fully open source. As such, the \"Deis community\" consists of anyone who uses the Deis software and participates in its evolution, whether by answering questions, finding bugs, suggesting enhancements, or writing documentation or code. Deis development is coordinated through numerous project repositories on GitHub . Anyone can check out the source code for any Deis component, fork it, make improvements, and create a pull request to offer those changes back to the Deis community. Engine Yard maintains the numerous Deis projects, and as such, decides what ends up in the official GitHub repositories. Deis depends on the contributions of the community; the maintainers will not ignore pull requests or issues. Deis uses the timeless, highly efficient, and totally unfair system known as \"Benevolent Dictator for Life\" ( BDFL ). Gabriel Monroy , the creator of Deis, is our BDFL and has final say over all decisions related to Deis. Open Source Bounties \u00b6 Deis projects are bounty-friendly. We believe open source bounty sites can be constructive tools in the development of open source software. Community members are encouraged to a) offer bounties and b) receive bounties for open source contributions that benefit everyone. The Deis maintainers, however, will not accept bounties on this project but are more than happy to help community members attempting bounties.","title":"Community"},{"location":"contributing/community/#community","text":"Deis software is fully open source. As such, the \"Deis community\" consists of anyone who uses the Deis software and participates in its evolution, whether by answering questions, finding bugs, suggesting enhancements, or writing documentation or code. Deis development is coordinated through numerous project repositories on GitHub . Anyone can check out the source code for any Deis component, fork it, make improvements, and create a pull request to offer those changes back to the Deis community. Engine Yard maintains the numerous Deis projects, and as such, decides what ends up in the official GitHub repositories. Deis depends on the contributions of the community; the maintainers will not ignore pull requests or issues. Deis uses the timeless, highly efficient, and totally unfair system known as \"Benevolent Dictator for Life\" ( BDFL ). Gabriel Monroy , the creator of Deis, is our BDFL and has final say over all decisions related to Deis.","title":"Community"},{"location":"contributing/community/#open-source-bounties","text":"Deis projects are bounty-friendly. We believe open source bounty sites can be constructive tools in the development of open source software. Community members are encouraged to a) offer bounties and b) receive bounties for open source contributions that benefit everyone. The Deis maintainers, however, will not accept bounties on this project but are more than happy to help community members attempting bounties.","title":"Open Source Bounties"},{"location":"contributing/conduct/","text":"Conduct \u00b6 The Deis community welcomes and encourages participation by everyone . No matter how you identify yourself or how others perceive you: we welcome you. We welcome contributions from everyone as long as they interact constructively with our community. The Deis developer community continues to grow, and it is inevitable that disagreements and conflict will arise. We ask that participants conduct themselves according to these principles: Be welcoming, friendly, and patient. Be considerate. Your work will be used by other people, and you in turn will depend on the work of others. Any decision you take will affect users and colleagues, and you should take those consequences into account when making decisions. Remember that we're a world-wide community, so you might not be communicating in someone else's primary language. Be respectful. Not all of us will agree all the time, but disagreement is no excuse for poor behavior and bad manners. We might all experience some frustration now and then, but we cannot allow that frustration to turn into a personal attack. It\u2019s important to remember that a community where people feel uncomfortable or threatened is not a productive one. Be careful in the words that you choose. Be kind to others. Do not insult or put down other participants. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are never appropriate for the community. (Thanks to the Debian and Django communities for their text and their inspiration.)","title":"Conduct"},{"location":"contributing/conduct/#conduct","text":"The Deis community welcomes and encourages participation by everyone . No matter how you identify yourself or how others perceive you: we welcome you. We welcome contributions from everyone as long as they interact constructively with our community. The Deis developer community continues to grow, and it is inevitable that disagreements and conflict will arise. We ask that participants conduct themselves according to these principles: Be welcoming, friendly, and patient. Be considerate. Your work will be used by other people, and you in turn will depend on the work of others. Any decision you take will affect users and colleagues, and you should take those consequences into account when making decisions. Remember that we're a world-wide community, so you might not be communicating in someone else's primary language. Be respectful. Not all of us will agree all the time, but disagreement is no excuse for poor behavior and bad manners. We might all experience some frustration now and then, but we cannot allow that frustration to turn into a personal attack. It\u2019s important to remember that a community where people feel uncomfortable or threatened is not a productive one. Be careful in the words that you choose. Be kind to others. Do not insult or put down other participants. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are never appropriate for the community. (Thanks to the Debian and Django communities for their text and their inspiration.)","title":"Conduct"},{"location":"contributing/design-documents/","text":"Design Documents \u00b6 Before submitting a pull request which will significantly alter the behavior of any Deis component, such as a new feature or major refactoring, contributors should first open an issue representing a design document. Goals \u00b6 Design documents help ensure project contributors: Involve stakeholders as early as possible in a feature's development Ensure code changes accomplish the original motivations and design goals Establish clear acceptance criteria for a feature or change Enforce test-driven design methodology and automated test coverage Contents \u00b6 Design document issues should be named Design Doc: <change description> and contain the following sections: Goal \u00b6 This section should briefly describe the proposed change and the motivations behind it. Tests will be written to ensure this design goal is met by the change. This section should also reference a separate GitHub issue tracking the feature or change, which will typically be assigned to a release milestone. Code Changes \u00b6 This section should detail the code changes necessary to accomplish the change, as well as the proposed implementation. This should be as detailed as necessary to help reviewers understand the change. Tests \u00b6 All changes should be covered by automated tests, either unit or integration tests (ideally both). This section should detail how tests will be written to validate that the change accomplishes the design goals and doesn't introduce any regressions. If a change cannot be sufficiently covered by automated testing, the design should be reconsidered. If there is no test coverage whatsoever for an affected section of code, a separate issue should be filed to integrate automated testing with that section of the codebase. The tests described here also form the acceptance criteria for the change, so that when it's completed maintainers can merge the pull request after confirming the tests pass CI. Approval \u00b6 A design document follows the same merge approval review process as final pull requests do, and maintainers will take extra care to ensure that any stakeholders for the change are included in the discussion and review of the design document. Once the design is accepted, the author can complete the change and submit a pull request for review. The pull request should close both the design document for the change as well as any issues that either track the issue or are closed as a result of the change. See Submitting a Pull Request for more information on pull request and commit message formatting.","title":"Design Documents"},{"location":"contributing/design-documents/#design-documents","text":"Before submitting a pull request which will significantly alter the behavior of any Deis component, such as a new feature or major refactoring, contributors should first open an issue representing a design document.","title":"Design Documents"},{"location":"contributing/design-documents/#goals","text":"Design documents help ensure project contributors: Involve stakeholders as early as possible in a feature's development Ensure code changes accomplish the original motivations and design goals Establish clear acceptance criteria for a feature or change Enforce test-driven design methodology and automated test coverage","title":"Goals"},{"location":"contributing/design-documents/#contents","text":"Design document issues should be named Design Doc: <change description> and contain the following sections:","title":"Contents"},{"location":"contributing/design-documents/#goal","text":"This section should briefly describe the proposed change and the motivations behind it. Tests will be written to ensure this design goal is met by the change. This section should also reference a separate GitHub issue tracking the feature or change, which will typically be assigned to a release milestone.","title":"Goal"},{"location":"contributing/design-documents/#code-changes","text":"This section should detail the code changes necessary to accomplish the change, as well as the proposed implementation. This should be as detailed as necessary to help reviewers understand the change.","title":"Code Changes"},{"location":"contributing/design-documents/#tests","text":"All changes should be covered by automated tests, either unit or integration tests (ideally both). This section should detail how tests will be written to validate that the change accomplishes the design goals and doesn't introduce any regressions. If a change cannot be sufficiently covered by automated testing, the design should be reconsidered. If there is no test coverage whatsoever for an affected section of code, a separate issue should be filed to integrate automated testing with that section of the codebase. The tests described here also form the acceptance criteria for the change, so that when it's completed maintainers can merge the pull request after confirming the tests pass CI.","title":"Tests"},{"location":"contributing/design-documents/#approval","text":"A design document follows the same merge approval review process as final pull requests do, and maintainers will take extra care to ensure that any stakeholders for the change are included in the discussion and review of the design document. Once the design is accepted, the author can complete the change and submit a pull request for review. The pull request should close both the design document for the change as well as any issues that either track the issue or are closed as a result of the change. See Submitting a Pull Request for more information on pull request and commit message formatting.","title":"Approval"},{"location":"contributing/development-environment/","text":"Development Environment \u00b6 This document is for developers who are interested in working directly on the Deis codebase. In this guide, we walk you through the process of setting up a development environment that is suitable for hacking on most Deis components. We try to make it simple to hack on Deis components. However, there are necessarily several moving pieces and some setup required. We welcome any suggestions for automating or simplifying this process. Note The Deis team is actively engaged in containerizing Go and Python based development environments tailored specifically for Deis development in order to minimize the setup required. This work is ongoing. Refer to the teamhephy/router project for a working example of a fully containerized development environment. If you're just getting into the Deis codebase, look for GitHub issues with the label easy-fix . These are more straightforward or low-risk issues and are a great way to become more familiar with Deis. Prerequisites \u00b6 In order to successfully compile and test Deis binaries and build Docker images of Deis components, the following are required: git Go 1.5 or later, with support for compiling to linux/amd64 glide golint shellcheck Docker (in a non-Linux environment, you will additionally want Docker Machine ) For teamhephy/controller , in particular, you will also need: Python 2.7 or later (with pip ) virtualenv ( sudo pip install virtualenv ) In most cases, you should simply install according to the instructions. There are a few special cases, though. We cover these below. Configuring Go \u00b6 If your local workstation does not support the linux/amd64 target environment, you will have to install Go from source with cross-compile support for that environment. This is because some of the components are built on your local machine and then injected into a Docker container. Homebrew users can just install with cross compiling support: $ brew install go --with-cc-common It is also straightforward to build Go from source: $ sudo su $ curl -sSL https://golang.org/dl/go1.5.src.tar.gz | tar -v -C /usr/local -xz $ cd /usr/local/go/src $ # compile Go for our default platform first, then add cross-compile support $ ./make.bash --no-clean $ GOOS=linux GOARCH=amd64 ./make.bash --no-clean Once you can compile to linux/amd64 , you should be able to compile Deis components as normal. Configuring Docker Machine (Mac) \u00b6 Deis needs Docker for building images. Docker utilizes a client/server architecture, and while the Docker client is available for Mac OS, the Docker server is dependent upon the Linux kernel. Therefore, in order to use Docker on Mac OS, Docker Machine is used to facilitate running the Docker server within a VirtualBox VM. Install Docker Machine according to the normal installation instructions, then use it to create a new VM: $ docker-machine create deis-docker \\ --driver=virtualbox \\ --virtualbox-disk-size=100000 \\ --engine-insecure-registry 10.0.0.0/8 \\ --engine-insecure-registry 172.16.0.0/12 \\ --engine-insecure-registry 192.168.0.0/16 \\ --engine-insecure-registry 100.64.0.0/10 This will create a new virtual machine named deis-docker that will take up as much as 100,000 MB of disk space. The images you build may be large, so allocating a big disk is a good idea. Once the deis-docker machine exists, source its values into your environment so your docker client knows how to use the new machine. You may even choose to add this to your bash profile or similar. $ eval \"$(docker-machine env deis-docker)\" After following these steps, some Docker Machine users report a slight delay (30 - 60 seconds) before the Docker server is ready. Note In subsequent steps, you may run a Docker registry within the deis-docker VM. Such a registry will not have a valid SSL certificate and will use HTTP instead of HTTPS. Such registries are implicitly untrusted by the Docker server (which is also running on the deis-docker VM). In order for the Docker server to trust the insecure registry, deis-docker is explicitly created to trust all registries in the IP ranges that that are reserved for use by private networks. The VM (and therefore the registry) will exist within such a range. This will effectively permit Docker pulls and pushes to such a registry. Fork the Repository \u00b6 Once the prerequisites have been met, we can begin to work with Deis components. Begin at Github by forking whichever Hephy project you would like to contribute to, then clone that fork locally. Since Hephy is predominantly written in Go, the best place to put it is under $GOPATH/src/github.com/teamhephy/ . $ mkdir -p $GOPATH/src/github.com/teamhephy $ cd $GOPATH/src/github.com/teamhephy $ git clone git@github.com:<username>/<component>.git $ cd <component> Note By checking out the forked copy into the namespace github.com/teamhephy/<component> , we are tricking the Go toolchain into seeing our fork as the \"official\" source tree. If you are going to be issuing pull requests to the upstream repository from which you forked, we suggest configuring Git such that you can easily rebase your code to the upstream repository's master branch. There are various strategies for doing this, but the most common is to add an upstream remote: $ git remote add upstream https://github.com/teamhephy/<component>.git For the sake of simplicity, you may want to point an environment variable to your Deis code - the directory containing one or more Deis components: $ export DEIS=$GOPATH/src/github.com/teamhephy Throughout the rest of this document, $DEIS refers to that location. Alternative: Forking with a Pushurl \u00b6 A number of Deis contributors prefer to pull directly from teamhephy/<component> , but push to <username>/<component> . If that workflow suits you better, you can set it up this way: $ git clone git@github.com:teamhephy/<component>.git $ cd teamhephy $ git config remote.origin.pushurl git@github.com:<username>/<component>.git In this setup, fetching and pulling code will work directly with the upstream repository, while pushing code will send changes to your fork. This makes it easy to stay up to date, but also make changes and then issue pull requests. Make Your Changes \u00b6 With your development environment set up and the code you wish to work on forked and cloned, you can begin making your changes. Test Your Changes \u00b6 Deis components each include a comprehensive suite of automated tests, mostly written in Go. See testing for instructions on running the tests. Deploying Your Changes \u00b6 Although writing and executing tests are critical to ensuring code quality, most contributors will also want to deploy their changes to a live environment, whether to make use of those changes or to test them further. The remainder of this section documents the procedure for running officially released Deis components in a development cluster and replacing any one of those with your customizations. Running a Kubernetes Cluster for Development \u00b6 To run a Kubernetes cluster locally or elsewhere to support your development activities, refer to Deis installation instructions here . Using a Development Registry \u00b6 To facilitate deploying Docker images containing your changes to your Kubernetes cluster, you will need to make use of a Docker registry. This is a location to where you can push your custom-built images and from where your Kubernetes cluster can retrieve those same images. If your development cluster runs locally (in Minikube, for instance), the most efficient and economical means of achieving this is to run a Docker registry locally as a Docker container. To facilitate this, most Deis components provide a make target to create such a registry: $ make dev-registry In a Linux environment, to begin using the registry: export DEIS_REGISTRY=<IP of the host machine>:5000 In non-Linux environments: export DEIS_REGISTRY=<IP of the deis-docker Docker Machine VM>:5000/ If your development cluster runs on a cloud provider such as Google Container Engine, a local registry such as the one above will not be accessible to your Kubernetes nodes. In such cases, a public registry such as DockerHub or quay.io will suffice. To use DockerHub for this purpose, for instance: $ export DEIS_REGISTRY=\"\" $ export IMAGE_PREFIX=<your DockerHub username> To use quay.io: $ export DEIS_REGISTRY=quay.io/ $ export IMAGE_PREFIX=<your quay.io username> Note the importance of the trailing slash. Dev / Deployment Workflow \u00b6 With a functioning Kubernetes cluster and the officially released Deis components installed onto it, deployment and further testing of any Deis component you have made changes to is facilitated by replacing the officially released component with a custom built image that contains your changes. Most Deis components include Makefiles with targets specifically intended to facilitate this workflow with minimal friction. In the general case, this workflow looks like this: Update source code and commit your changes using git Use make build to build a new Docker image Use make dev-release to generate Kubernetes manifest(s) Use make deploy to restart the component using the updated manifest This can be shortened to a one-liner using just the deploy target: $ make deploy Useful Commands \u00b6 Once your customized Deis component has been deployed, here are some helpful commands that will allow you to inspect your cluster and to troubleshoot, if necessary: See All Deis Pods \u00b6 $ kubectl --namespace=deis get pods Describe a Pod \u00b6 This is often useful for troubleshooting pods that are in pending or crashed states: $ kubectl --namespace=deis describe -f <pod name> Tail Logs \u00b6 $ kubectl --namespace=deis logs -f <pod name> Django Shell \u00b6 Specific to teamhephy/controller $ kubectl --namespace=deis exec -it <pod name> -- python manage.py shell Have commands other Deis contributors might find useful? Send us a PR! Pull Requests \u00b6 Satisfied with your changes? Share them! Please read Submitting a Pull Request . It contains a checklist of things you should do when proposing a change to any Deis component.","title":"Development Environment"},{"location":"contributing/development-environment/#development-environment","text":"This document is for developers who are interested in working directly on the Deis codebase. In this guide, we walk you through the process of setting up a development environment that is suitable for hacking on most Deis components. We try to make it simple to hack on Deis components. However, there are necessarily several moving pieces and some setup required. We welcome any suggestions for automating or simplifying this process. Note The Deis team is actively engaged in containerizing Go and Python based development environments tailored specifically for Deis development in order to minimize the setup required. This work is ongoing. Refer to the teamhephy/router project for a working example of a fully containerized development environment. If you're just getting into the Deis codebase, look for GitHub issues with the label easy-fix . These are more straightforward or low-risk issues and are a great way to become more familiar with Deis.","title":"Development Environment"},{"location":"contributing/development-environment/#prerequisites","text":"In order to successfully compile and test Deis binaries and build Docker images of Deis components, the following are required: git Go 1.5 or later, with support for compiling to linux/amd64 glide golint shellcheck Docker (in a non-Linux environment, you will additionally want Docker Machine ) For teamhephy/controller , in particular, you will also need: Python 2.7 or later (with pip ) virtualenv ( sudo pip install virtualenv ) In most cases, you should simply install according to the instructions. There are a few special cases, though. We cover these below.","title":"Prerequisites"},{"location":"contributing/development-environment/#configuring-go","text":"If your local workstation does not support the linux/amd64 target environment, you will have to install Go from source with cross-compile support for that environment. This is because some of the components are built on your local machine and then injected into a Docker container. Homebrew users can just install with cross compiling support: $ brew install go --with-cc-common It is also straightforward to build Go from source: $ sudo su $ curl -sSL https://golang.org/dl/go1.5.src.tar.gz | tar -v -C /usr/local -xz $ cd /usr/local/go/src $ # compile Go for our default platform first, then add cross-compile support $ ./make.bash --no-clean $ GOOS=linux GOARCH=amd64 ./make.bash --no-clean Once you can compile to linux/amd64 , you should be able to compile Deis components as normal.","title":"Configuring Go"},{"location":"contributing/development-environment/#configuring-docker-machine-mac","text":"Deis needs Docker for building images. Docker utilizes a client/server architecture, and while the Docker client is available for Mac OS, the Docker server is dependent upon the Linux kernel. Therefore, in order to use Docker on Mac OS, Docker Machine is used to facilitate running the Docker server within a VirtualBox VM. Install Docker Machine according to the normal installation instructions, then use it to create a new VM: $ docker-machine create deis-docker \\ --driver=virtualbox \\ --virtualbox-disk-size=100000 \\ --engine-insecure-registry 10.0.0.0/8 \\ --engine-insecure-registry 172.16.0.0/12 \\ --engine-insecure-registry 192.168.0.0/16 \\ --engine-insecure-registry 100.64.0.0/10 This will create a new virtual machine named deis-docker that will take up as much as 100,000 MB of disk space. The images you build may be large, so allocating a big disk is a good idea. Once the deis-docker machine exists, source its values into your environment so your docker client knows how to use the new machine. You may even choose to add this to your bash profile or similar. $ eval \"$(docker-machine env deis-docker)\" After following these steps, some Docker Machine users report a slight delay (30 - 60 seconds) before the Docker server is ready. Note In subsequent steps, you may run a Docker registry within the deis-docker VM. Such a registry will not have a valid SSL certificate and will use HTTP instead of HTTPS. Such registries are implicitly untrusted by the Docker server (which is also running on the deis-docker VM). In order for the Docker server to trust the insecure registry, deis-docker is explicitly created to trust all registries in the IP ranges that that are reserved for use by private networks. The VM (and therefore the registry) will exist within such a range. This will effectively permit Docker pulls and pushes to such a registry.","title":"Configuring Docker Machine (Mac)"},{"location":"contributing/development-environment/#fork-the-repository","text":"Once the prerequisites have been met, we can begin to work with Deis components. Begin at Github by forking whichever Hephy project you would like to contribute to, then clone that fork locally. Since Hephy is predominantly written in Go, the best place to put it is under $GOPATH/src/github.com/teamhephy/ . $ mkdir -p $GOPATH/src/github.com/teamhephy $ cd $GOPATH/src/github.com/teamhephy $ git clone git@github.com:<username>/<component>.git $ cd <component> Note By checking out the forked copy into the namespace github.com/teamhephy/<component> , we are tricking the Go toolchain into seeing our fork as the \"official\" source tree. If you are going to be issuing pull requests to the upstream repository from which you forked, we suggest configuring Git such that you can easily rebase your code to the upstream repository's master branch. There are various strategies for doing this, but the most common is to add an upstream remote: $ git remote add upstream https://github.com/teamhephy/<component>.git For the sake of simplicity, you may want to point an environment variable to your Deis code - the directory containing one or more Deis components: $ export DEIS=$GOPATH/src/github.com/teamhephy Throughout the rest of this document, $DEIS refers to that location.","title":"Fork the Repository"},{"location":"contributing/development-environment/#alternative-forking-with-a-pushurl","text":"A number of Deis contributors prefer to pull directly from teamhephy/<component> , but push to <username>/<component> . If that workflow suits you better, you can set it up this way: $ git clone git@github.com:teamhephy/<component>.git $ cd teamhephy $ git config remote.origin.pushurl git@github.com:<username>/<component>.git In this setup, fetching and pulling code will work directly with the upstream repository, while pushing code will send changes to your fork. This makes it easy to stay up to date, but also make changes and then issue pull requests.","title":"Alternative: Forking with a Pushurl"},{"location":"contributing/development-environment/#make-your-changes","text":"With your development environment set up and the code you wish to work on forked and cloned, you can begin making your changes.","title":"Make Your Changes"},{"location":"contributing/development-environment/#test-your-changes","text":"Deis components each include a comprehensive suite of automated tests, mostly written in Go. See testing for instructions on running the tests.","title":"Test Your Changes"},{"location":"contributing/development-environment/#deploying-your-changes","text":"Although writing and executing tests are critical to ensuring code quality, most contributors will also want to deploy their changes to a live environment, whether to make use of those changes or to test them further. The remainder of this section documents the procedure for running officially released Deis components in a development cluster and replacing any one of those with your customizations.","title":"Deploying Your Changes"},{"location":"contributing/development-environment/#running-a-kubernetes-cluster-for-development","text":"To run a Kubernetes cluster locally or elsewhere to support your development activities, refer to Deis installation instructions here .","title":"Running a Kubernetes Cluster for Development"},{"location":"contributing/development-environment/#using-a-development-registry","text":"To facilitate deploying Docker images containing your changes to your Kubernetes cluster, you will need to make use of a Docker registry. This is a location to where you can push your custom-built images and from where your Kubernetes cluster can retrieve those same images. If your development cluster runs locally (in Minikube, for instance), the most efficient and economical means of achieving this is to run a Docker registry locally as a Docker container. To facilitate this, most Deis components provide a make target to create such a registry: $ make dev-registry In a Linux environment, to begin using the registry: export DEIS_REGISTRY=<IP of the host machine>:5000 In non-Linux environments: export DEIS_REGISTRY=<IP of the deis-docker Docker Machine VM>:5000/ If your development cluster runs on a cloud provider such as Google Container Engine, a local registry such as the one above will not be accessible to your Kubernetes nodes. In such cases, a public registry such as DockerHub or quay.io will suffice. To use DockerHub for this purpose, for instance: $ export DEIS_REGISTRY=\"\" $ export IMAGE_PREFIX=<your DockerHub username> To use quay.io: $ export DEIS_REGISTRY=quay.io/ $ export IMAGE_PREFIX=<your quay.io username> Note the importance of the trailing slash.","title":"Using a Development Registry"},{"location":"contributing/development-environment/#dev-deployment-workflow","text":"With a functioning Kubernetes cluster and the officially released Deis components installed onto it, deployment and further testing of any Deis component you have made changes to is facilitated by replacing the officially released component with a custom built image that contains your changes. Most Deis components include Makefiles with targets specifically intended to facilitate this workflow with minimal friction. In the general case, this workflow looks like this: Update source code and commit your changes using git Use make build to build a new Docker image Use make dev-release to generate Kubernetes manifest(s) Use make deploy to restart the component using the updated manifest This can be shortened to a one-liner using just the deploy target: $ make deploy","title":"Dev / Deployment Workflow"},{"location":"contributing/development-environment/#useful-commands","text":"Once your customized Deis component has been deployed, here are some helpful commands that will allow you to inspect your cluster and to troubleshoot, if necessary:","title":"Useful Commands"},{"location":"contributing/development-environment/#see-all-deis-pods","text":"$ kubectl --namespace=deis get pods","title":"See All Deis Pods"},{"location":"contributing/development-environment/#describe-a-pod","text":"This is often useful for troubleshooting pods that are in pending or crashed states: $ kubectl --namespace=deis describe -f <pod name>","title":"Describe a Pod"},{"location":"contributing/development-environment/#tail-logs","text":"$ kubectl --namespace=deis logs -f <pod name>","title":"Tail Logs"},{"location":"contributing/development-environment/#django-shell","text":"Specific to teamhephy/controller $ kubectl --namespace=deis exec -it <pod name> -- python manage.py shell Have commands other Deis contributors might find useful? Send us a PR!","title":"Django Shell"},{"location":"contributing/development-environment/#pull-requests","text":"Satisfied with your changes? Share them! Please read Submitting a Pull Request . It contains a checklist of things you should do when proposing a change to any Deis component.","title":"Pull Requests"},{"location":"contributing/maintainers/","text":"Deis Maintainers \u00b6 This document serves to describe the leadership structure of the Deis project, and list the current project maintainers. What is a maintainer? \u00b6 (Unabashedly stolen from the Docker project) There are different types of maintainers, with different responsibilities, but all maintainers have 3 things in common: They share responsibility in the project's success. They have made a long-term, recurring time investment to improve the project. They spend that time doing whatever needs to be done, not necessarily what is the most interesting or fun. Maintainers are often under-appreciated, because their work is harder to appreciate. It's easy to appreciate a really cool and technically advanced feature. It's harder to appreciate the absence of bugs, the slow but steady improvement in stability, or the reliability of a release process. But those things distinguish a good project from a great one. Deis maintainers \u00b6 Deis has two groups of maintainers in addition to our beloved Benevolent Dictator for Life. BDFL \u00b6 Deis follows the timeless, highly efficient and totally unfair system known as Benevolent dictator for life . Gabriel Monroy ( @gabrtv ), as creator of the Deis project, serves as our project's BDFL. While the day-to-day project management is carried out by the maintainers, Gabriel serves as the final arbiter of any disputes and has the final say on project direction. Core maintainers \u00b6 Core maintainers are exceptionally knowledgeable about all areas of Deis. Some maintainers work on Deis full-time, although this is not a requirement. The duties of a core maintainer include: Classify and respond to GitHub issues and review pull requests Help to shape the Deis roadmap and lead efforts to accomplish roadmap milestones Participate actively in feature development and bug fixing Answer questions and help users in the Deis #community Slack channel The current list of core maintainers can be seen here . No pull requests can be merged until at least one core maintainer signs off with an LGTM . The other LGTM can come from either a core maintainer or contributing maintainer. Contributing maintainers \u00b6 Contributing maintainers are exceptionally knowledgeable about some but not necessarily all areas of Deis, and are often selected due to specific domain knowledge that complements the project (but a willingness to continually contribute to the project is most important!). Often, core maintainers will ask a contributing maintainer to weigh in on issues, pull requests, or conversations where the contributing maintainer is knowledgeable. The duties of a contributing maintainer are very similar to those of a core maintainer, but they are limited to areas of the Deis project where the contributing maintainer is knowledgeable. Contributing maintainers are defined in practice as those who have write access to the Deis repository. All maintainers can review pull requests and add LGTM labels as appropriate. Becoming a maintainer \u00b6 The Deis project wouldn't be where it is today without its community. Many of the project's community members embody the spirit of maintainership, and have contributed substantially to the project. The contributing maintainers group was created in part so that exceptional members of the community who have an interest in the continued success of the project have the opportunity to join the core maintainers in guiding the future of Deis. Generally, potential contributing maintainers are selected by the Deis core maintainers based in part on the following criteria: Sustained contributions to the project over a period of time (usually months) A willingness to help Deis users on GitHub and in the Deis #community Slack channel A friendly attitude :) The Deis core maintainers must unanimously agree before inviting a community member to join as a contributing maintainer, although in many cases the candidate has already been acting in the capacity of a contributing maintainer for some time, and has been consulted on issues, pull requests, etc.","title":"Maintainers"},{"location":"contributing/maintainers/#deis-maintainers","text":"This document serves to describe the leadership structure of the Deis project, and list the current project maintainers.","title":"Deis Maintainers"},{"location":"contributing/maintainers/#what-is-a-maintainer","text":"(Unabashedly stolen from the Docker project) There are different types of maintainers, with different responsibilities, but all maintainers have 3 things in common: They share responsibility in the project's success. They have made a long-term, recurring time investment to improve the project. They spend that time doing whatever needs to be done, not necessarily what is the most interesting or fun. Maintainers are often under-appreciated, because their work is harder to appreciate. It's easy to appreciate a really cool and technically advanced feature. It's harder to appreciate the absence of bugs, the slow but steady improvement in stability, or the reliability of a release process. But those things distinguish a good project from a great one.","title":"What is a maintainer?"},{"location":"contributing/maintainers/#deis-maintainers_1","text":"Deis has two groups of maintainers in addition to our beloved Benevolent Dictator for Life.","title":"Deis maintainers"},{"location":"contributing/maintainers/#bdfl","text":"Deis follows the timeless, highly efficient and totally unfair system known as Benevolent dictator for life . Gabriel Monroy ( @gabrtv ), as creator of the Deis project, serves as our project's BDFL. While the day-to-day project management is carried out by the maintainers, Gabriel serves as the final arbiter of any disputes and has the final say on project direction.","title":"BDFL"},{"location":"contributing/maintainers/#core-maintainers","text":"Core maintainers are exceptionally knowledgeable about all areas of Deis. Some maintainers work on Deis full-time, although this is not a requirement. The duties of a core maintainer include: Classify and respond to GitHub issues and review pull requests Help to shape the Deis roadmap and lead efforts to accomplish roadmap milestones Participate actively in feature development and bug fixing Answer questions and help users in the Deis #community Slack channel The current list of core maintainers can be seen here . No pull requests can be merged until at least one core maintainer signs off with an LGTM . The other LGTM can come from either a core maintainer or contributing maintainer.","title":"Core maintainers"},{"location":"contributing/maintainers/#contributing-maintainers","text":"Contributing maintainers are exceptionally knowledgeable about some but not necessarily all areas of Deis, and are often selected due to specific domain knowledge that complements the project (but a willingness to continually contribute to the project is most important!). Often, core maintainers will ask a contributing maintainer to weigh in on issues, pull requests, or conversations where the contributing maintainer is knowledgeable. The duties of a contributing maintainer are very similar to those of a core maintainer, but they are limited to areas of the Deis project where the contributing maintainer is knowledgeable. Contributing maintainers are defined in practice as those who have write access to the Deis repository. All maintainers can review pull requests and add LGTM labels as appropriate.","title":"Contributing maintainers"},{"location":"contributing/maintainers/#becoming-a-maintainer","text":"The Deis project wouldn't be where it is today without its community. Many of the project's community members embody the spirit of maintainership, and have contributed substantially to the project. The contributing maintainers group was created in part so that exceptional members of the community who have an interest in the continued success of the project have the opportunity to join the core maintainers in guiding the future of Deis. Generally, potential contributing maintainers are selected by the Deis core maintainers based in part on the following criteria: Sustained contributions to the project over a period of time (usually months) A willingness to help Deis users on GitHub and in the Deis #community Slack channel A friendly attitude :) The Deis core maintainers must unanimously agree before inviting a community member to join as a contributing maintainer, although in many cases the candidate has already been acting in the capacity of a contributing maintainer for some time, and has been consulted on issues, pull requests, etc.","title":"Becoming a maintainer"},{"location":"contributing/overview/","text":"Contributor Overview \u00b6 Interested in contributing to a Deis project? There are lots of ways to help. File Bugs & Enhancements \u00b6 Find a bug? Want to see a new feature? Have a request for the maintainers? Open a Github issue in the applicable repository and we\u2019ll get the conversation started. Our official support channel is the Deis #community Slack channel . Don't know what the applicable repository for an issue is? Open up in issue in workflow or chat with a maintainer in the Deis #community Slack channel and we'll make sure it gets to the right place. Additionally, take a look at the troubleshooting documentation for common issues. Before opening a new issue, it's helpful to search and see if anyone else has already reported the problem. You can search through a list of issues for all Deis projects here . Write Documentation \u00b6 We are always looking to improve and expand our documentation. Most docs reside in the teamhephy/workflow repository. Simply fork the project, update docs and send us a pull request. Contribute Code \u00b6 We are always looking for help improving the core platform, other workloads, tooling, and test coverage. Interested in contributing code? Let\u2019s chat in the Deis #community Slack channel . Make sure to check out issues tagged easy fix or help wanted . When you're ready to begin writing code, review Design Documents and get your Development Environment set up. By contributing to any Deis project you agree to its Developer Certificate of Origin (DCO) . This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution. Triage Issues \u00b6 If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. See Triaging Issues for more info. Share your Experience \u00b6 Interact with the community on our user mailing list or live in our Deis #community Slack channel , where you can chat with other Deis Workflow users any time of day.","title":"Overview"},{"location":"contributing/overview/#contributor-overview","text":"Interested in contributing to a Deis project? There are lots of ways to help.","title":"Contributor Overview"},{"location":"contributing/overview/#file-bugs-enhancements","text":"Find a bug? Want to see a new feature? Have a request for the maintainers? Open a Github issue in the applicable repository and we\u2019ll get the conversation started. Our official support channel is the Deis #community Slack channel . Don't know what the applicable repository for an issue is? Open up in issue in workflow or chat with a maintainer in the Deis #community Slack channel and we'll make sure it gets to the right place. Additionally, take a look at the troubleshooting documentation for common issues. Before opening a new issue, it's helpful to search and see if anyone else has already reported the problem. You can search through a list of issues for all Deis projects here .","title":"File Bugs &amp; Enhancements"},{"location":"contributing/overview/#write-documentation","text":"We are always looking to improve and expand our documentation. Most docs reside in the teamhephy/workflow repository. Simply fork the project, update docs and send us a pull request.","title":"Write Documentation"},{"location":"contributing/overview/#contribute-code","text":"We are always looking for help improving the core platform, other workloads, tooling, and test coverage. Interested in contributing code? Let\u2019s chat in the Deis #community Slack channel . Make sure to check out issues tagged easy fix or help wanted . When you're ready to begin writing code, review Design Documents and get your Development Environment set up. By contributing to any Deis project you agree to its Developer Certificate of Origin (DCO) . This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution.","title":"Contribute Code"},{"location":"contributing/overview/#triage-issues","text":"If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. See Triaging Issues for more info.","title":"Triage Issues"},{"location":"contributing/overview/#share-your-experience","text":"Interact with the community on our user mailing list or live in our Deis #community Slack channel , where you can chat with other Deis Workflow users any time of day.","title":"Share your Experience"},{"location":"contributing/submitting-a-pull-request/","text":"Submitting a Pull Request \u00b6 Proposed changes to Deis projects are made as GitHub pull requests. Design Document \u00b6 Before opening a pull request, ensure your change also references a design document if the contribution is substantial. For more information, see Design Documents . Single Issue \u00b6 It's hard to reach agreement on the merit of a PR when it isn't focused. When fixing an issue or implementing a new feature, resist the temptation to refactor nearby code or to fix that potential bug you noticed. Instead, open a separate issue or pull request. Keeping concerns separated allows pull requests to be tested, reviewed, and merged more quickly. Squash and rebase the commit or commits in your pull request into logical units of work with git . Include tests and documentation changes in the same commit, so that a revert would remove all traces of the feature or fix. Most pull requests will reference a GitHub issue. In the PR description - not in the commit itself - include a line such as \"closes #1234\". The issue referenced will automatically be closed when your PR is merged. Include Tests \u00b6 If you significantly alter or add functionality to a component that impacts the broader Deis Workflow PaaS, you should submit a complementary PR to modify or amend end-to-end integration tests. These integration tests can be found in the teamhephy/workflow-e2e repository. See testing for more information. Include Docs \u00b6 Changes to any Deis Workflow component that could affect a user's experience also require a change or addition to the relevant documentation. For most Deis components, this involves updating the component's own documentation. In some cases where a component is tightly integrated into teamhephy/workflow , its documentation must also be updated. Cross-repo commits \u00b6 If a pull request is part of a larger piece of work involving one or more additional commits in other Workflow repositories, these commits can be referenced in the last PR to be submitted. The downstream e2e test job will then supply every referenced commit (derived from PR issue number supplied) to the test runner so it can source the necessary Docker images for inclusion in the generated Workflow chart to be tested. For example, consider paired commits in teamhephy/controller and teamhephy/workflow-e2e . The commit body for the first PR in teamhephy/workflow-e2e would look like: feat(foo_test): add e2e test for feature foo [skip e2e] test for controller#42 Adding [skip e2e] forgoes the e2e tests on this commit. This and any other required PRs aside from the final PR should be submitted first, so that their respective build and image push jobs run. Lastly, the final PR in teamhephy/controller should be created with the required PR number(s) listed, in the form of [Rr]equires <repoName>#<pullRequestNumber> , for use by the downstream e2e run. feat(foo): add feature foo Requires workflow-e2e#42 Code Standards \u00b6 Deis components are implemented in Go and Python . For both languages, we agree with The Zen of Python , which emphasizes simple over clever. Readability counts. Go code should always be run through gofmt on the default settings. Lines of code may be up to 99 characters long. Documentation strings and tests are required for all exported functions. Use of third-party go packages should be minimal, but when doing so, such dependencies should be managed via the glide tool. Python code should always adhere to PEP8 , the python code style guide, with the exception that lines of code may be up to 99 characters long. Docstrings and tests are required for all public methods, although the flake8 tool used by Deis does not enforce this. Commit Style \u00b6 We follow a convention for commit messages borrowed from CoreOS, who borrowed theirs from AngularJS. This is an example of a commit: feat(scripts/test-cluster): add a cluster test command this uses tmux to setup a test cluster that you can easily kill and start for debugging. To make it more formal, it looks something like this: {type}({scope}): {subject} <BLANK LINE> {body} <BLANK LINE> {footer} The allowed {types} are as follows: feat -> feature fix -> bug fix docs -> documentation style -> formatting ref -> refactoring code test -> adding missing tests chore -> maintenance The {scope} can be anything specifying the location(s) of the commit change(s). The {subject} needs to be an imperative, present tense verb: \u201cchange\u201d, not \u201cchanged\u201d nor \u201cchanges\u201d. The first letter should not be capitalized, and there is no dot (.) at the end. Just like the {subject} , the message {body} needs to be in the present tense, and includes the motivation for the change, as well as a contrast with the previous behavior. The first letter in a paragraph must be capitalized. All breaking changes need to be mentioned in the {footer} with the description of the change, the justification behind the change and any migration notes required. Any line of the commit message cannot be longer than 72 characters, with the subject line limited to 50 characters. This allows the message to be easier to read on GitHub as well as in various git tools. Merge Approval \u00b6 Any code change - other than a simple typo fix or one-line documentation change - requires at least two Deis maintainers to accept it. Maintainers tag pull requests with \" LGTM1 \" and \" LGTM2 \" (Looks Good To Me) labels to indicate acceptance. No pull requests can be merged until at least one core maintainer signs off with an LGTM. The other LGTM can come from either a core maintainer or contributing maintainer. If the PR is from a Deis maintainer, then he or she should be the one to close it. This keeps the commit stream clean and gives the maintainer the benefit of revisiting the PR before deciding whether or not to merge the changes. An exception to this is when an errant commit needs to be reverted urgently. If necessary, a PR that only reverts a previous commit can be merged without waiting for LGTM approval.","title":"Submitting a Pull Request"},{"location":"contributing/submitting-a-pull-request/#submitting-a-pull-request","text":"Proposed changes to Deis projects are made as GitHub pull requests.","title":"Submitting a Pull Request"},{"location":"contributing/submitting-a-pull-request/#design-document","text":"Before opening a pull request, ensure your change also references a design document if the contribution is substantial. For more information, see Design Documents .","title":"Design Document"},{"location":"contributing/submitting-a-pull-request/#single-issue","text":"It's hard to reach agreement on the merit of a PR when it isn't focused. When fixing an issue or implementing a new feature, resist the temptation to refactor nearby code or to fix that potential bug you noticed. Instead, open a separate issue or pull request. Keeping concerns separated allows pull requests to be tested, reviewed, and merged more quickly. Squash and rebase the commit or commits in your pull request into logical units of work with git . Include tests and documentation changes in the same commit, so that a revert would remove all traces of the feature or fix. Most pull requests will reference a GitHub issue. In the PR description - not in the commit itself - include a line such as \"closes #1234\". The issue referenced will automatically be closed when your PR is merged.","title":"Single Issue"},{"location":"contributing/submitting-a-pull-request/#include-tests","text":"If you significantly alter or add functionality to a component that impacts the broader Deis Workflow PaaS, you should submit a complementary PR to modify or amend end-to-end integration tests. These integration tests can be found in the teamhephy/workflow-e2e repository. See testing for more information.","title":"Include Tests"},{"location":"contributing/submitting-a-pull-request/#include-docs","text":"Changes to any Deis Workflow component that could affect a user's experience also require a change or addition to the relevant documentation. For most Deis components, this involves updating the component's own documentation. In some cases where a component is tightly integrated into teamhephy/workflow , its documentation must also be updated.","title":"Include Docs"},{"location":"contributing/submitting-a-pull-request/#cross-repo-commits","text":"If a pull request is part of a larger piece of work involving one or more additional commits in other Workflow repositories, these commits can be referenced in the last PR to be submitted. The downstream e2e test job will then supply every referenced commit (derived from PR issue number supplied) to the test runner so it can source the necessary Docker images for inclusion in the generated Workflow chart to be tested. For example, consider paired commits in teamhephy/controller and teamhephy/workflow-e2e . The commit body for the first PR in teamhephy/workflow-e2e would look like: feat(foo_test): add e2e test for feature foo [skip e2e] test for controller#42 Adding [skip e2e] forgoes the e2e tests on this commit. This and any other required PRs aside from the final PR should be submitted first, so that their respective build and image push jobs run. Lastly, the final PR in teamhephy/controller should be created with the required PR number(s) listed, in the form of [Rr]equires <repoName>#<pullRequestNumber> , for use by the downstream e2e run. feat(foo): add feature foo Requires workflow-e2e#42","title":"Cross-repo commits"},{"location":"contributing/submitting-a-pull-request/#code-standards","text":"Deis components are implemented in Go and Python . For both languages, we agree with The Zen of Python , which emphasizes simple over clever. Readability counts. Go code should always be run through gofmt on the default settings. Lines of code may be up to 99 characters long. Documentation strings and tests are required for all exported functions. Use of third-party go packages should be minimal, but when doing so, such dependencies should be managed via the glide tool. Python code should always adhere to PEP8 , the python code style guide, with the exception that lines of code may be up to 99 characters long. Docstrings and tests are required for all public methods, although the flake8 tool used by Deis does not enforce this.","title":"Code Standards"},{"location":"contributing/submitting-a-pull-request/#commit-style","text":"We follow a convention for commit messages borrowed from CoreOS, who borrowed theirs from AngularJS. This is an example of a commit: feat(scripts/test-cluster): add a cluster test command this uses tmux to setup a test cluster that you can easily kill and start for debugging. To make it more formal, it looks something like this: {type}({scope}): {subject} <BLANK LINE> {body} <BLANK LINE> {footer} The allowed {types} are as follows: feat -> feature fix -> bug fix docs -> documentation style -> formatting ref -> refactoring code test -> adding missing tests chore -> maintenance The {scope} can be anything specifying the location(s) of the commit change(s). The {subject} needs to be an imperative, present tense verb: \u201cchange\u201d, not \u201cchanged\u201d nor \u201cchanges\u201d. The first letter should not be capitalized, and there is no dot (.) at the end. Just like the {subject} , the message {body} needs to be in the present tense, and includes the motivation for the change, as well as a contrast with the previous behavior. The first letter in a paragraph must be capitalized. All breaking changes need to be mentioned in the {footer} with the description of the change, the justification behind the change and any migration notes required. Any line of the commit message cannot be longer than 72 characters, with the subject line limited to 50 characters. This allows the message to be easier to read on GitHub as well as in various git tools.","title":"Commit Style"},{"location":"contributing/submitting-a-pull-request/#merge-approval","text":"Any code change - other than a simple typo fix or one-line documentation change - requires at least two Deis maintainers to accept it. Maintainers tag pull requests with \" LGTM1 \" and \" LGTM2 \" (Looks Good To Me) labels to indicate acceptance. No pull requests can be merged until at least one core maintainer signs off with an LGTM. The other LGTM can come from either a core maintainer or contributing maintainer. If the PR is from a Deis maintainer, then he or she should be the one to close it. This keeps the commit stream clean and gives the maintainer the benefit of revisiting the PR before deciding whether or not to merge the changes. An exception to this is when an errant commit needs to be reverted urgently. If necessary, a PR that only reverts a previous commit can be merged without waiting for LGTM approval.","title":"Merge Approval"},{"location":"contributing/testing/","text":"Testing Deis \u00b6 Each Deis component is one among an ecosystem of such components - many of which integrate with one another - which makes testing each component thoroughly a matter of paramount importance. Each Deis component includes its own suite of style checks, unit tests , and black-box type functional tests . Integration tests verify the behavior of the Deis components together as a system and are provided separately by the teamhephy/workflow-e2e project. GitHub pull requests for all Deis components are tested automatically by the Travis CI continuous integration system. Contributors should run the same tests locally before proposing any changes to the Deis codebase. Set Up the Environment \u00b6 Successfully executing the unit and functional tests for any Deis component requires that the Development Environment is set up first. Run the Tests \u00b6 The style checks, unit tests, and functional tests for each component can all be executed via make targets: To execute style checks: $ make test-style To execute unit tests: $ make test-unit To execute functional tests: $ make test-functional To execute style checks, unit tests, and functional tests all in one shot: $ make test To execute integration tests, refer to teamhephy/workflow-e2e documentation.","title":"Testing"},{"location":"contributing/testing/#testing-deis","text":"Each Deis component is one among an ecosystem of such components - many of which integrate with one another - which makes testing each component thoroughly a matter of paramount importance. Each Deis component includes its own suite of style checks, unit tests , and black-box type functional tests . Integration tests verify the behavior of the Deis components together as a system and are provided separately by the teamhephy/workflow-e2e project. GitHub pull requests for all Deis components are tested automatically by the Travis CI continuous integration system. Contributors should run the same tests locally before proposing any changes to the Deis codebase.","title":"Testing Deis"},{"location":"contributing/testing/#set-up-the-environment","text":"Successfully executing the unit and functional tests for any Deis component requires that the Development Environment is set up first.","title":"Set Up the Environment"},{"location":"contributing/testing/#run-the-tests","text":"The style checks, unit tests, and functional tests for each component can all be executed via make targets: To execute style checks: $ make test-style To execute unit tests: $ make test-unit To execute functional tests: $ make test-functional To execute style checks, unit tests, and functional tests all in one shot: $ make test To execute integration tests, refer to teamhephy/workflow-e2e documentation.","title":"Run the Tests"},{"location":"contributing/triaging-issues/","text":"Triaging Issues \u00b6 Issue triage provides an important way to contribute to an open source project. Triage helps ensure issues resolve quickly by: Describing the issue's intent and purpose is conveyed precisely. This is necessary because it can be difficult for an issue to explain how an end user experiences an problem and what actions they took. Giving a contributor the information they need before they commit to resolving an issue. Lowering the issue count by preventing duplicate issues. Streamlining the development process by preventing duplicate discussions. If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours. Ensure the Issue Contains Basic Information \u00b6 Before triaging an issue very far, make sure that the issue's author provided the standard issue information. This will help you make an educated recommendation on how this to categorize the issue. Standard information that should be included in most issues are things such as: the version(s) of Deis this issue affects a reproducible case if this is a bug page URL if this is a docs issue or the name of a man page Depending on the issue, you might not feel all this information is needed. Use your best judgment. If you cannot triage an issue using what its author provided, explain kindly to the author that they must provide the above information to clarify the problem. If the author provides the recommended information but you are still unable to triage the issue, request additional information. Do this kindly and politely because you are asking for more of the author's time. If the author does not respond requested information within the timespan of a week, close the issue with a kind note stating that the author can request for the issue to be reopened when the necessary information is provided. Classifying the Issue \u00b6 An issue can have multiple of the following labels: Issue Kind \u00b6 Kind Description bug Bugs are bugs. The cause may or may not be known at triage time so debugging should be taken account into the time estimate. docs Writing documentation, man pages, articles, blogs, or other significant word-driven task. enhancement Enhancements can drastically improve usability or performance of a component. question Contains a user or contributor question requiring a response. security Security-related issues such as TLS encryption, network segregation, authn/authz features, etc. Functional Area \u00b6 builder cache contrib and provisioning client controller database docs kubernetes registry router store (Ceph) tests Easy Fix \u00b6 \"Easy Fix\" issues are a way for a new contributor to find issues that are fit for their experience level. These issues are typically for users who are new to Deis, and possibly Go, and is looking to help while learning the basics. Prioritizing issues \u00b6 When attached to a specific milestone, an issue can be attributed one of the following labels to indicate their degree of priority. Priority Description priority 0 Urgent: Security, critical bugs, blocking issues. Drop everything and fix this today, then consider creating a patch release. priority 1 Serious: Impedes user actions or is a regression. Fix this before the next planned release. And that's it. That should be all the information required for a new or existing contributor to come in an resolve an issue.","title":"Triaging Issues"},{"location":"contributing/triaging-issues/#triaging-issues","text":"Issue triage provides an important way to contribute to an open source project. Triage helps ensure issues resolve quickly by: Describing the issue's intent and purpose is conveyed precisely. This is necessary because it can be difficult for an issue to explain how an end user experiences an problem and what actions they took. Giving a contributor the information they need before they commit to resolving an issue. Lowering the issue count by preventing duplicate issues. Streamlining the development process by preventing duplicate discussions. If you don't have time to code, consider helping with triage. The community will thank you for saving them time by spending some of yours.","title":"Triaging Issues"},{"location":"contributing/triaging-issues/#ensure-the-issue-contains-basic-information","text":"Before triaging an issue very far, make sure that the issue's author provided the standard issue information. This will help you make an educated recommendation on how this to categorize the issue. Standard information that should be included in most issues are things such as: the version(s) of Deis this issue affects a reproducible case if this is a bug page URL if this is a docs issue or the name of a man page Depending on the issue, you might not feel all this information is needed. Use your best judgment. If you cannot triage an issue using what its author provided, explain kindly to the author that they must provide the above information to clarify the problem. If the author provides the recommended information but you are still unable to triage the issue, request additional information. Do this kindly and politely because you are asking for more of the author's time. If the author does not respond requested information within the timespan of a week, close the issue with a kind note stating that the author can request for the issue to be reopened when the necessary information is provided.","title":"Ensure the Issue Contains Basic Information"},{"location":"contributing/triaging-issues/#classifying-the-issue","text":"An issue can have multiple of the following labels:","title":"Classifying the Issue"},{"location":"contributing/triaging-issues/#issue-kind","text":"Kind Description bug Bugs are bugs. The cause may or may not be known at triage time so debugging should be taken account into the time estimate. docs Writing documentation, man pages, articles, blogs, or other significant word-driven task. enhancement Enhancements can drastically improve usability or performance of a component. question Contains a user or contributor question requiring a response. security Security-related issues such as TLS encryption, network segregation, authn/authz features, etc.","title":"Issue Kind"},{"location":"contributing/triaging-issues/#functional-area","text":"builder cache contrib and provisioning client controller database docs kubernetes registry router store (Ceph) tests","title":"Functional Area"},{"location":"contributing/triaging-issues/#easy-fix","text":"\"Easy Fix\" issues are a way for a new contributor to find issues that are fit for their experience level. These issues are typically for users who are new to Deis, and possibly Go, and is looking to help while learning the basics.","title":"Easy Fix"},{"location":"contributing/triaging-issues/#prioritizing-issues","text":"When attached to a specific milestone, an issue can be attributed one of the following labels to indicate their degree of priority. Priority Description priority 0 Urgent: Security, critical bugs, blocking issues. Drop everything and fix this today, then consider creating a patch release. priority 1 Serious: Impedes user actions or is a regression. Fix this before the next planned release. And that's it. That should be all the information required for a new or existing contributor to come in an resolve an issue.","title":"Prioritizing issues"},{"location":"diagrams/","text":"Architecture Diagrams \u00b6 This is an OmniGraffle file which holds the source materials for the following images. To update a chart: Make your modification! Select \"File > Export\" Select \"Entire Document Choose: Scale: 100% Set Bitmap Resolution to 72 dpi (for web) Uncheck \"Transparent Background\" Select \"images\" directory Click \"Export\" This should update all of the graphics in one go! Commit and pull-request.","title":"Architecture Diagrams"},{"location":"diagrams/#architecture-diagrams","text":"This is an OmniGraffle file which holds the source materials for the following images. To update a chart: Make your modification! Select \"File > Export\" Select \"Entire Document Choose: Scale: 100% Set Bitmap Resolution to 72 dpi (for web) Uncheck \"Transparent Background\" Select \"images\" directory Click \"Export\" This should update all of the graphics in one go! Commit and pull-request.","title":"Architecture Diagrams"},{"location":"installing-workflow/","text":"Installing Deis Workflow \u00b6 This document is aimed at those who have already provisioned a Kubernetes v1.3.4+ cluster and want to install Deis Workflow. If help is required getting started with Kubernetes and Deis Workflow, follow the quickstart guide for assistance. Prerequisites \u00b6 Verify the Kubernetes system requirements Install Helm and Deis Workflow CLI tools Check Your Setup \u00b6 Check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Check Your Authorization \u00b6 If your cluster uses RBAC for authorization, helm will need to be granted the necessary permissions to create Workflow resources. This can be done with the following commands: $ kubectl create sa tiller-deploy -n kube-system $ kubectl create clusterrolebinding helm --clusterrole=cluster-admin --serviceaccount=kube-system:tiller-deploy $ helm init --service-account=tiller-deploy If helm is already installed in cluster without sufficient rights, simply add --upgrade to the init command above. Note : Specific helm permissions haven't been sorted yet and details may change (watch helm docs ) Choose Your Deployment Strategy \u00b6 Deis Workflow includes everything it needs to run out of the box. However, these defaults are aimed at simplicity rather than production readiness. Production and staging deployments of Workflow should, at a minimum, use off-cluster storage which is used by Workflow components to store and backup critical data. Should an operator need to completely re-install Workflow, the required components can recover from off-cluster storage. See the documentation for configuring object storage for more details. More rigorous installations would benefit from using outside sources for the following things: Postgres - For example AWS RDS. Registry - This includes quay.io , dockerhub , Amazon ECR , and Google GCR . Redis - Such as AWS Elasticache InfluxDB and Grafana (Experimental) Kubernetes Native Ingress \u00b6 Workflow now offers experimental native ingress to take advantage of native Kubernetes routing. Any compatible Kubernetes ingress controller can be used in place of Workflow's nginx-based deis-router. Follow this guide to enable experimental native ingress. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-574483744-l15zj 1/1 Running 0 4m deis-controller-3953262871-pncgq 1/1 Running 2 4m deis-database-83844344-47ld6 1/1 Running 0 4m deis-logger-176328999-wjckx 1/1 Running 4 4m deis-logger-fluentd-zxnqb 1/1 Running 0 4m deis-logger-redis-304849759-1f35p 1/1 Running 0 4m deis-minio-676004970-nxqgt 1/1 Running 0 4m deis-monitor-grafana-432627134-lnl2h 1/1 Running 0 4m deis-monitor-influxdb-2729788615-m9b5n 1/1 Running 0 4m deis-monitor-telegraf-wmcmn 1/1 Running 1 4m deis-nsqd-3597503299-6mn2x 1/1 Running 0 4m deis-registry-756475849-lwc6b 1/1 Running 1 4m deis-registry-proxy-96c4p 1/1 Running 0 4m deis-router-2126433040-6sl6z 1/1 Running 0 4m deis-workflow-manager-2528409207-jkz2r 1/1 Running 0 4m Once all of the pods are in the READY state, Deis Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Installing Workflow"},{"location":"installing-workflow/#installing-deis-workflow","text":"This document is aimed at those who have already provisioned a Kubernetes v1.3.4+ cluster and want to install Deis Workflow. If help is required getting started with Kubernetes and Deis Workflow, follow the quickstart guide for assistance.","title":"Installing Deis Workflow"},{"location":"installing-workflow/#prerequisites","text":"Verify the Kubernetes system requirements Install Helm and Deis Workflow CLI tools","title":"Prerequisites"},{"location":"installing-workflow/#check-your-setup","text":"Check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"}","title":"Check Your Setup"},{"location":"installing-workflow/#check-your-authorization","text":"If your cluster uses RBAC for authorization, helm will need to be granted the necessary permissions to create Workflow resources. This can be done with the following commands: $ kubectl create sa tiller-deploy -n kube-system $ kubectl create clusterrolebinding helm --clusterrole=cluster-admin --serviceaccount=kube-system:tiller-deploy $ helm init --service-account=tiller-deploy If helm is already installed in cluster without sufficient rights, simply add --upgrade to the init command above. Note : Specific helm permissions haven't been sorted yet and details may change (watch helm docs )","title":"Check Your Authorization"},{"location":"installing-workflow/#choose-your-deployment-strategy","text":"Deis Workflow includes everything it needs to run out of the box. However, these defaults are aimed at simplicity rather than production readiness. Production and staging deployments of Workflow should, at a minimum, use off-cluster storage which is used by Workflow components to store and backup critical data. Should an operator need to completely re-install Workflow, the required components can recover from off-cluster storage. See the documentation for configuring object storage for more details. More rigorous installations would benefit from using outside sources for the following things: Postgres - For example AWS RDS. Registry - This includes quay.io , dockerhub , Amazon ECR , and Google GCR . Redis - Such as AWS Elasticache InfluxDB and Grafana","title":"Choose Your Deployment Strategy"},{"location":"installing-workflow/#experimental-kubernetes-native-ingress","text":"Workflow now offers experimental native ingress to take advantage of native Kubernetes routing. Any compatible Kubernetes ingress controller can be used in place of Workflow's nginx-based deis-router. Follow this guide to enable experimental native ingress.","title":"(Experimental) Kubernetes Native Ingress"},{"location":"installing-workflow/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"installing-workflow/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-574483744-l15zj 1/1 Running 0 4m deis-controller-3953262871-pncgq 1/1 Running 2 4m deis-database-83844344-47ld6 1/1 Running 0 4m deis-logger-176328999-wjckx 1/1 Running 4 4m deis-logger-fluentd-zxnqb 1/1 Running 0 4m deis-logger-redis-304849759-1f35p 1/1 Running 0 4m deis-minio-676004970-nxqgt 1/1 Running 0 4m deis-monitor-grafana-432627134-lnl2h 1/1 Running 0 4m deis-monitor-influxdb-2729788615-m9b5n 1/1 Running 0 4m deis-monitor-telegraf-wmcmn 1/1 Running 1 4m deis-nsqd-3597503299-6mn2x 1/1 Running 0 4m deis-registry-756475849-lwc6b 1/1 Running 1 4m deis-registry-proxy-96c4p 1/1 Running 0 4m deis-router-2126433040-6sl6z 1/1 Running 0 4m deis-workflow-manager-2528409207-jkz2r 1/1 Running 0 4m Once all of the pods are in the READY state, Deis Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Install Deis Workflow"},{"location":"installing-workflow/chart-provenance/","text":"Chart Provenance \u00b6 As of Workflow v2.8.0 , Deis has released Kubernetes Helm charts for Workflow and for each of its components . Helm provides tools for establishing and verifying chart integrity. (For an overview, see the Provenance doc.) All release charts from the Deis Workflow team are now signed using this mechanism. The full Deis, Inc. (Helm chart signing key) <security@deis.com> public key can be found here , as well as the pgp.mit.edu keyserver and the official Deis Keybase account . The key's fingerprint can be cross-checked against all of these sources. Verifying a signed chart \u00b6 The public key mentioned above must exist in a local keyring before a signed chart can be verified. To add it to the default ~/.gnupg/pubring.gpg keyring, any of the following commands will work: $ # via our hosted location $ curl https://deis.com/workflow/docs/security/1d6a97d0.txt | gpg --import $ # via the pgp.mit.edu keyserver $ gpg --keyserver pgp.mit.edu --recv-keys 1D6A97D0 $ # via Keybase with account... $ keybase follow deis $ keybase pgp pull $ # via Keybase by curl $ curl https://keybase.io/deis/key.asc | gpg --import Charts signed with this key can then be verified when fetched: $ helm repo add deis https://charts.deis.com/workflow \"deis\" has been added to your repositories $ helm fetch --verify deis/workflow --version v2.17.0 Verification: &{0xc420704c80 sha256:a2a140dca075a2eabe20422f1aa5bc1ce210b18a326472d6b2708e1a93afebea workflow-v2.17.0.tgz} One can then inspect the fetched workflow-v2.17.0.tgz.prov provenance file. If the chart was not signed, the command above would result in: Error: Failed to fetch provenance \"https://charts.deis.com/workflow/workflow-v2.17.0.tgz.prov\" Alternatively, the chart can also be verified at install time: $ helm install --verify deis/workflow --namespace deis NAME: exiled-mink LAST DEPLOYED: Wed Aug 9 08:22:16 2017 NAMESPACE: deis STATUS: DEPLOYED ... $ helm ls NAME REVISION UPDATED STATUS CHART exiled-mink 1 Wed Aug 9 08:22:16 2017 DEPLOYED workflow-v2.17.0 Having done so, one is assured of the origin and authenticity of any installed Workflow chart released by Deis.","title":"Chart Provenance"},{"location":"installing-workflow/chart-provenance/#chart-provenance","text":"As of Workflow v2.8.0 , Deis has released Kubernetes Helm charts for Workflow and for each of its components . Helm provides tools for establishing and verifying chart integrity. (For an overview, see the Provenance doc.) All release charts from the Deis Workflow team are now signed using this mechanism. The full Deis, Inc. (Helm chart signing key) <security@deis.com> public key can be found here , as well as the pgp.mit.edu keyserver and the official Deis Keybase account . The key's fingerprint can be cross-checked against all of these sources.","title":"Chart Provenance"},{"location":"installing-workflow/chart-provenance/#verifying-a-signed-chart","text":"The public key mentioned above must exist in a local keyring before a signed chart can be verified. To add it to the default ~/.gnupg/pubring.gpg keyring, any of the following commands will work: $ # via our hosted location $ curl https://deis.com/workflow/docs/security/1d6a97d0.txt | gpg --import $ # via the pgp.mit.edu keyserver $ gpg --keyserver pgp.mit.edu --recv-keys 1D6A97D0 $ # via Keybase with account... $ keybase follow deis $ keybase pgp pull $ # via Keybase by curl $ curl https://keybase.io/deis/key.asc | gpg --import Charts signed with this key can then be verified when fetched: $ helm repo add deis https://charts.deis.com/workflow \"deis\" has been added to your repositories $ helm fetch --verify deis/workflow --version v2.17.0 Verification: &{0xc420704c80 sha256:a2a140dca075a2eabe20422f1aa5bc1ce210b18a326472d6b2708e1a93afebea workflow-v2.17.0.tgz} One can then inspect the fetched workflow-v2.17.0.tgz.prov provenance file. If the chart was not signed, the command above would result in: Error: Failed to fetch provenance \"https://charts.deis.com/workflow/workflow-v2.17.0.tgz.prov\" Alternatively, the chart can also be verified at install time: $ helm install --verify deis/workflow --namespace deis NAME: exiled-mink LAST DEPLOYED: Wed Aug 9 08:22:16 2017 NAMESPACE: deis STATUS: DEPLOYED ... $ helm ls NAME REVISION UPDATED STATUS CHART exiled-mink 1 Wed Aug 9 08:22:16 2017 DEPLOYED workflow-v2.17.0 Having done so, one is assured of the origin and authenticity of any installed Workflow chart released by Deis.","title":"Verifying a signed chart"},{"location":"installing-workflow/configuring-object-storage/","text":"Configuring Object Storage \u00b6 A variety of Deis Workflow components rely on an object storage system to do their work including storing application slugs, Docker images and database logs. Deis Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost . Therefore, Minio should be used for development or testing only . Configuring off-cluster Object Storage \u00b6 Every component that relies on object storage uses two inputs for configuration: Component-specific environment variables (e.g. BUILDER_STORAGE and REGISTRY_STORAGE ) Access credentials stored as a Kubernetes secret named objectstorage-keyfile The helm chart for Deis Workflow can be easily configured to connect Workflow components to off-cluster object storage. Deis Workflow currently supports Google Compute Storage, Amazon S3, Azure Blob Storage and OpenStack Swift Storage. Step 1: Create storage buckets \u00b6 Create storage buckets for each of the Workflow subsystems: builder , registry , and database . Depending on your chosen object storage you may need to provide globally unique bucket names. If you are using S3, use hyphens instead of periods in the bucket names. Using periods in the bucket name will cause an ssl certificate validation issue with S3 . If you provide credentials with sufficient access to the underlying storage, Workflow components will create the buckets if they do not exist. Step 2: Generate storage credentials \u00b6 If applicable, generate credentials that have create and write access to the storage buckets created in Step 1. If you are using AWS S3 and your Kubernetes nodes are configured with appropriate IAM API keys via InstanceRoles, you do not need to create API credentials. Do, however, validate that the InstanceRole has appropriate permissions to the configured buckets! Step 3: Add Deis Repo \u00b6 If you haven't already added the Helm repo, do so with helm repo add deis https://charts.deis.com/workflow Step 4: Configure Workflow Chart \u00b6 Operators should configure object storage by editing the Helm values file before running helm install . To do so: Fetch the Helm values by running helm inspect values deis/workflow > values.yaml Update the global/storage parameter to reference the platform you are using, e.g. s3 , azure , gcs , or swift Find the corresponding section for your storage type and provide appropriate values including region, bucket names, and access credentials. Save your changes. Note All values will be automatically (base64) encoded except the key_json values under gcs / gcr . These must be base64-encoded. This is to support cleanly passing said encoded text via helm --set cli functionality rather than attempting to pass the raw JSON data. For example: $ helm install workflow --namespace deis \\ --set global.storage=gcs,gcs.key_json=\"$(cat /path/to/gcs_creds.json | base64 -w 0)\" You are now ready to run helm install deis/workflow --namespace deis -f values.yaml using your desired object storage.","title":"Configuring Object Storage"},{"location":"installing-workflow/configuring-object-storage/#configuring-object-storage","text":"A variety of Deis Workflow components rely on an object storage system to do their work including storing application slugs, Docker images and database logs. Deis Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost . Therefore, Minio should be used for development or testing only .","title":"Configuring Object Storage"},{"location":"installing-workflow/configuring-object-storage/#configuring-off-cluster-object-storage","text":"Every component that relies on object storage uses two inputs for configuration: Component-specific environment variables (e.g. BUILDER_STORAGE and REGISTRY_STORAGE ) Access credentials stored as a Kubernetes secret named objectstorage-keyfile The helm chart for Deis Workflow can be easily configured to connect Workflow components to off-cluster object storage. Deis Workflow currently supports Google Compute Storage, Amazon S3, Azure Blob Storage and OpenStack Swift Storage.","title":"Configuring off-cluster Object Storage"},{"location":"installing-workflow/configuring-object-storage/#step-1-create-storage-buckets","text":"Create storage buckets for each of the Workflow subsystems: builder , registry , and database . Depending on your chosen object storage you may need to provide globally unique bucket names. If you are using S3, use hyphens instead of periods in the bucket names. Using periods in the bucket name will cause an ssl certificate validation issue with S3 . If you provide credentials with sufficient access to the underlying storage, Workflow components will create the buckets if they do not exist.","title":"Step 1: Create storage buckets"},{"location":"installing-workflow/configuring-object-storage/#step-2-generate-storage-credentials","text":"If applicable, generate credentials that have create and write access to the storage buckets created in Step 1. If you are using AWS S3 and your Kubernetes nodes are configured with appropriate IAM API keys via InstanceRoles, you do not need to create API credentials. Do, however, validate that the InstanceRole has appropriate permissions to the configured buckets!","title":"Step 2: Generate storage credentials"},{"location":"installing-workflow/configuring-object-storage/#step-3-add-deis-repo","text":"If you haven't already added the Helm repo, do so with helm repo add deis https://charts.deis.com/workflow","title":"Step 3: Add Deis Repo"},{"location":"installing-workflow/configuring-object-storage/#step-4-configure-workflow-chart","text":"Operators should configure object storage by editing the Helm values file before running helm install . To do so: Fetch the Helm values by running helm inspect values deis/workflow > values.yaml Update the global/storage parameter to reference the platform you are using, e.g. s3 , azure , gcs , or swift Find the corresponding section for your storage type and provide appropriate values including region, bucket names, and access credentials. Save your changes. Note All values will be automatically (base64) encoded except the key_json values under gcs / gcr . These must be base64-encoded. This is to support cleanly passing said encoded text via helm --set cli functionality rather than attempting to pass the raw JSON data. For example: $ helm install workflow --namespace deis \\ --set global.storage=gcs,gcs.key_json=\"$(cat /path/to/gcs_creds.json | base64 -w 0)\" You are now ready to run helm install deis/workflow --namespace deis -f values.yaml using your desired object storage.","title":"Step 4: Configure Workflow Chart"},{"location":"installing-workflow/configuring-postgres/","text":"Configuring Postgres \u00b6 Deis Workflow's controller component relies on a PostgreSQL database to store platform state. By default, Deis Workflow ships with the database component, which provides an in-cluster PostgreSQL database backed up to in-cluster or off-cluster object storage . Currently, for object storage, which is utilized by several Workflow components, only off-cluster solutions such as S3 or GCS are recommended in production environments. Experience has shown that many operators already opting for off-cluster object storage similarly prefer to host Postgres off-cluster as well, using Amazon RDS or similar. When excercising both options, a Workflow installation becomes entirely stateless, and is thus restored or rebuilt with greater ease should the need ever arise. Provisioning off-cluster Postgres \u00b6 First, provision a PostgreSQL RDBMS using the cloud provider or other infrastructure of your choice. Take care to ensure that security groups or other firewall rules will permit connectivity from your Kubernetes worker nodes, any of which may play host to the Workflow controller component. Take note of the following: The hostname or public IP of your PostgreSQL RDBMS The port on which your PostgreSQL RDBMS runs-- typically 5432 Within the off-cluster RDBMS, manually provision the following: A database user (take note of the username and password) A database owned by that user (take note of its name) If you are able to log into the RDBMS as a superuser or a user with appropriate permissions, this process will typically look like this: $ psql -h <host> -p <port> -d postgres -U <\"postgres\" or your own username> > create user <deis username; typically \"deis\"> with password '<password>'; > create database <database name; typically \"deis\"> with owner <deis username>; > \\q Configuring Workflow \u00b6 The Helm chart for Deis Workflow can be easily configured to connect the Workflow controller component to an off-cluster PostgreSQL database. Step 1: If you haven't already fetched the values, do so with helm inspect values deis/workflow > values.yaml Step 2: Update database connection details by modifying values.yaml : Update the database_location parameter to off-cluster . Update the values in the [database] configuration section to properly reflect all connection details. Save your changes. Note: you do not need to (and must not) base64 encode any values, as the Helm chart will automatically handle encoding as necessary. You are now ready to helm install deis/workflow --namespace deis -f values.yaml as usual .","title":"Configuring Postgres"},{"location":"installing-workflow/configuring-postgres/#configuring-postgres","text":"Deis Workflow's controller component relies on a PostgreSQL database to store platform state. By default, Deis Workflow ships with the database component, which provides an in-cluster PostgreSQL database backed up to in-cluster or off-cluster object storage . Currently, for object storage, which is utilized by several Workflow components, only off-cluster solutions such as S3 or GCS are recommended in production environments. Experience has shown that many operators already opting for off-cluster object storage similarly prefer to host Postgres off-cluster as well, using Amazon RDS or similar. When excercising both options, a Workflow installation becomes entirely stateless, and is thus restored or rebuilt with greater ease should the need ever arise.","title":"Configuring Postgres"},{"location":"installing-workflow/configuring-postgres/#provisioning-off-cluster-postgres","text":"First, provision a PostgreSQL RDBMS using the cloud provider or other infrastructure of your choice. Take care to ensure that security groups or other firewall rules will permit connectivity from your Kubernetes worker nodes, any of which may play host to the Workflow controller component. Take note of the following: The hostname or public IP of your PostgreSQL RDBMS The port on which your PostgreSQL RDBMS runs-- typically 5432 Within the off-cluster RDBMS, manually provision the following: A database user (take note of the username and password) A database owned by that user (take note of its name) If you are able to log into the RDBMS as a superuser or a user with appropriate permissions, this process will typically look like this: $ psql -h <host> -p <port> -d postgres -U <\"postgres\" or your own username> > create user <deis username; typically \"deis\"> with password '<password>'; > create database <database name; typically \"deis\"> with owner <deis username>; > \\q","title":"Provisioning off-cluster Postgres"},{"location":"installing-workflow/configuring-postgres/#configuring-workflow","text":"The Helm chart for Deis Workflow can be easily configured to connect the Workflow controller component to an off-cluster PostgreSQL database. Step 1: If you haven't already fetched the values, do so with helm inspect values deis/workflow > values.yaml Step 2: Update database connection details by modifying values.yaml : Update the database_location parameter to off-cluster . Update the values in the [database] configuration section to properly reflect all connection details. Save your changes. Note: you do not need to (and must not) base64 encode any values, as the Helm chart will automatically handle encoding as necessary. You are now ready to helm install deis/workflow --namespace deis -f values.yaml as usual .","title":"Configuring Workflow"},{"location":"installing-workflow/configuring-registry/","text":"Configuring Registry \u00b6 Deis Workflow's builder component relies on a registry for storing application docker images. Deis Workflow ships with a registry component by default, which provides an in-cluster Docker registry backed by the platform-configured object storage . Operators might want to use an off-cluster registry for performance or security reasons. Configuring Off-Cluster Private Registry \u00b6 Every component that relies on a registry uses two inputs for configuration: Registry Location environment variable named DEIS_REGISTRY_LOCATION Access credentials stored as a Kubernetes secret named registry-secret The Helm chart for Deis Workflow can be easily configured to connect Workflow components to off-cluster registry. Deis Workflow supports external registries which provide either short-lived tokens that are valid only for a specified amount of time or long-lived tokens (basic username/password) which are valid forever for authenticating to them. For those registries which provide short lived tokens for authentication, Deis Workflow will generate and refresh them such that the deployed apps will only have access to the short-lived tokens and not to the actual credentials for the registries. When using a private registry the docker images are no longer pulled by Deis Workflow Controller but rather are managed by Kubernetes . This will increase security and overall speed, however the port information can no longer be discovered. Instead the port information can be set via deis config:set PORT=<port> prior to deploying the application. Deis Workflow currently supports: Google Container Registry( gcr ). EC2 Container Registry( ecr ). off-cluster: Any provider which supports long-lived username/password authentication, such as Azure Container Registry , Docker Hub , quay.io , or a self-hosted Docker registry. Configuration \u00b6 If you haven't already fetched the values file, do so with helm inspect values deis/workflow > values.yaml Update registry location details by modifying the values file: Update the registry_location parameter to reference the registry location you are using: off-cluster , ecr , gcr Update the values in the section which corresponds to your registry location type. You are now ready to helm install deis/workflow --namespace deis -f values.yaml using your desired registry. Examples \u00b6 Here we show how the relevant parts of the fetched values.yaml file might look like after configuring for a particular off-cluster registry: ECR \u00b6 global: ... registry_location: \"ecr\" ... registry-token-refresher: # Time in minutes after which the token should be refreshed. # Leave it empty to use the default provider time. token_refresh_time: \"\" ... ecr: # Your AWS access key. Leave it empty if you want to use IAM credentials. accesskey: \"ACCESS_KEY\" # Your AWS secret key. Leave it empty if you want to use IAM credentials. secretkey: \"SECRET_KEY\" # Any S3 region region: \"us-west-2\" registryid: \"\" hostname: \"\" ... Note: registryid and hostname should not be set. See this issue for more info. GCR \u00b6 global: ... registry_location: \"gcr\" ... registry-token-refresher: # Time in minutes after which the token should be refreshed. # Leave it empty to use the default provider time. token_refresh_time: \"\" ... gcr: key_json: <base64-encoded JSON data> hostname: \"\" Note: hostname should be left empty. Azure Container Registry (ACR) \u00b6 After following the docs and creating a registry, e.g. myregistry , with its corresponding login server of myregistry.azurecr.io , the following values should be supplied: global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... off_cluster_registry: hostname: \"myregistry.azurecr.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ... Note: The mandatory organization field (here myorg ) will be created as an ACR repository if it does not already exist. Quay.io \u00b6 global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... off_cluster_registry: hostname: \"quay.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ...","title":"Configuring the Registry"},{"location":"installing-workflow/configuring-registry/#configuring-registry","text":"Deis Workflow's builder component relies on a registry for storing application docker images. Deis Workflow ships with a registry component by default, which provides an in-cluster Docker registry backed by the platform-configured object storage . Operators might want to use an off-cluster registry for performance or security reasons.","title":"Configuring Registry"},{"location":"installing-workflow/configuring-registry/#configuring-off-cluster-private-registry","text":"Every component that relies on a registry uses two inputs for configuration: Registry Location environment variable named DEIS_REGISTRY_LOCATION Access credentials stored as a Kubernetes secret named registry-secret The Helm chart for Deis Workflow can be easily configured to connect Workflow components to off-cluster registry. Deis Workflow supports external registries which provide either short-lived tokens that are valid only for a specified amount of time or long-lived tokens (basic username/password) which are valid forever for authenticating to them. For those registries which provide short lived tokens for authentication, Deis Workflow will generate and refresh them such that the deployed apps will only have access to the short-lived tokens and not to the actual credentials for the registries. When using a private registry the docker images are no longer pulled by Deis Workflow Controller but rather are managed by Kubernetes . This will increase security and overall speed, however the port information can no longer be discovered. Instead the port information can be set via deis config:set PORT=<port> prior to deploying the application. Deis Workflow currently supports: Google Container Registry( gcr ). EC2 Container Registry( ecr ). off-cluster: Any provider which supports long-lived username/password authentication, such as Azure Container Registry , Docker Hub , quay.io , or a self-hosted Docker registry.","title":"Configuring Off-Cluster Private Registry"},{"location":"installing-workflow/configuring-registry/#configuration","text":"If you haven't already fetched the values file, do so with helm inspect values deis/workflow > values.yaml Update registry location details by modifying the values file: Update the registry_location parameter to reference the registry location you are using: off-cluster , ecr , gcr Update the values in the section which corresponds to your registry location type. You are now ready to helm install deis/workflow --namespace deis -f values.yaml using your desired registry.","title":"Configuration"},{"location":"installing-workflow/configuring-registry/#examples","text":"Here we show how the relevant parts of the fetched values.yaml file might look like after configuring for a particular off-cluster registry:","title":"Examples"},{"location":"installing-workflow/configuring-registry/#ecr","text":"global: ... registry_location: \"ecr\" ... registry-token-refresher: # Time in minutes after which the token should be refreshed. # Leave it empty to use the default provider time. token_refresh_time: \"\" ... ecr: # Your AWS access key. Leave it empty if you want to use IAM credentials. accesskey: \"ACCESS_KEY\" # Your AWS secret key. Leave it empty if you want to use IAM credentials. secretkey: \"SECRET_KEY\" # Any S3 region region: \"us-west-2\" registryid: \"\" hostname: \"\" ... Note: registryid and hostname should not be set. See this issue for more info.","title":"ECR"},{"location":"installing-workflow/configuring-registry/#gcr","text":"global: ... registry_location: \"gcr\" ... registry-token-refresher: # Time in minutes after which the token should be refreshed. # Leave it empty to use the default provider time. token_refresh_time: \"\" ... gcr: key_json: <base64-encoded JSON data> hostname: \"\" Note: hostname should be left empty.","title":"GCR"},{"location":"installing-workflow/configuring-registry/#azure-container-registry-acr","text":"After following the docs and creating a registry, e.g. myregistry , with its corresponding login server of myregistry.azurecr.io , the following values should be supplied: global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... off_cluster_registry: hostname: \"myregistry.azurecr.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ... Note: The mandatory organization field (here myorg ) will be created as an ACR repository if it does not already exist.","title":"Azure Container Registry (ACR)"},{"location":"installing-workflow/configuring-registry/#quayio","text":"global: ... registry_location: \"off-cluster\" ... registry-token-refresher: ... off_cluster_registry: hostname: \"quay.io\" organization: \"myorg\" username: \"myusername\" password: \"mypassword\" ...","title":"Quay.io"},{"location":"installing-workflow/experimental-native-ingress/","text":"Experimental Native Ingress \u00b6 Install Deis Workflow (With experimental native ingress support) \u00b6 Now that Helm is installed and the repository has been added, install Workflow with a native ingress by running: $ helm install deis/workflow --namespace deis --set global.experimental_native_ingress=true,controller.platform_domain=deis.com Where controller.platform_domain is a required parameter that is traditionally not required for Workflow that is explained in the next section. In this example we are using deis.com for $hostname . Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods You should also notice that several Kubernetes ingresses has been installed on your cluster. You can view it by running: $ kubectl get ingress --namespace deis Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops waiting for minio before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Install a Kubernetes Ingress Controller \u00b6 Now that Workflow has been deployed with the global.experimental_native_ingress flag set to true , we will need a Kubernetes ingress controller in place to begin routing traffic. Here is an example of how to use traefik as an ingress controller for Workflow. Of course, you are welcome to use any controller you wish. $ helm install stable/traefik --name ingress --namespace kube-system Configure DNS \u00b6 The experimental ingress feature requires a user to set up a hostname, and assumes the deis.$host convention. We need to point the *.$host record to the public IP address of your ingress controller. You can get the public IP using the following command. A wildcard entry is necessary here as apps will use the same rule after they are deployed. $ kubectl get svc ingress-traefik --namespace kube-system NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-traefik 10.0.25.3 138.91.243.152 80:31625/TCP,443:30871/TCP 33m Additionally, we need to point the deis-builder.$host record to the public IP address of the Builder . $ kubectl get svc deis-builder --namespace deis NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE deis-builder 10.0.165.140 40.86.182.187 2222:32488/TCP 33m If we were using deis.com as a hostname, we would need to create the following A DNS records. Name Type Value *.deis.com A 138.91.243.152 deis-builder.deis.com A 40.86.182.187 Once all of the pods are in the READY state, and deis.$host resolves to the external IP found above, Workflow is up and running! After installing Workflow, register a user and deploy an application . Feedback \u00b6 While this feature is experimental we welcome feedback on the issue. We would like to learn more about use cases, and user experience. Please open a new issue for feedback.","title":"Experimental Native Ingress"},{"location":"installing-workflow/experimental-native-ingress/#experimental-native-ingress","text":"","title":"Experimental Native Ingress"},{"location":"installing-workflow/experimental-native-ingress/#install-deis-workflow-with-experimental-native-ingress-support","text":"Now that Helm is installed and the repository has been added, install Workflow with a native ingress by running: $ helm install deis/workflow --namespace deis --set global.experimental_native_ingress=true,controller.platform_domain=deis.com Where controller.platform_domain is a required parameter that is traditionally not required for Workflow that is explained in the next section. In this example we are using deis.com for $hostname . Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods You should also notice that several Kubernetes ingresses has been installed on your cluster. You can view it by running: $ kubectl get ingress --namespace deis Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops waiting for minio before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-workflow-manager-68nu6 1/1 Running 0 5m","title":"Install Deis Workflow (With experimental native ingress support)"},{"location":"installing-workflow/experimental-native-ingress/#install-a-kubernetes-ingress-controller","text":"Now that Workflow has been deployed with the global.experimental_native_ingress flag set to true , we will need a Kubernetes ingress controller in place to begin routing traffic. Here is an example of how to use traefik as an ingress controller for Workflow. Of course, you are welcome to use any controller you wish. $ helm install stable/traefik --name ingress --namespace kube-system","title":"Install a Kubernetes Ingress Controller"},{"location":"installing-workflow/experimental-native-ingress/#configure-dns","text":"The experimental ingress feature requires a user to set up a hostname, and assumes the deis.$host convention. We need to point the *.$host record to the public IP address of your ingress controller. You can get the public IP using the following command. A wildcard entry is necessary here as apps will use the same rule after they are deployed. $ kubectl get svc ingress-traefik --namespace kube-system NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-traefik 10.0.25.3 138.91.243.152 80:31625/TCP,443:30871/TCP 33m Additionally, we need to point the deis-builder.$host record to the public IP address of the Builder . $ kubectl get svc deis-builder --namespace deis NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE deis-builder 10.0.165.140 40.86.182.187 2222:32488/TCP 33m If we were using deis.com as a hostname, we would need to create the following A DNS records. Name Type Value *.deis.com A 138.91.243.152 deis-builder.deis.com A 40.86.182.187 Once all of the pods are in the READY state, and deis.$host resolves to the external IP found above, Workflow is up and running! After installing Workflow, register a user and deploy an application .","title":"Configure DNS"},{"location":"installing-workflow/experimental-native-ingress/#feedback","text":"While this feature is experimental we welcome feedback on the issue. We would like to learn more about use cases, and user experience. Please open a new issue for feedback.","title":"Feedback"},{"location":"installing-workflow/system-requirements/","text":"Requirements \u00b6 To run Deis Workflow on a Kubernetes cluster, there are a few requirements to keep in mind. Kubernetes Versions \u00b6 Deis Workflow requires Kubernetes v1.3.4 or later, or Kubernetes v1.6.2 or later. Kubernetes v1.6.0 and v1.6.1 have a bug that can prevent git push deis master from completing successfully. Storage Requirements \u00b6 A variety of Deis Workflow components rely on an object storage system to do their work, including storing application slugs, Docker images and database logs. Deis Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost. Therefore, Minio should be used for development or testing only. Workflow supports Amazon Simple Storage Service (S3), Google Cloud Storage (GCS), OpenShift Swift, and Azure Blob Storage. See configuring object storage for setup instructions. Resource Requirements \u00b6 When deploying Deis Workflow, it's important to provision machines with adequate resources. Deis is a highly-available distributed system, which means that Deis components and your deployed applications will move around the cluster onto healthy hosts as hosts leave the cluster for various reasons (failures, reboots, autoscalers, etc.). Because of this, you should have ample spare resources on any machine in your cluster to withstand the additional load of running services for failed machines. Deis Workflow components use about 2.5GB of memory across the cluster, and require approximately 30GB of hard disk space. Because it may need to handle additional load if another one fails, each machine has minimum requirements of: At least 4GB of RAM (more is better) At least 40GB of hard disk space Note that these estimates are for Deis Workflow and Kubernetes only. Be sure to leave enough spare capacity for your application footprint as well. Running smaller machines will likely result in increased system load and has been known to result in component failures and instability. Warning Workflow versions prior to 2.2 require '--insecure-registry' to function properly. Depending on your Kubernetes and Docker configuration, setting EXTRA_DOCKER_OPTS=\"--insecure-registry=10.0.0.0/8\" may be sufficient. SELinux + OverlayFS \u00b6 If you are using Docker with OverlayFS, you must disable SELinux by adding --selinux-enabled=false to EXTRA_DOCKER_OPTS . For more background information, see: https://github.com/docker/docker/issues/7952 https://github.com/deis/workflow/issues/63","title":"System Requirements"},{"location":"installing-workflow/system-requirements/#requirements","text":"To run Deis Workflow on a Kubernetes cluster, there are a few requirements to keep in mind.","title":"Requirements"},{"location":"installing-workflow/system-requirements/#kubernetes-versions","text":"Deis Workflow requires Kubernetes v1.3.4 or later, or Kubernetes v1.6.2 or later. Kubernetes v1.6.0 and v1.6.1 have a bug that can prevent git push deis master from completing successfully.","title":"Kubernetes Versions"},{"location":"installing-workflow/system-requirements/#storage-requirements","text":"A variety of Deis Workflow components rely on an object storage system to do their work, including storing application slugs, Docker images and database logs. Deis Workflow ships with Minio by default, which provides in-cluster, ephemeral object storage. This means that if the Minio server crashes, all data will be lost. Therefore, Minio should be used for development or testing only. Workflow supports Amazon Simple Storage Service (S3), Google Cloud Storage (GCS), OpenShift Swift, and Azure Blob Storage. See configuring object storage for setup instructions.","title":"Storage Requirements"},{"location":"installing-workflow/system-requirements/#resource-requirements","text":"When deploying Deis Workflow, it's important to provision machines with adequate resources. Deis is a highly-available distributed system, which means that Deis components and your deployed applications will move around the cluster onto healthy hosts as hosts leave the cluster for various reasons (failures, reboots, autoscalers, etc.). Because of this, you should have ample spare resources on any machine in your cluster to withstand the additional load of running services for failed machines. Deis Workflow components use about 2.5GB of memory across the cluster, and require approximately 30GB of hard disk space. Because it may need to handle additional load if another one fails, each machine has minimum requirements of: At least 4GB of RAM (more is better) At least 40GB of hard disk space Note that these estimates are for Deis Workflow and Kubernetes only. Be sure to leave enough spare capacity for your application footprint as well. Running smaller machines will likely result in increased system load and has been known to result in component failures and instability. Warning Workflow versions prior to 2.2 require '--insecure-registry' to function properly. Depending on your Kubernetes and Docker configuration, setting EXTRA_DOCKER_OPTS=\"--insecure-registry=10.0.0.0/8\" may be sufficient.","title":"Resource Requirements"},{"location":"installing-workflow/system-requirements/#selinux-overlayfs","text":"If you are using Docker with OverlayFS, you must disable SELinux by adding --selinux-enabled=false to EXTRA_DOCKER_OPTS . For more background information, see: https://github.com/docker/docker/issues/7952 https://github.com/deis/workflow/issues/63","title":"SELinux + OverlayFS"},{"location":"managing-workflow/configuring-dns/","text":"Configure DNS \u00b6 The Deis Workflow controller and all applications deployed via Workflow are intended (by default) to be accessible as subdomains of the Workflow cluster's domain. For example, assuming example.com were a cluster's domain: The controller should be accessible at deis.example.com Applications should be accessible (by default) at <application name>.example.com Given that this is the case, the primary objective in configuring DNS is that traffic for all subdomains of a cluster's domain be directed to the cluster node(s) hosting the platform's router component, which is capable of directing traffic within the cluster to the correct endpoints. With a Load Balancer \u00b6 Generally, it is recommended that a load balancer be used to direct inbound traffic to one or more routers. In such a case, configuring DNS is as simple as defining a wildcard record in DNS that points to the load balancer. For example, assuming a domain of example.com : An A record enumerating each of your load balancer(s) IPs (i.e. DNS round-robining) A CNAME record referencing an existing fully-qualified domain name for the load balancer Per AWS' own documentation , this is the recommended strategy when using AWS Elastic Load Balancers, as ELB IPs may change over time. DNS for any applications using a \"custom domain\" (a fully-qualified domain name that is not a subdomain of the cluster's own domain) can be configured by creating a CNAME record that references the wildcard record described above. Although it is dependent upon your distribution of Kubernetes and your underlying infrastructure, in many cases, the IP(s) or existing fully-qualified domain name of a load balancer can be determined directly using the kubectl tool: $ kubectl --namespace=deis describe service deis-router | grep \"LoadBalancer Ingress\" LoadBalancer Ingress: a493e4e58ea0511e5bb390686bc85da3-1558404688.us-west-2.elb.amazonaws.com The LoadBalancer Ingress field typically describes an existing domain name or public IP(s). Note that if Kubernetes is able to automatically provision a load balancer for you, it does so asynchronously. If the command shown above is issued very soon after Workflow installation, the load balancer may not exist yet. Without a Load Balancer \u00b6 On some platforms (Minikube, for instance), a load balancer is not an easy or practical thing to provision. In these cases, one can directly identify the public IP of a Kubernetes node that is hosting a router pod and use that information to configure the local /etc/hosts file. Because wildcard entries do not work in a local /etc/hosts file, using this strategy may result in frequent editing of that file to add fully-qualified subdomains of a cluster for each application added to that cluster. Because of this a more viable option may be to utilize the xip.io service. In general, for any IP, a.b.c.d , the fully-qualified domain name any-subdomain.a.b.c.d.xip.io will resolve to the IP a.b.c.d . This can be enormously useful. To begin, find the node(s) hosting router instances using kubectl : $ kubectl --namespace=deis describe pod deis-router | grep Node Node: ip-10-0-0-199.us-west-2.compute.internal/10.0.0.199 Node: ip-10-0-0-198.us-west-2.compute.internal/10.0.0.198 The command will display information for every router pod. For each, a node name and IP are displayed in the Node field. If the IPs appearing in these fields are public, any of these may be used to configure your local /etc/hosts file or may be used with xip.io . If the IPs shown are not public, further investigation may be needed. You can list the IP addresses of a node using kubectl : $ kubectl describe node ip-10-0-0-199.us-west-2.compute.internal # ... Addresses: 10.0.0.199,10.0.0.199,54.218.85.175 # ... Here, the Addresses field lists all the node's IPs. If any of them are public, again, they may be used to configure your local /etc/hosts file or may be used with xip.io . Tutorial: Configuring DNS with Google Cloud DNS \u00b6 In this section, we'll describe how to configure Google Cloud DNS for routing your domain name to your Deis cluster. We'll assume the following in this section: Your Deis router service has a load balancer in front of it. The load balancer need not be cloud based, it just needs to provide a stable IP address or a stable domain name You have the mystuff.com domain name registered with a registrar Replace your domain name with mystuff.com in the instructions to follow Your registrar lets you alter the nameservers for your domain name (most registrars do) Here are the steps for configuring cloud DNS to route to your deis cluster: Get the load balancer IP or domain name If you are on Google Container Engine, you can run kubectl get svc deis-router and look for the LoadBalancer Ingress column to get the IP address Create a new Cloud DNS Zone (on the console: Networking => Cloud DNS , then click on Create Zone ) Name your zone, and set the DNS name to mystuff.com. (note the . at the end Click on the Create button Click on the Add Record Set button on the resulting page If your load balancer provides a stable IP address, enter the following fields in the resulting form: DNS Name : * Resource Record Type : A TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many deis clusters over time, we recommend a low TTL IPv4 Address : The IP that you got in the very first step Click the Create button If your load balancer provides the stable domain name lbdomain.com , enter the following fields in the resulting form: DNS Name : * Resource Record Type : CNAME TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many deis clusters over time, we recommend a low TTL Canonical name : lbdomain.com. (note the . a the end) Click on the Create button In your domain registrar, set the nameservers for your mystuff.com domain to the ones under the data column in the NS record on the same page. They'll often be something like the below (note the trailing . characters). ns-cloud-b1.googledomains.com. ns-cloud-b2.googledomains.com. ns-cloud-b3.googledomains.com. ns-cloud-b4.googledomains.com. Note: If you ever have to re-create your deis cluster, simply go back to step 6.4 or 7.4 (depending on your load balancer) and change the IP address or domain name to the new value. You may have to wait for the TTL you set to expire. Testing \u00b6 To test that traffic reaches its intended destination, a request can be sent to the Deis controller like so (do not forget the trailing slash!): curl http://deis.example.com/v2/ Or: curl http://deis.54.218.85.175.xip.io/v2/ Since such requests require authentication, a response such as the following should be considered an indicator of success: {\"detail\":\"Authentication credentials were not provided.\"}","title":"Configuring DNS"},{"location":"managing-workflow/configuring-dns/#configure-dns","text":"The Deis Workflow controller and all applications deployed via Workflow are intended (by default) to be accessible as subdomains of the Workflow cluster's domain. For example, assuming example.com were a cluster's domain: The controller should be accessible at deis.example.com Applications should be accessible (by default) at <application name>.example.com Given that this is the case, the primary objective in configuring DNS is that traffic for all subdomains of a cluster's domain be directed to the cluster node(s) hosting the platform's router component, which is capable of directing traffic within the cluster to the correct endpoints.","title":"Configure DNS"},{"location":"managing-workflow/configuring-dns/#with-a-load-balancer","text":"Generally, it is recommended that a load balancer be used to direct inbound traffic to one or more routers. In such a case, configuring DNS is as simple as defining a wildcard record in DNS that points to the load balancer. For example, assuming a domain of example.com : An A record enumerating each of your load balancer(s) IPs (i.e. DNS round-robining) A CNAME record referencing an existing fully-qualified domain name for the load balancer Per AWS' own documentation , this is the recommended strategy when using AWS Elastic Load Balancers, as ELB IPs may change over time. DNS for any applications using a \"custom domain\" (a fully-qualified domain name that is not a subdomain of the cluster's own domain) can be configured by creating a CNAME record that references the wildcard record described above. Although it is dependent upon your distribution of Kubernetes and your underlying infrastructure, in many cases, the IP(s) or existing fully-qualified domain name of a load balancer can be determined directly using the kubectl tool: $ kubectl --namespace=deis describe service deis-router | grep \"LoadBalancer Ingress\" LoadBalancer Ingress: a493e4e58ea0511e5bb390686bc85da3-1558404688.us-west-2.elb.amazonaws.com The LoadBalancer Ingress field typically describes an existing domain name or public IP(s). Note that if Kubernetes is able to automatically provision a load balancer for you, it does so asynchronously. If the command shown above is issued very soon after Workflow installation, the load balancer may not exist yet.","title":"With a Load Balancer"},{"location":"managing-workflow/configuring-dns/#without-a-load-balancer","text":"On some platforms (Minikube, for instance), a load balancer is not an easy or practical thing to provision. In these cases, one can directly identify the public IP of a Kubernetes node that is hosting a router pod and use that information to configure the local /etc/hosts file. Because wildcard entries do not work in a local /etc/hosts file, using this strategy may result in frequent editing of that file to add fully-qualified subdomains of a cluster for each application added to that cluster. Because of this a more viable option may be to utilize the xip.io service. In general, for any IP, a.b.c.d , the fully-qualified domain name any-subdomain.a.b.c.d.xip.io will resolve to the IP a.b.c.d . This can be enormously useful. To begin, find the node(s) hosting router instances using kubectl : $ kubectl --namespace=deis describe pod deis-router | grep Node Node: ip-10-0-0-199.us-west-2.compute.internal/10.0.0.199 Node: ip-10-0-0-198.us-west-2.compute.internal/10.0.0.198 The command will display information for every router pod. For each, a node name and IP are displayed in the Node field. If the IPs appearing in these fields are public, any of these may be used to configure your local /etc/hosts file or may be used with xip.io . If the IPs shown are not public, further investigation may be needed. You can list the IP addresses of a node using kubectl : $ kubectl describe node ip-10-0-0-199.us-west-2.compute.internal # ... Addresses: 10.0.0.199,10.0.0.199,54.218.85.175 # ... Here, the Addresses field lists all the node's IPs. If any of them are public, again, they may be used to configure your local /etc/hosts file or may be used with xip.io .","title":"Without a Load Balancer"},{"location":"managing-workflow/configuring-dns/#tutorial-configuring-dns-with-google-cloud-dns","text":"In this section, we'll describe how to configure Google Cloud DNS for routing your domain name to your Deis cluster. We'll assume the following in this section: Your Deis router service has a load balancer in front of it. The load balancer need not be cloud based, it just needs to provide a stable IP address or a stable domain name You have the mystuff.com domain name registered with a registrar Replace your domain name with mystuff.com in the instructions to follow Your registrar lets you alter the nameservers for your domain name (most registrars do) Here are the steps for configuring cloud DNS to route to your deis cluster: Get the load balancer IP or domain name If you are on Google Container Engine, you can run kubectl get svc deis-router and look for the LoadBalancer Ingress column to get the IP address Create a new Cloud DNS Zone (on the console: Networking => Cloud DNS , then click on Create Zone ) Name your zone, and set the DNS name to mystuff.com. (note the . at the end Click on the Create button Click on the Add Record Set button on the resulting page If your load balancer provides a stable IP address, enter the following fields in the resulting form: DNS Name : * Resource Record Type : A TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many deis clusters over time, we recommend a low TTL IPv4 Address : The IP that you got in the very first step Click the Create button If your load balancer provides the stable domain name lbdomain.com , enter the following fields in the resulting form: DNS Name : * Resource Record Type : CNAME TTL : the DNS TTL of your choosing. If you're testing or you anticipate that you'll tear down and rebuild many deis clusters over time, we recommend a low TTL Canonical name : lbdomain.com. (note the . a the end) Click on the Create button In your domain registrar, set the nameservers for your mystuff.com domain to the ones under the data column in the NS record on the same page. They'll often be something like the below (note the trailing . characters). ns-cloud-b1.googledomains.com. ns-cloud-b2.googledomains.com. ns-cloud-b3.googledomains.com. ns-cloud-b4.googledomains.com. Note: If you ever have to re-create your deis cluster, simply go back to step 6.4 or 7.4 (depending on your load balancer) and change the IP address or domain name to the new value. You may have to wait for the TTL you set to expire.","title":"Tutorial: Configuring DNS with Google Cloud DNS"},{"location":"managing-workflow/configuring-dns/#testing","text":"To test that traffic reaches its intended destination, a request can be sent to the Deis controller like so (do not forget the trailing slash!): curl http://deis.example.com/v2/ Or: curl http://deis.54.218.85.175.xip.io/v2/ Since such requests require authentication, a response such as the following should be considered an indicator of success: {\"detail\":\"Authentication credentials were not provided.\"}","title":"Testing"},{"location":"managing-workflow/configuring-load-balancers/","text":"Configuring Load Balancers \u00b6 Depending on what distribution of Kubernetes you use and where you host it, installation of Deis Workflow may automatically provision an external (to Kubernetes) load balancer or similar mechanism for directing inbound traffic from beyond the cluster to the Deis router(s). For example, kube-aws and Google Container Engine both do this. On some other platforms-- Minikube or bare metal, for instance-- this must either be accomplished manually or does not apply at all. Idle connection timeouts \u00b6 If a load balancer such as the one described above does exist (whether created automatically or manually) and if you intend on handling any long-running requests, the load balancer (or similar) may require some manual configuration to increase the idle connection timeout. Typically, this is most applicable to AWS and Elastic Load Balancers, but may apply in other cases as well. It does not apply to Google Container Engine, as the idle connection timeout cannot be configured there, but also works as-is. If, for instance, Deis Workflow were installed on kube-aws, this timeout should be increased to a recommended value of 1200 seconds. This will ensure the load balancer does not hang up on the client during long-running operations like an application deployment. The AWS-specific annotation below will be included by default in the router service starting in Workflow v2.13.0. If you are running Kubernetes v1.4 or later but a Workflow version earlier than v2.13.0, you should configure the idle timeout using this service annotation: $ kubectl --namespace=deis annotate service/deis-router service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout=1200 On older Kubernetes versions, you have to configure the idle timeout manually , but it will reset back to the default of 60 seconds whenever Kubernetes needs to reconfigure the load balancer, for example because a node in your cluster was added or removed. Remember to re-apply your manual changes if that happens. Configuring PROXY protocol \u00b6 By default Kubernetes will create an external TCP load balancer to route incoming requests to the Deis router, which will take care of forwarding the requests to the right application inside the cluster depending on the hostname. Because the original request is not modified by the load balancer, the router only knows about the internal IP address of the load balancer which will then be forwarded to your app in the X-Forwarded-For HTTP header. If you need access to the actual client's IP address in your application, for example for IP-based sessions, access control or auditing, you need to configure the external load balancer and the Deis router to use the PROXY protocol . The PROXY protocol adds a small header with the client's IP address to each connection, which can then be used by the Deis router to pass the actual client IP in the X-Forwarded-For HTTP header. Here's how to enable PROXY protocol when running Kubernetes on AWS with an ELB Classic Load Balancer: Enable PROXY protocol for the deis-router deployment: $ kubectl --namespace=deis annotate deployment/deis-router router.deis.io/nginx.useProxyProtocol=true Enable PROXY protocol on the ELB load balancer for the deis-router service: $ kubectl --namespace=deis annotate service/deis-router service.beta.kubernetes.io/aws-load-balancer-proxy-protocol='*' Prepare for a short downtime until both the ELB and the router have converged to the new configuration. Important ELB PROXY protocol support was added in Kubernetes 1.3. If you are still on Kubernetes 1.2, you need to first upgrade to a newer supported Kubernetes version . Manually configuring a load balancer \u00b6 If using a Kubernetes distribution or underlying infrastructure that does not support the automated provisioning of a front-facing load balancer, operators will wish to manually configure a load balancer (or use other tricks) to route inbound traffic from beyond the cluster into the cluster to the Deis router(s). There are many ways to accomplish this. This documentation will focus on the most common method. Readers interested in other options may refer to the router component's own documentation for further details. Begin by determining the \"node ports\" for the deis-router service: $ kubectl --namespace=deis describe service deis-router This will yield output similar to the following: ... Port: http 80/TCP NodePort: http 32477/TCP Endpoints: 10.2.80.11:80 Port: https 443/TCP NodePort: https 32389/TCP Endpoints: 10.2.80.11:443 Port: builder 2222/TCP NodePort: builder 30729/TCP Endpoints: 10.2.80.11:2222 Port: healthz 9090/TCP NodePort: healthz 31061/TCP Endpoints: 10.2.80.11:9090 ... The node ports shown above are high-numbered ports that are allocated on every Kubernetes worker node for use by the router service. The kube-proxy component on every Kubernetes node will listen on these ports and proxy traffic through to the corresponding port within an endpoint-- that is, a pod running the Deis router. If manually creating a load balancer, configure it to forward inbound traffic on ports 80, 443, and 2222 (port 9090 can be ignored) to the corresponding node ports on your Kubernetes worker nodes. Ports 80 and 443 may use either HTTP/S or TCP as protocols. Port 2222 must use TCP.","title":"Configuring Load Balancers"},{"location":"managing-workflow/configuring-load-balancers/#configuring-load-balancers","text":"Depending on what distribution of Kubernetes you use and where you host it, installation of Deis Workflow may automatically provision an external (to Kubernetes) load balancer or similar mechanism for directing inbound traffic from beyond the cluster to the Deis router(s). For example, kube-aws and Google Container Engine both do this. On some other platforms-- Minikube or bare metal, for instance-- this must either be accomplished manually or does not apply at all.","title":"Configuring Load Balancers"},{"location":"managing-workflow/configuring-load-balancers/#idle-connection-timeouts","text":"If a load balancer such as the one described above does exist (whether created automatically or manually) and if you intend on handling any long-running requests, the load balancer (or similar) may require some manual configuration to increase the idle connection timeout. Typically, this is most applicable to AWS and Elastic Load Balancers, but may apply in other cases as well. It does not apply to Google Container Engine, as the idle connection timeout cannot be configured there, but also works as-is. If, for instance, Deis Workflow were installed on kube-aws, this timeout should be increased to a recommended value of 1200 seconds. This will ensure the load balancer does not hang up on the client during long-running operations like an application deployment. The AWS-specific annotation below will be included by default in the router service starting in Workflow v2.13.0. If you are running Kubernetes v1.4 or later but a Workflow version earlier than v2.13.0, you should configure the idle timeout using this service annotation: $ kubectl --namespace=deis annotate service/deis-router service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout=1200 On older Kubernetes versions, you have to configure the idle timeout manually , but it will reset back to the default of 60 seconds whenever Kubernetes needs to reconfigure the load balancer, for example because a node in your cluster was added or removed. Remember to re-apply your manual changes if that happens.","title":"Idle connection timeouts"},{"location":"managing-workflow/configuring-load-balancers/#configuring-proxy-protocol","text":"By default Kubernetes will create an external TCP load balancer to route incoming requests to the Deis router, which will take care of forwarding the requests to the right application inside the cluster depending on the hostname. Because the original request is not modified by the load balancer, the router only knows about the internal IP address of the load balancer which will then be forwarded to your app in the X-Forwarded-For HTTP header. If you need access to the actual client's IP address in your application, for example for IP-based sessions, access control or auditing, you need to configure the external load balancer and the Deis router to use the PROXY protocol . The PROXY protocol adds a small header with the client's IP address to each connection, which can then be used by the Deis router to pass the actual client IP in the X-Forwarded-For HTTP header. Here's how to enable PROXY protocol when running Kubernetes on AWS with an ELB Classic Load Balancer: Enable PROXY protocol for the deis-router deployment: $ kubectl --namespace=deis annotate deployment/deis-router router.deis.io/nginx.useProxyProtocol=true Enable PROXY protocol on the ELB load balancer for the deis-router service: $ kubectl --namespace=deis annotate service/deis-router service.beta.kubernetes.io/aws-load-balancer-proxy-protocol='*' Prepare for a short downtime until both the ELB and the router have converged to the new configuration. Important ELB PROXY protocol support was added in Kubernetes 1.3. If you are still on Kubernetes 1.2, you need to first upgrade to a newer supported Kubernetes version .","title":"Configuring PROXY protocol"},{"location":"managing-workflow/configuring-load-balancers/#manually-configuring-a-load-balancer","text":"If using a Kubernetes distribution or underlying infrastructure that does not support the automated provisioning of a front-facing load balancer, operators will wish to manually configure a load balancer (or use other tricks) to route inbound traffic from beyond the cluster into the cluster to the Deis router(s). There are many ways to accomplish this. This documentation will focus on the most common method. Readers interested in other options may refer to the router component's own documentation for further details. Begin by determining the \"node ports\" for the deis-router service: $ kubectl --namespace=deis describe service deis-router This will yield output similar to the following: ... Port: http 80/TCP NodePort: http 32477/TCP Endpoints: 10.2.80.11:80 Port: https 443/TCP NodePort: https 32389/TCP Endpoints: 10.2.80.11:443 Port: builder 2222/TCP NodePort: builder 30729/TCP Endpoints: 10.2.80.11:2222 Port: healthz 9090/TCP NodePort: healthz 31061/TCP Endpoints: 10.2.80.11:9090 ... The node ports shown above are high-numbered ports that are allocated on every Kubernetes worker node for use by the router service. The kube-proxy component on every Kubernetes node will listen on these ports and proxy traffic through to the corresponding port within an endpoint-- that is, a pod running the Deis router. If manually creating a load balancer, configure it to forward inbound traffic on ports 80, 443, and 2222 (port 9090 can be ignored) to the corresponding node ports on your Kubernetes worker nodes. Ports 80 and 443 may use either HTTP/S or TCP as protocols. Port 2222 must use TCP.","title":"Manually configuring a load balancer"},{"location":"managing-workflow/deploy-hooks/","text":"Deploy Hooks \u00b6 Deploy hooks allow an external service to receive a notification whenever a new version of your app is pushed to Workflow. It\u2019s useful to help keep the development team informed about deploys, while it can also be used to integrate different systems together. After one or more hooks are setup, hook output and errors appear in your application\u2019s logs: $ deis logs ... 2011-03-15T15:07:29-07:00 deis[api]: Deploy hook sent to http://deis.rocks Deploy hooks are a generic HTTP hook. An administrator can create and configure multiple deploy hooks by tuning the controller settings via the Helm chart. HTTP POST Hook \u00b6 The HTTP deploy hook performs an HTTP POST to a URL. The parameters included in the request are the same as the variables available in the hook message: app , release , release_summary , sha and user . See below for their descriptions: app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv Optionally, if a deploy hook secret key is added to the controller through tuning the controller settings , a new Authorization header will be present in the POST request. The value of this header is computed as the HMAC hex digest of the request URL, using the secret as the key. In order to authenticate that this request came from Workflow, use the secret key, the full URL and the HMAC-SHA1 hashing algorithm to compute the signature. In Python, that would look something like this: import hashlib import hmac hmac.new(\"my_secret_key\", \"http://deis.rocks?app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv\", digestmod=hashlib.sha1).hexdigest() If the value of the computed HMAC hex digest and the value in the Authorization header are identical, then the request came from Workflow. Important When computing the signature, ensure that the URL parameters are in alphabetic order. This is critical when computing the cryptographic signature as most web applications don't care about the order of the HTTP parameters, but the cryptographic signature will not be the same.","title":"Deploy Hooks"},{"location":"managing-workflow/deploy-hooks/#deploy-hooks","text":"Deploy hooks allow an external service to receive a notification whenever a new version of your app is pushed to Workflow. It\u2019s useful to help keep the development team informed about deploys, while it can also be used to integrate different systems together. After one or more hooks are setup, hook output and errors appear in your application\u2019s logs: $ deis logs ... 2011-03-15T15:07:29-07:00 deis[api]: Deploy hook sent to http://deis.rocks Deploy hooks are a generic HTTP hook. An administrator can create and configure multiple deploy hooks by tuning the controller settings via the Helm chart.","title":"Deploy Hooks"},{"location":"managing-workflow/deploy-hooks/#http-post-hook","text":"The HTTP deploy hook performs an HTTP POST to a URL. The parameters included in the request are the same as the variables available in the hook message: app , release , release_summary , sha and user . See below for their descriptions: app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv Optionally, if a deploy hook secret key is added to the controller through tuning the controller settings , a new Authorization header will be present in the POST request. The value of this header is computed as the HMAC hex digest of the request URL, using the secret as the key. In order to authenticate that this request came from Workflow, use the secret key, the full URL and the HMAC-SHA1 hashing algorithm to compute the signature. In Python, that would look something like this: import hashlib import hmac hmac.new(\"my_secret_key\", \"http://deis.rocks?app=secure-woodland&release=v4&release_summary=gabrtv%20deployed%35b3726&sha=35b3726&user=gabrtv\", digestmod=hashlib.sha1).hexdigest() If the value of the computed HMAC hex digest and the value in the Authorization header are identical, then the request came from Workflow. Important When computing the signature, ensure that the URL parameters are in alphabetic order. This is critical when computing the cryptographic signature as most web applications don't care about the order of the HTTP parameters, but the cryptographic signature will not be the same.","title":"HTTP POST Hook"},{"location":"managing-workflow/extending-workflow/","text":"Extending Workflow \u00b6 Deis Workflow is an open source project which wouldn't be here without the amazing skill and enthusiasm of the community that has grown up around it. Several projects have blossomed which extend Workflow in various ways. These links are to community-contributed extensions of Deis Workflow. Deis makes no guarantees about the functionality, security, or code contained within. As with any software, use with caution in a production environment. Workflow Community Projects \u00b6 alea is a backing services manager for Deis Workflow, providing easy access to PostgreSQL, Redis, MongoDB, and memcached. deisdash is a web-based UI supporting many user and app actions without need of the deis command-line interface. deis-cleanup is a Deis-friendly, configurable approach to purging unneeded Docker containers and images. deis-global-config-plugin stores config values in Vault for easy use in Workflow apps. deis-node is a controller API client for a browser in NodeJS. deis-ui is the beginning of a full client-side dashboard that interfaces with the controller API. deis-workflow-aws simplifies installing Workflow on Amazon Web Services , backed by S3 and using ECR as the container registry. deis-workflow-gke simplifies installing Workflow on Google Container Engine , backed by Google Cloud Storage and using gcr.io as the container registry. deis-workflow-ruby contains Workflow controller API bindings for Ruby programming. heroku-to-deis migrates existing Heroku applications to the Workflow platform. kube-solo-osx creates a zero-to-Kubernetes development environment for macOS in under two minutes, with specific support for installing Workflow with Helm or Helm Classic. Are we missing something? Please open a documentation pull request to add it.","title":"Extending Workflow"},{"location":"managing-workflow/extending-workflow/#extending-workflow","text":"Deis Workflow is an open source project which wouldn't be here without the amazing skill and enthusiasm of the community that has grown up around it. Several projects have blossomed which extend Workflow in various ways. These links are to community-contributed extensions of Deis Workflow. Deis makes no guarantees about the functionality, security, or code contained within. As with any software, use with caution in a production environment.","title":"Extending Workflow"},{"location":"managing-workflow/extending-workflow/#workflow-community-projects","text":"alea is a backing services manager for Deis Workflow, providing easy access to PostgreSQL, Redis, MongoDB, and memcached. deisdash is a web-based UI supporting many user and app actions without need of the deis command-line interface. deis-cleanup is a Deis-friendly, configurable approach to purging unneeded Docker containers and images. deis-global-config-plugin stores config values in Vault for easy use in Workflow apps. deis-node is a controller API client for a browser in NodeJS. deis-ui is the beginning of a full client-side dashboard that interfaces with the controller API. deis-workflow-aws simplifies installing Workflow on Amazon Web Services , backed by S3 and using ECR as the container registry. deis-workflow-gke simplifies installing Workflow on Google Container Engine , backed by Google Cloud Storage and using gcr.io as the container registry. deis-workflow-ruby contains Workflow controller API bindings for Ruby programming. heroku-to-deis migrates existing Heroku applications to the Workflow platform. kube-solo-osx creates a zero-to-Kubernetes development environment for macOS in under two minutes, with specific support for installing Workflow with Helm or Helm Classic. Are we missing something? Please open a documentation pull request to add it.","title":"Workflow Community Projects"},{"location":"managing-workflow/platform-logging/","text":"Platform Logging \u00b6 The logging platform is made up of 2 components - Fluentd and Logger . Fluentd runs on every worker node of the cluster and is deployed as a Daemon Set . The Fluentd pods capture all of the stderr and stdout streams of every container running on the host (even those not hosted directly by kubernetes). Once the log message arrives in our custom fluentd plugin we determine where the message originated. If the message was from the Workflow Controller or from an application deployed via workflow we send it to the logs topic on the local NSQD instance. If the message is from the Workflow Router we build an Influxdb compatible message and send it to the same NSQD instance but instead place the message on the metrics topic. Logger then acts as a consumer reading messages off of the NSQ logs topic storing those messages in a local Redis instance. When a user wants to retrieve log entries using the deis logs command we make an HTTP request from Controller to Logger which then fetches the appropriate data from Redis. Configuring Off Cluster Redis \u00b6 Even though we provide a redis instance with the default Workflow install, it is recommended that operators use a third-party source like Elasticache or similar offering. This way your data is durable across upgrades or outages. If you have a third-party Redis installation you would like to use all you need to do is set the following values in your helm chart: db = \"0\" host = \"my.host.redis\" port = \"6379\" password = \"\" These can be changed by running helm inspect values hephy/workflow > values.yaml before using helm install to complete the installation. To customize the redis credentials, edit values.yaml and modify the redis section of the file to tune these settings. Debugging Logger \u00b6 If the deis logs command encounters an error it will return the following message: Error: There are currently no log messages. Please check the following things: 1) Logger and fluentd pods are running. 2) The application is writing logs to the logger component by checking that an entry in the ring buffer was created: kubectl --namespace=deis logs <logger pod> 3) Making sure that the container logs were mounted properly into the fluentd pod: kubectl --namespace=deis exec <fluentd pod> ls /var/log/containers Architecture Diagram \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Default Configuration \u00b6 By default the Fluentd pod can be configured to talk to numerous syslog endpoints. So for example it is possible to have Fluentd send log messages to both the Logger component and Papertrail . This allows production deployments of Deis to satisfy stringent logging requirements such as offsite backups of log data. Configuring Fluentd to talk to multiple syslog endpoints means modifying the Fluentd daemonset manifest. This means you will need to fetch the chart with helm fetch hephy/workflow --untar , then modify workflow/charts/fluentd/templates/logger-fluentd-daemon.yaml with the following: env: - name: \"SYSLOG_HOST_1\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT_1\" value: \"5144\" .... - name: \"SYSLOG_HOST_N\" value: \"my.syslog.host.n\" - name: \"SYSLOG_PORT_N\" value: \"51333\" If you only need to talk to 1 Syslog endpoint you can use the following configuration within your chart: env: - name: \"SYSLOG_HOST\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT\" value: \"5144\" Then run helm install ./workflow --namespace deis to install the modified chart. Customizing: \u00b6 We currently support logging information to Syslog, Elastic Search, and Sumo Logic. However, we will gladly accept pull requests that add support to other locations. For more information please visit the fluentd repository . Custom Fluentd Plugins \u00b6 That are many output plugins available for Fluentd . But, we purposefully do not ship our Fluentd image with these installed. Instead, we provide a mechanism that allows users to install a plugin at startup time of the container and configure it. If you would like to install a plugin you can set an environment variable such as the following: FLUENTD_PLUGIN_N=some-fluentd-plugin where N is a positive integer that is incremented for every plugin you wish to install. After you set this value you must then set the configuration text for the FILTER or STORE plugin you are installing. You can do that by setting CUSTOM_STORE_N=configuration text where N is the corresponding index value of the plugin you just installed. Here is an example of setting the values directly in the manifest of the daemonset. env: - name: \"FLUENTD_PLUGIN_1\" value: \"fluent-plugin-kafka\" - name: \"CUSTOM_STORE_1\" value: | <store> @type kafka \\ default_topic some_topic </store> Or you could configure it using the daemon_environment key in the values.yaml : fluentd: daemon_environment: FLUENTD_PLUGIN_1: \"fluent-plugin-kafka\" CUSTOM_STORE_1: \"|\\n <store>\\n @type kafka\\n default_topic some_topic\\n </store>\" INSTALL_BUILD_TOOLS: \"|\\n true\" For more information please see the Custom Plugins section of the README.","title":"Platform Logging"},{"location":"managing-workflow/platform-logging/#platform-logging","text":"The logging platform is made up of 2 components - Fluentd and Logger . Fluentd runs on every worker node of the cluster and is deployed as a Daemon Set . The Fluentd pods capture all of the stderr and stdout streams of every container running on the host (even those not hosted directly by kubernetes). Once the log message arrives in our custom fluentd plugin we determine where the message originated. If the message was from the Workflow Controller or from an application deployed via workflow we send it to the logs topic on the local NSQD instance. If the message is from the Workflow Router we build an Influxdb compatible message and send it to the same NSQD instance but instead place the message on the metrics topic. Logger then acts as a consumer reading messages off of the NSQ logs topic storing those messages in a local Redis instance. When a user wants to retrieve log entries using the deis logs command we make an HTTP request from Controller to Logger which then fetches the appropriate data from Redis.","title":"Platform Logging"},{"location":"managing-workflow/platform-logging/#configuring-off-cluster-redis","text":"Even though we provide a redis instance with the default Workflow install, it is recommended that operators use a third-party source like Elasticache or similar offering. This way your data is durable across upgrades or outages. If you have a third-party Redis installation you would like to use all you need to do is set the following values in your helm chart: db = \"0\" host = \"my.host.redis\" port = \"6379\" password = \"\" These can be changed by running helm inspect values hephy/workflow > values.yaml before using helm install to complete the installation. To customize the redis credentials, edit values.yaml and modify the redis section of the file to tune these settings.","title":"Configuring Off Cluster Redis"},{"location":"managing-workflow/platform-logging/#debugging-logger","text":"If the deis logs command encounters an error it will return the following message: Error: There are currently no log messages. Please check the following things: 1) Logger and fluentd pods are running. 2) The application is writing logs to the logger component by checking that an entry in the ring buffer was created: kubectl --namespace=deis logs <logger pod> 3) Making sure that the container logs were mounted properly into the fluentd pod: kubectl --namespace=deis exec <fluentd pod> ls /var/log/containers","title":"Debugging Logger"},{"location":"managing-workflow/platform-logging/#architecture-diagram","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture Diagram"},{"location":"managing-workflow/platform-logging/#default-configuration","text":"By default the Fluentd pod can be configured to talk to numerous syslog endpoints. So for example it is possible to have Fluentd send log messages to both the Logger component and Papertrail . This allows production deployments of Deis to satisfy stringent logging requirements such as offsite backups of log data. Configuring Fluentd to talk to multiple syslog endpoints means modifying the Fluentd daemonset manifest. This means you will need to fetch the chart with helm fetch hephy/workflow --untar , then modify workflow/charts/fluentd/templates/logger-fluentd-daemon.yaml with the following: env: - name: \"SYSLOG_HOST_1\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT_1\" value: \"5144\" .... - name: \"SYSLOG_HOST_N\" value: \"my.syslog.host.n\" - name: \"SYSLOG_PORT_N\" value: \"51333\" If you only need to talk to 1 Syslog endpoint you can use the following configuration within your chart: env: - name: \"SYSLOG_HOST\" value: \"my.syslog.host\" - name: \"SYSLOG_PORT\" value: \"5144\" Then run helm install ./workflow --namespace deis to install the modified chart.","title":"Default Configuration"},{"location":"managing-workflow/platform-logging/#customizing","text":"We currently support logging information to Syslog, Elastic Search, and Sumo Logic. However, we will gladly accept pull requests that add support to other locations. For more information please visit the fluentd repository .","title":"Customizing:"},{"location":"managing-workflow/platform-logging/#custom-fluentd-plugins","text":"That are many output plugins available for Fluentd . But, we purposefully do not ship our Fluentd image with these installed. Instead, we provide a mechanism that allows users to install a plugin at startup time of the container and configure it. If you would like to install a plugin you can set an environment variable such as the following: FLUENTD_PLUGIN_N=some-fluentd-plugin where N is a positive integer that is incremented for every plugin you wish to install. After you set this value you must then set the configuration text for the FILTER or STORE plugin you are installing. You can do that by setting CUSTOM_STORE_N=configuration text where N is the corresponding index value of the plugin you just installed. Here is an example of setting the values directly in the manifest of the daemonset. env: - name: \"FLUENTD_PLUGIN_1\" value: \"fluent-plugin-kafka\" - name: \"CUSTOM_STORE_1\" value: | <store> @type kafka \\ default_topic some_topic </store> Or you could configure it using the daemon_environment key in the values.yaml : fluentd: daemon_environment: FLUENTD_PLUGIN_1: \"fluent-plugin-kafka\" CUSTOM_STORE_1: \"|\\n <store>\\n @type kafka\\n default_topic some_topic\\n </store>\" INSTALL_BUILD_TOOLS: \"|\\n true\" For more information please see the Custom Plugins section of the README.","title":"Custom Fluentd Plugins"},{"location":"managing-workflow/platform-monitoring/","text":"Platform Monitoring \u00b6 Description \u00b6 We now include a monitoring stack for introspection on a running Kubernetes cluster. The stack includes 3 components: Telegraf - Metrics collection daemon written by team behind InfluxDB. InfluxDB - Time series database Grafana - Graphing tool for time series data Architecture Diagram \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Grafana \u00b6 Grafana allows users to create custom dashboards that visualize the data captured to the running InfluxDB component. By default Grafana is exposed using a service annotation through the router at the following URL: http://grafana.mydomain.com . The default login is admin/admin . If you are interested in changing these values please see Tuning Component Settings . Grafana will preload several dashboards to help operators get started with monitoring Kubernetes and Deis Workflow. These dashboards are meant as starting points and don't include every item that might be desirable to monitor in a production installation. Deis Workflow monitoring by default does not write data to the host filesystem or to long-term storage. If the Grafana instance fails, modified dashboards are lost. Production Configuration \u00b6 A production install of Grafana should have the following configuration values changed if possible: Change the default username and password from admin/admin . The value for the password is passed in plain text so it is best to set this value on the command line instead of checking it into version control. Enable persistence Use a supported external database such as mysql or postgres. You can find more information here On Cluster Persistence \u00b6 Enabling persistence will allow your custom configuration to persist across pod restarts. This means that the default sqllite database (which stores things like sessions and user data) will not disappear if you upgrade the Workflow installation. If you wish to have persistence for Grafana you can set enabled to true in the values.yaml file before running helm install . grafana: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size Off Cluster Grafana \u00b6 If you wish to provide your own Grafana instance you can set grafana_location in the values.yaml file before running helm install . InfluxDB \u00b6 InfluxDB writes data to the host disk; however, if the InfluxDB pod dies and comes back on another host, the data will not be recovered. The InfluxDB Admin UI is also exposed through the router allowing users to access the query engine by going to influx.mydomain.com . You will need to configure where to find the influx-api endpoint by clicking the \"gear\" icon at the top right and changing the host to influxapi.mydomain.com and port to 80 . On Cluster Persistence \u00b6 If you wish to have persistence for InfluxDB you can set enabled to true in the values.yaml file before running helm install . influxdb: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size Off Cluster Influxdb \u00b6 To use off-cluster Influx, please provide the following values in the values.yaml file before running helm install . influxdb_location=off-cluster url = \"http://my-influxhost.com:8086\" database = \"metrics\" user = \"InfluxUser\" password = \"MysuperSecurePassword\" Telegraf \u00b6 Telegraf is the metrics collection daemon used within the monitoring stack. It will collect and send the following metrics to InfluxDB: System level metrics such as CPU, Load Average, Memory, Disk, and Network stats Container level metrics such as CPU and Memory Kubernetes metrics such as API request latency, Pod Startup Latency, and number of running pods It is possible to send these metrics to other endpoints besides InfluxDB. For more information please consult the following file Customizing the Monitoring Stack \u00b6 To learn more about customizing each of the above components please visit the Tuning Component Settings section.","title":"Platform Monitoring"},{"location":"managing-workflow/platform-monitoring/#platform-monitoring","text":"","title":"Platform Monitoring"},{"location":"managing-workflow/platform-monitoring/#description","text":"We now include a monitoring stack for introspection on a running Kubernetes cluster. The stack includes 3 components: Telegraf - Metrics collection daemon written by team behind InfluxDB. InfluxDB - Time series database Grafana - Graphing tool for time series data","title":"Description"},{"location":"managing-workflow/platform-monitoring/#architecture-diagram","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Router \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Logger \u2502\u25c0\u2500\u2500\u2500\u25b6\u2502Redis\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 Log file \u25b2 \u2502 \u2502 \u25bc \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 logs/metrics \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502App Logs\u2502\u2500\u2500Log File\u2500\u2500\u25b6\u2502 fluentd \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500topics\u2500\u2500\u2500\u2500\u2500\u25b6\u2502 NSQ \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 HOST \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502Telegraf\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 Telegraf \u2502\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u25b6\u2502 InfluxDB \u2502\u25c0\u2500\u2500\u2500\u2500Wire \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Protocol \u2502 \u25b2 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 HOST \u2502 \u2502 \u25bc \u2502 Telegraf \u2502\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 Grafana \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Architecture Diagram"},{"location":"managing-workflow/platform-monitoring/#grafana","text":"Grafana allows users to create custom dashboards that visualize the data captured to the running InfluxDB component. By default Grafana is exposed using a service annotation through the router at the following URL: http://grafana.mydomain.com . The default login is admin/admin . If you are interested in changing these values please see Tuning Component Settings . Grafana will preload several dashboards to help operators get started with monitoring Kubernetes and Deis Workflow. These dashboards are meant as starting points and don't include every item that might be desirable to monitor in a production installation. Deis Workflow monitoring by default does not write data to the host filesystem or to long-term storage. If the Grafana instance fails, modified dashboards are lost.","title":"Grafana"},{"location":"managing-workflow/platform-monitoring/#production-configuration","text":"A production install of Grafana should have the following configuration values changed if possible: Change the default username and password from admin/admin . The value for the password is passed in plain text so it is best to set this value on the command line instead of checking it into version control. Enable persistence Use a supported external database such as mysql or postgres. You can find more information here","title":"Production Configuration"},{"location":"managing-workflow/platform-monitoring/#on-cluster-persistence","text":"Enabling persistence will allow your custom configuration to persist across pod restarts. This means that the default sqllite database (which stores things like sessions and user data) will not disappear if you upgrade the Workflow installation. If you wish to have persistence for Grafana you can set enabled to true in the values.yaml file before running helm install . grafana: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size","title":"On Cluster Persistence"},{"location":"managing-workflow/platform-monitoring/#off-cluster-grafana","text":"If you wish to provide your own Grafana instance you can set grafana_location in the values.yaml file before running helm install .","title":"Off Cluster Grafana"},{"location":"managing-workflow/platform-monitoring/#influxdb","text":"InfluxDB writes data to the host disk; however, if the InfluxDB pod dies and comes back on another host, the data will not be recovered. The InfluxDB Admin UI is also exposed through the router allowing users to access the query engine by going to influx.mydomain.com . You will need to configure where to find the influx-api endpoint by clicking the \"gear\" icon at the top right and changing the host to influxapi.mydomain.com and port to 80 .","title":"InfluxDB"},{"location":"managing-workflow/platform-monitoring/#on-cluster-persistence_1","text":"If you wish to have persistence for InfluxDB you can set enabled to true in the values.yaml file before running helm install . influxdb: # Configure the following ONLY if you want persistence for on-cluster grafana # GCP PDs and EBS volumes are supported only persistence: enabled: true # Set to true to enable persistence size: 5Gi # PVC size","title":"On Cluster Persistence"},{"location":"managing-workflow/platform-monitoring/#off-cluster-influxdb","text":"To use off-cluster Influx, please provide the following values in the values.yaml file before running helm install . influxdb_location=off-cluster url = \"http://my-influxhost.com:8086\" database = \"metrics\" user = \"InfluxUser\" password = \"MysuperSecurePassword\"","title":"Off Cluster Influxdb"},{"location":"managing-workflow/platform-monitoring/#telegraf","text":"Telegraf is the metrics collection daemon used within the monitoring stack. It will collect and send the following metrics to InfluxDB: System level metrics such as CPU, Load Average, Memory, Disk, and Network stats Container level metrics such as CPU and Memory Kubernetes metrics such as API request latency, Pod Startup Latency, and number of running pods It is possible to send these metrics to other endpoints besides InfluxDB. For more information please consult the following file","title":"Telegraf"},{"location":"managing-workflow/platform-monitoring/#customizing-the-monitoring-stack","text":"To learn more about customizing each of the above components please visit the Tuning Component Settings section.","title":"Customizing the Monitoring Stack"},{"location":"managing-workflow/platform-ssl/","text":"Platform SSL \u00b6 SSL/TLS is the standard security technology for establishing an encrypted link between a web server and a browser. This link ensures that all data passed between the web server and browsers remain private and integral. To enable SSL for the Workflow API and all managed apps, you can add an SSL certificate to the Deis Workflow router. You must provide either an SSL certificate that was registered with a CA or your own self-signed SSL certificate . Note that the platform SSL certificate also functions as a default certificate for your apps that are deployed via Workflow. If you would like to attach a specific certificate to an application and domain see Application SSL Certificates . Installing SSL on the Deis Router \u00b6 To terminate SSL connections on the Deis Router use kubectl to create a new Secret at a known name. The Deis Workflow router will automatically detect this secret and reconfigure itself appropriately. The following criteria must be met: The name of the secret must be deis-router-platform-cert The certificate's public key must be supplied as the value of the tls.crt key The certificate's private key must be supplied as the value of the tls.key key Both the certificate and private key must be base64 encoded If your certificate has intermediate certs, append the intermediate signing certs to the bottom of the cert file before base64 encoding the combined certificates. Prepare your certificate and key files by encoding them in base64: $ cat certificate-file.crt -----BEGIN CERTIFICATE----- / * your SSL certificate here */ -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- /* any intermediate certificates */ -----END CERTIFICATE----- $ cat certificate-file.crt | base64 -e LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCi8gKiB5b3VyIFNTTCBjZXJ0aWZpY2F0ZSBoZXJlICovCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCi8qIGFueSBpbnRlcm1lZGlhdGUgY2VydGlmaWNhdGVzICovCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K $ cat certificate.key -----BEGIN RSA PRIVATE KEY----- /* your unencrypted private key here */ -----END RSA PRIVATE KEY----- $ cat certificate.key | base64 -e LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQovKiB5b3VyIHVuZW5jcnlwdGVkIHByaXZhdGUga2V5IGhlcmUgKi8KLS0tLS1FTkQgUlNBIFBSSVZBVEUgS0VZLS0tLS0K Open your favorite text editor and create the Kubernetes manifest: $ $EDITOR deis-router-platform-cert.yaml The format of the Secret manifest should match the below example. Make sure you paste the appropriate values for cert and key from the above examples: $ cat deis-router-platform-cert.yaml apiVersion: v1 kind: Secret metadata: name: deis-router-platform-cert namespace: deis type: Opaque data: tls.crt: LS0...tCg== tls.key: LS0...LQo= Once you've created the deis-router-platform-cert.yaml file, you can install the manifest with kubectl create -f deis-router-platform-cert.yaml . The Deis Workflow router will automatically notice the new secret and update its configuration on-the-fly. Installing SSL on a Load Balancer \u00b6 Most cloud-based load balancers also support SSL termination in addition to passing traffic through to Deis Router. Any communication inbound to the load balancer will be encrypted while the internal components of Deis Workflow will still communicate over HTTP. This offloads SSL processing to the cloud load balancer but also means that any application-specific SSL certificates must also be configured on the cloud load balancer. To terminate SSL on the cloud load balancer you will need to modify the load balancer's listener settings: Swap the load balancer protocol on port 443 to use HTTPS instead of TCP Swap the backend protocol to use HTTP instead of TCP Change the destination backend port to match the port configured for HTTP, usually port 80 Install the certificate on the listener associated with port 443 See your vendor's specific instructions on installing SSL on your load balancer. For AWS, see their documentation on installing an SSL cert for load balancing .","title":"Platform SSL"},{"location":"managing-workflow/platform-ssl/#platform-ssl","text":"SSL/TLS is the standard security technology for establishing an encrypted link between a web server and a browser. This link ensures that all data passed between the web server and browsers remain private and integral. To enable SSL for the Workflow API and all managed apps, you can add an SSL certificate to the Deis Workflow router. You must provide either an SSL certificate that was registered with a CA or your own self-signed SSL certificate . Note that the platform SSL certificate also functions as a default certificate for your apps that are deployed via Workflow. If you would like to attach a specific certificate to an application and domain see Application SSL Certificates .","title":"Platform SSL"},{"location":"managing-workflow/platform-ssl/#installing-ssl-on-the-deis-router","text":"To terminate SSL connections on the Deis Router use kubectl to create a new Secret at a known name. The Deis Workflow router will automatically detect this secret and reconfigure itself appropriately. The following criteria must be met: The name of the secret must be deis-router-platform-cert The certificate's public key must be supplied as the value of the tls.crt key The certificate's private key must be supplied as the value of the tls.key key Both the certificate and private key must be base64 encoded If your certificate has intermediate certs, append the intermediate signing certs to the bottom of the cert file before base64 encoding the combined certificates. Prepare your certificate and key files by encoding them in base64: $ cat certificate-file.crt -----BEGIN CERTIFICATE----- / * your SSL certificate here */ -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- /* any intermediate certificates */ -----END CERTIFICATE----- $ cat certificate-file.crt | base64 -e LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCi8gKiB5b3VyIFNTTCBjZXJ0aWZpY2F0ZSBoZXJlICovCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCi8qIGFueSBpbnRlcm1lZGlhdGUgY2VydGlmaWNhdGVzICovCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K $ cat certificate.key -----BEGIN RSA PRIVATE KEY----- /* your unencrypted private key here */ -----END RSA PRIVATE KEY----- $ cat certificate.key | base64 -e LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQovKiB5b3VyIHVuZW5jcnlwdGVkIHByaXZhdGUga2V5IGhlcmUgKi8KLS0tLS1FTkQgUlNBIFBSSVZBVEUgS0VZLS0tLS0K Open your favorite text editor and create the Kubernetes manifest: $ $EDITOR deis-router-platform-cert.yaml The format of the Secret manifest should match the below example. Make sure you paste the appropriate values for cert and key from the above examples: $ cat deis-router-platform-cert.yaml apiVersion: v1 kind: Secret metadata: name: deis-router-platform-cert namespace: deis type: Opaque data: tls.crt: LS0...tCg== tls.key: LS0...LQo= Once you've created the deis-router-platform-cert.yaml file, you can install the manifest with kubectl create -f deis-router-platform-cert.yaml . The Deis Workflow router will automatically notice the new secret and update its configuration on-the-fly.","title":"Installing SSL on the Deis Router"},{"location":"managing-workflow/platform-ssl/#installing-ssl-on-a-load-balancer","text":"Most cloud-based load balancers also support SSL termination in addition to passing traffic through to Deis Router. Any communication inbound to the load balancer will be encrypted while the internal components of Deis Workflow will still communicate over HTTP. This offloads SSL processing to the cloud load balancer but also means that any application-specific SSL certificates must also be configured on the cloud load balancer. To terminate SSL on the cloud load balancer you will need to modify the load balancer's listener settings: Swap the load balancer protocol on port 443 to use HTTPS instead of TCP Swap the backend protocol to use HTTP instead of TCP Change the destination backend port to match the port configured for HTTP, usually port 80 Install the certificate on the listener associated with port 443 See your vendor's specific instructions on installing SSL on your load balancer. For AWS, see their documentation on installing an SSL cert for load balancing .","title":"Installing SSL on a Load Balancer"},{"location":"managing-workflow/production-deployments/","text":"Production Deployments \u00b6 When readying a Workflow deployment for production workloads, there are some additional recommendations. Running Workflow without Minio \u00b6 Workflow makes use of Minio to provide storage for the Registry , Database , and Logger components. Minio is provided out of the box as a central storage compartment, but it is not resilient to cluster outages. If Minio is shut down, all data is lost. In production, persistent storage can be achieved by running an external object store. For users on AWS, GCE/GKE or Azure, the convenience of Amazon S3, Google GCS or Microsoft Azure Storage makes the prospect of running a Minio-less Workflow cluster quite reasonable. For users who have restriction on using external object storage using swift object storage can be an option. Running a Workflow cluster without Minio provides several advantages: Removal of state from the worker nodes Reduced resource usage Reduced complexity and operational burden of managing Workflow See Configuring Object Storage for details on removing this operational complexity. Review Security Considerations \u00b6 There are some additional security-related considerations when running Workflow in production. See Security Considerations for details. Registration is Admin-Only \u00b6 By default, registration with the Workflow controller is in \"admin_only\" mode. The first user to run a deis register command becomes the initial \"admin\" user, and registrations after that are disallowed unless requested by an admin. Please see the following documentation to learn about changing registration mode: Customizing Controller Disable Grafana Signups \u00b6 It is also recommended to disable signups for the Grafana dashboards. Please see the following documentation to learn about disabling Grafana signups: Customizing Monitor Enable TLS \u00b6 Using TLS to encrypt traffic (including Workflow client traffic, such as login credentials) is crucial. See Platform SSL for the platform. Scale Routers \u00b6 If all router pods in your cluster become unavailable then you will be unable to access the workflow API or any deployed applications. To reduce the potential of this happening it is recommended that you scale the deis-router Deployment to run more than one router pod. This can be accomplished by running kubectl --namespace=deis scale --replicas=2 deployment/deis-router Using on-cluster registry with CNI \u00b6 If you are using CNI for managing container network, you cannot use hostPort notation due to this issue . In this case you could enable CNI for deis-registry-proxy by setting use_cni variable to true inside values.yaml or by adding --set global.use_cni=true to helm 's args. Running Workflow with RBAC \u00b6 If your cluster has RBAC amongst your authorization modes ( $ kubectl api-versions should contains rbac.authorization.k8s.io ) it may be necessary to enable RBAC in Workflow. This can be achieved by setting use_rbac in the global section of values.yaml to true , or by adding --set=global.use_rbac=true to the $ helm install/upgrade command. RBAC support was announced in Kubernetes-1.5 and is enabled by default if: - your Kubernetes cluster is in GKE - your Kubernetes cluster built with kubeadm Note : helm may need to be given specific permissions under RBAC if not already done. Attention : Azure ACS Kubernetes clusters are not RBAC-enabled for today due to lack in authentication strategy. Feel free to watch this PR for more details.","title":"Production Deployments"},{"location":"managing-workflow/production-deployments/#production-deployments","text":"When readying a Workflow deployment for production workloads, there are some additional recommendations.","title":"Production Deployments"},{"location":"managing-workflow/production-deployments/#running-workflow-without-minio","text":"Workflow makes use of Minio to provide storage for the Registry , Database , and Logger components. Minio is provided out of the box as a central storage compartment, but it is not resilient to cluster outages. If Minio is shut down, all data is lost. In production, persistent storage can be achieved by running an external object store. For users on AWS, GCE/GKE or Azure, the convenience of Amazon S3, Google GCS or Microsoft Azure Storage makes the prospect of running a Minio-less Workflow cluster quite reasonable. For users who have restriction on using external object storage using swift object storage can be an option. Running a Workflow cluster without Minio provides several advantages: Removal of state from the worker nodes Reduced resource usage Reduced complexity and operational burden of managing Workflow See Configuring Object Storage for details on removing this operational complexity.","title":"Running Workflow without Minio"},{"location":"managing-workflow/production-deployments/#review-security-considerations","text":"There are some additional security-related considerations when running Workflow in production. See Security Considerations for details.","title":"Review Security Considerations"},{"location":"managing-workflow/production-deployments/#registration-is-admin-only","text":"By default, registration with the Workflow controller is in \"admin_only\" mode. The first user to run a deis register command becomes the initial \"admin\" user, and registrations after that are disallowed unless requested by an admin. Please see the following documentation to learn about changing registration mode: Customizing Controller","title":"Registration is Admin-Only"},{"location":"managing-workflow/production-deployments/#disable-grafana-signups","text":"It is also recommended to disable signups for the Grafana dashboards. Please see the following documentation to learn about disabling Grafana signups: Customizing Monitor","title":"Disable Grafana Signups"},{"location":"managing-workflow/production-deployments/#enable-tls","text":"Using TLS to encrypt traffic (including Workflow client traffic, such as login credentials) is crucial. See Platform SSL for the platform.","title":"Enable TLS"},{"location":"managing-workflow/production-deployments/#scale-routers","text":"If all router pods in your cluster become unavailable then you will be unable to access the workflow API or any deployed applications. To reduce the potential of this happening it is recommended that you scale the deis-router Deployment to run more than one router pod. This can be accomplished by running kubectl --namespace=deis scale --replicas=2 deployment/deis-router","title":"Scale Routers"},{"location":"managing-workflow/production-deployments/#using-on-cluster-registry-with-cni","text":"If you are using CNI for managing container network, you cannot use hostPort notation due to this issue . In this case you could enable CNI for deis-registry-proxy by setting use_cni variable to true inside values.yaml or by adding --set global.use_cni=true to helm 's args.","title":"Using on-cluster registry with CNI"},{"location":"managing-workflow/production-deployments/#running-workflow-with-rbac","text":"If your cluster has RBAC amongst your authorization modes ( $ kubectl api-versions should contains rbac.authorization.k8s.io ) it may be necessary to enable RBAC in Workflow. This can be achieved by setting use_rbac in the global section of values.yaml to true , or by adding --set=global.use_rbac=true to the $ helm install/upgrade command. RBAC support was announced in Kubernetes-1.5 and is enabled by default if: - your Kubernetes cluster is in GKE - your Kubernetes cluster built with kubeadm Note : helm may need to be given specific permissions under RBAC if not already done. Attention : Azure ACS Kubernetes clusters are not RBAC-enabled for today due to lack in authentication strategy. Feel free to watch this PR for more details.","title":"Running Workflow with RBAC"},{"location":"managing-workflow/security-considerations/","text":"Security Considerations \u00b6 Important Workflow is not suitable for multi-tenant environments or hosting untrusted code. A major goal of Workflow is to be operationally secure and trusted by operations engineers in every deployed environment. There are, however, two notable security-related considerations to be aware of when deploying Workflow. Application Runtime Segregation \u00b6 Users of Workflow often want to deploy their applications to separate environments. Typically, physical network isolation isn\u2019t the goal, but rather segregation of application environments - if a region goes haywire, it shouldn\u2019t affect applications that are running in a separate region. In Workflow, deployed applications can be segregated by using the deis tags command. This enables you to tag machines in your cluster with arbitrary metadata, then configure your applications to be scheduled to machines which match the metadata. For example, if some machines in your cluster are tagged with region=us-west-1 and some with region=us-east-1 , you can configure an application to be deployed to us-west-1 by using deis tags set region=us-west-1 . Workflow will pass this configuration along to Kubernetes, which will schedule your application in different regions. See Isolate the Application for more information. Running Workflow on Public Clouds \u00b6 If you are running on a public cloud without security group features, you will have to set up security groups yourself through either iptables or a similar tool. The only ports on worker nodes that should be exposed to the public are: 22: (optional) for remote SSH 80: for the routers 443: (optional) routers w/ SSL enabled 2222: for the routers proxying TCP to the builder 9090: for the routers' health check IP Whitelist \u00b6 Enforcing a cluster-wide IP whitelist may be advisable for routers governing ingress to a cluster that hosts applications intended for a limited audience-- e.g. applications for internal use within an organization. You can enforce cluster-wide IP whitelisting by enabling whitelists, then attaching an annotation to the router: $ kubectl --namespace=deis annotate deployments/deis-router router.deis.io/nginx.enforceWhitelists=true $ kubectl --namespace=deis annotate deployments/deis-router router.deis.io/nginx.defaultWhitelist=\"0.0.0.0/0\" The format is the same for the controller whitelist but you need to specify the whitelist directly to the controller's service. For example: $ kubectl --namespace=deis annotate service deis-controller router.deis.io/whitelist=\"10.0.1.0/24,121.212.121.212\" And the same applies to applications. For example, to apply a whitelist to an application named example : $ kubectl --namespace=example annotate service example-web router.deis.io/whitelist=\"10.0.1.0/24,121.212.121.212\" Application level whitelisting can also be done using the Deis client. To add/remove/list addresses of an application whitelist, use deis whitelist : $ deis whitelist:add 10.0.1.0/24,121.212.121.212 -a drafty-zaniness Adding 10.0.1.0/24,121.212.121.212 to drafty-zaniness whitelist...done $ deis whitelist:remove 121.212.121.212 -a drafty-zaniness Removing 121.212.121.212 from drafty-zaniness whitelist... done $ deis whitelist -a drafty-zaniness === drafty-zaniness Whitelisted Addresses 10.0.1.0/24","title":"Security Considerations"},{"location":"managing-workflow/security-considerations/#security-considerations","text":"Important Workflow is not suitable for multi-tenant environments or hosting untrusted code. A major goal of Workflow is to be operationally secure and trusted by operations engineers in every deployed environment. There are, however, two notable security-related considerations to be aware of when deploying Workflow.","title":"Security Considerations"},{"location":"managing-workflow/security-considerations/#application-runtime-segregation","text":"Users of Workflow often want to deploy their applications to separate environments. Typically, physical network isolation isn\u2019t the goal, but rather segregation of application environments - if a region goes haywire, it shouldn\u2019t affect applications that are running in a separate region. In Workflow, deployed applications can be segregated by using the deis tags command. This enables you to tag machines in your cluster with arbitrary metadata, then configure your applications to be scheduled to machines which match the metadata. For example, if some machines in your cluster are tagged with region=us-west-1 and some with region=us-east-1 , you can configure an application to be deployed to us-west-1 by using deis tags set region=us-west-1 . Workflow will pass this configuration along to Kubernetes, which will schedule your application in different regions. See Isolate the Application for more information.","title":"Application Runtime Segregation"},{"location":"managing-workflow/security-considerations/#running-workflow-on-public-clouds","text":"If you are running on a public cloud without security group features, you will have to set up security groups yourself through either iptables or a similar tool. The only ports on worker nodes that should be exposed to the public are: 22: (optional) for remote SSH 80: for the routers 443: (optional) routers w/ SSL enabled 2222: for the routers proxying TCP to the builder 9090: for the routers' health check","title":"Running Workflow on Public Clouds"},{"location":"managing-workflow/security-considerations/#ip-whitelist","text":"Enforcing a cluster-wide IP whitelist may be advisable for routers governing ingress to a cluster that hosts applications intended for a limited audience-- e.g. applications for internal use within an organization. You can enforce cluster-wide IP whitelisting by enabling whitelists, then attaching an annotation to the router: $ kubectl --namespace=deis annotate deployments/deis-router router.deis.io/nginx.enforceWhitelists=true $ kubectl --namespace=deis annotate deployments/deis-router router.deis.io/nginx.defaultWhitelist=\"0.0.0.0/0\" The format is the same for the controller whitelist but you need to specify the whitelist directly to the controller's service. For example: $ kubectl --namespace=deis annotate service deis-controller router.deis.io/whitelist=\"10.0.1.0/24,121.212.121.212\" And the same applies to applications. For example, to apply a whitelist to an application named example : $ kubectl --namespace=example annotate service example-web router.deis.io/whitelist=\"10.0.1.0/24,121.212.121.212\" Application level whitelisting can also be done using the Deis client. To add/remove/list addresses of an application whitelist, use deis whitelist : $ deis whitelist:add 10.0.1.0/24,121.212.121.212 -a drafty-zaniness Adding 10.0.1.0/24,121.212.121.212 to drafty-zaniness whitelist...done $ deis whitelist:remove 121.212.121.212 -a drafty-zaniness Removing 121.212.121.212 from drafty-zaniness whitelist... done $ deis whitelist -a drafty-zaniness === drafty-zaniness Whitelisted Addresses 10.0.1.0/24","title":"IP Whitelist"},{"location":"managing-workflow/tuning-component-settings/","text":"Tuning Component Settings \u00b6 Helm Charts are a set of Kubernetes manifests that reflect best practices for deploying an application or service on Kubernetes. After you add the Deis Chart Repository, you can customize the chart using helm inspect values hephy/workflow > values.yaml before using helm install to complete the installation. There are a few ways to customize the respective component: If the value is exposed in the values.yaml file as derived above, one may modify the section of the component to tune these settings. The modified value(s) will then take effect at chart installation or release upgrade time via either of the two respective commands: $ helm install hephy/workflow -n hephy --namespace deis -f values.yaml $ helm upgrade hephy -f values.yaml If the value hasn't yet been exposed in the values.yaml file, one may edit the component deployment with the tuned setting. Here we edit the deis-controller deployment: $ kubectl --namespace deis edit deployment deis-controller Add/edit the setting via the appropriate environment variable and value under the env section and save. The updated deployment will recreate the component pod with the new/modified setting. Lastly, one may also fetch and edit the chart as served by version control/the chart repository itself: $ helm fetch hephy/workflow --untar $ $EDITOR workflow/charts/controller/templates/controller-deployment.yaml Then run helm install ./workflow --namespace deis --name hephy to apply the changes, or helm upgrade hephy ./workflow if the cluster is already running. Setting Resource limits \u00b6 You can set resource limits to Workflow components by modifying the values.yaml file fetched earlier. This file has a section for each Workflow component. To set a limit to any Workflow component just add limits_cpu , limits_memory in the section and set them to the appropriate values. Below is an example of how the builder section of values.yaml might look with CPU and memory limits set: builder: org: \"hephyci\" pullPolicy: \"Always\" dockerTag: \"canary\" limits_cpu: \"100m\" limits_memory: \"50Mi\" Customizing the Builder \u00b6 The following environment variables are tunable for the Builder component: Setting Description DEBUG Enable debug log output (default: false) BUILDER_POD_NODE_SELECTOR A node selector setting for builder job. As it may sometimes consume a lot of node resources, one may want a given builder job to run in a specific node only, so it won't affect critical nodes. for example pool:testing,disk:magnetic Customizing the Controller \u00b6 The following environment variables are tunable for the Controller component: Setting Description REGISTRATION_MODE set registration to \"enabled\", \"disabled\", or \"admin_only\" (default: \"admin_only\") GUNICORN_WORKERS number of gunicorn workers spawned to process requests (default: CPU cores * 4 + 1) RESERVED_NAMES a comma-separated list of names which applications cannot reserve for routing (default: \"deis, deis-builder, deis-workflow-manager\") SLUGRUNNER_IMAGE_NAME the image used to run buildpack application slugs (default: \"quay.io/hephyci/slugrunner:canary\") DEIS_DEPLOY_HOOK_URLS a comma-separated list of URLs to send deploy hooks to. DEIS_DEPLOY_HOOK_SECRET_KEY a private key used to compute the HMAC signature for deploy hooks. DEIS_DEPLOY_REJECT_IF_PROCFILE_MISSING rejects a deploy if the previous build had a Procfile but the current deploy is missing it. A 409 is thrown in the API. Prevents accidental process types removal. (default: \"false\", allowed values: \"true\", \"false\") DEIS_DEPLOY_PROCFILE_MISSING_REMOVE when turned on (default) any missing process type in a Procfile compared to the previous deploy is removed. When set to false will allow an empty Procfile to go through without removing missing process types, note that new images, configs and so on will get updated on all proc types. (default: \"true\", allowed values: \"true\", \"false\") DEIS_DEFAULT_CONFIG_TAGS set tags for all applications by default, for example: '{\"role\": \"worker\"}'. (default: '') KUBERNETES_NAMESPACE_DEFAULT_QUOTA_SPEC set resource quota to application namespace by setting ResourceQuota spec, for example: {\"spec\":{\"hard\":{\"pods\":\"10\"}}} , restrict app owner to spawn more then 10 pods (default: \"\", no quota will be applied to namespace) LDAP authentication settings \u00b6 Configuration options for LDAP authentication are detailed here . The following environment variables are available for enabling LDAP authentication of user accounts in the Controller component: Setting Description LDAP_ENDPOINT The URI of the LDAP server. If not specified, LDAP authentication is not enabled (default: \"\", example: ldap://hostname ). LDAP_BIND_DN The distinguished name to use when binding to the LDAP server (default: \"\") LDAP_BIND_PASSWORD The password to use with LDAP_BIND_DN (default: \"\") LDAP_USER_BASEDN The distinguished name of the search base for user names (default: \"\") LDAP_USER_FILTER The name of the login field in the users search base (default: \"username\") LDAP_GROUP_BASEDN The distinguished name of the search base for user's groups names (default: \"\") LDAP_GROUP_FILTER The filter for user's groups (default: \"\", example: objectClass=person ) Global and per application settings \u00b6 Setting Description DEIS_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DEIS_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes image pull policy for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) See the Deploying Apps guide for more detailed information on those. Customizing the Database \u00b6 The following environment variables are tunable for the Database component: Setting Description BACKUP_FREQUENCY how often the database should perform a base backup (default: \"12h\") BACKUPS_TO_RETAIN number of base backups the backing store should retain (default: 5) Customizing Fluentd \u00b6 The following values can be changed in the values.yaml file or by using the --set flag with the Helm CLI. Key Default Description syslog.host \"\" Host value of a syslog endpoint syslog.port \"\" Port value of a syslog endpoint sources.start_script false Capture kubernetes start script logs sources.docker false Capture docker daemon logs sources.etcd false Capture etcd logs sources.kubelet false Capture kubelet logs sources.kube_api false Capture Kubernetes API logs sources.controller false Capture Kubernetes Controller logs sources.scheduler false Capture Kubernetes Scheduler logs output.disable_deis false Disable the Deis output plugin boot.install_build_tools false Install the build tools package. This is useful when using custom plugins daemon_environment Takes key-value pairs and turns them into environment variables. For more information about the various environment variables that can be set please see the README Customizing the Logger \u00b6 The following environment variables are tunable for the Logger component: Setting Description STORAGE_ADAPTER How to store logs that are sent to the logger. Legal values are \"file\", \"memory\", and \"redis\". (default: \"redis\") NUMBER_OF_LINES How many lines to store in the ring buffer (default: 1000) Customizing the Monitor \u00b6 Grafana \u00b6 We have exposed some of the more useful configuration values directly in the chart. This allows them to be set using either the values.yaml file or by using the --set flag with the Helm CLI. You can see these options below: Setting | Default Value | Description ----------------- | -------------- |------------ | user | \"admin\" | The first user created in the database (this user has admin privileges) password | \"admin\" | Password for the first user. allow_sign_up | \"true\" | Allows users to sign up for an account. For a list of other options you can set by using environment variables please see the configuration file in Github. Telegraf \u00b6 For a list of configuration values that can be set by using environment variables please see the following configuration file . InfluxDB \u00b6 You can find a list of values that can be set using environment variables here . Customizing the Registry \u00b6 The Registry component can be tuned by following the teamhephy/distribution config doc . Customizing the Router \u00b6 The majority of router settings are tunable through annotations, which allows the router to be re-configured with zero downtime post-installation. You can find the list of annotations to tune here . The following environment variables are tunable for the Router component: Setting Description POD_NAMESPACE The pod namespace the router resides in. This is set by the Kubernetes downward API . Customizing Workflow Manager \u00b6 The following environment variables are tunable for Workflow Manager : Setting Description CHECK_VERSIONS Enables the external version check at https://versions.teamhephy.info/ (default: \"true\") POLL_INTERVAL_SEC The interval when Workflow Manager performs a version check, in seconds (default: 43200, or 12 hours) VERSIONS_API_URL The versions API URL (default: \" https://versions-staging.teamhephy.info \") DOCTOR_API_URL The doctor API URL (default: \" https://doctor-staging.teamhephy.info \") API_VERSION The version number Workflow Manager sends to the versions API (default: \"v2\")","title":"Tuning Component Settings"},{"location":"managing-workflow/tuning-component-settings/#tuning-component-settings","text":"Helm Charts are a set of Kubernetes manifests that reflect best practices for deploying an application or service on Kubernetes. After you add the Deis Chart Repository, you can customize the chart using helm inspect values hephy/workflow > values.yaml before using helm install to complete the installation. There are a few ways to customize the respective component: If the value is exposed in the values.yaml file as derived above, one may modify the section of the component to tune these settings. The modified value(s) will then take effect at chart installation or release upgrade time via either of the two respective commands: $ helm install hephy/workflow -n hephy --namespace deis -f values.yaml $ helm upgrade hephy -f values.yaml If the value hasn't yet been exposed in the values.yaml file, one may edit the component deployment with the tuned setting. Here we edit the deis-controller deployment: $ kubectl --namespace deis edit deployment deis-controller Add/edit the setting via the appropriate environment variable and value under the env section and save. The updated deployment will recreate the component pod with the new/modified setting. Lastly, one may also fetch and edit the chart as served by version control/the chart repository itself: $ helm fetch hephy/workflow --untar $ $EDITOR workflow/charts/controller/templates/controller-deployment.yaml Then run helm install ./workflow --namespace deis --name hephy to apply the changes, or helm upgrade hephy ./workflow if the cluster is already running.","title":"Tuning Component Settings"},{"location":"managing-workflow/tuning-component-settings/#setting-resource-limits","text":"You can set resource limits to Workflow components by modifying the values.yaml file fetched earlier. This file has a section for each Workflow component. To set a limit to any Workflow component just add limits_cpu , limits_memory in the section and set them to the appropriate values. Below is an example of how the builder section of values.yaml might look with CPU and memory limits set: builder: org: \"hephyci\" pullPolicy: \"Always\" dockerTag: \"canary\" limits_cpu: \"100m\" limits_memory: \"50Mi\"","title":"Setting Resource limits"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-builder","text":"The following environment variables are tunable for the Builder component: Setting Description DEBUG Enable debug log output (default: false) BUILDER_POD_NODE_SELECTOR A node selector setting for builder job. As it may sometimes consume a lot of node resources, one may want a given builder job to run in a specific node only, so it won't affect critical nodes. for example pool:testing,disk:magnetic","title":"Customizing the Builder"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-controller","text":"The following environment variables are tunable for the Controller component: Setting Description REGISTRATION_MODE set registration to \"enabled\", \"disabled\", or \"admin_only\" (default: \"admin_only\") GUNICORN_WORKERS number of gunicorn workers spawned to process requests (default: CPU cores * 4 + 1) RESERVED_NAMES a comma-separated list of names which applications cannot reserve for routing (default: \"deis, deis-builder, deis-workflow-manager\") SLUGRUNNER_IMAGE_NAME the image used to run buildpack application slugs (default: \"quay.io/hephyci/slugrunner:canary\") DEIS_DEPLOY_HOOK_URLS a comma-separated list of URLs to send deploy hooks to. DEIS_DEPLOY_HOOK_SECRET_KEY a private key used to compute the HMAC signature for deploy hooks. DEIS_DEPLOY_REJECT_IF_PROCFILE_MISSING rejects a deploy if the previous build had a Procfile but the current deploy is missing it. A 409 is thrown in the API. Prevents accidental process types removal. (default: \"false\", allowed values: \"true\", \"false\") DEIS_DEPLOY_PROCFILE_MISSING_REMOVE when turned on (default) any missing process type in a Procfile compared to the previous deploy is removed. When set to false will allow an empty Procfile to go through without removing missing process types, note that new images, configs and so on will get updated on all proc types. (default: \"true\", allowed values: \"true\", \"false\") DEIS_DEFAULT_CONFIG_TAGS set tags for all applications by default, for example: '{\"role\": \"worker\"}'. (default: '') KUBERNETES_NAMESPACE_DEFAULT_QUOTA_SPEC set resource quota to application namespace by setting ResourceQuota spec, for example: {\"spec\":{\"hard\":{\"pods\":\"10\"}}} , restrict app owner to spawn more then 10 pods (default: \"\", no quota will be applied to namespace)","title":"Customizing the Controller"},{"location":"managing-workflow/tuning-component-settings/#ldap-authentication-settings","text":"Configuration options for LDAP authentication are detailed here . The following environment variables are available for enabling LDAP authentication of user accounts in the Controller component: Setting Description LDAP_ENDPOINT The URI of the LDAP server. If not specified, LDAP authentication is not enabled (default: \"\", example: ldap://hostname ). LDAP_BIND_DN The distinguished name to use when binding to the LDAP server (default: \"\") LDAP_BIND_PASSWORD The password to use with LDAP_BIND_DN (default: \"\") LDAP_USER_BASEDN The distinguished name of the search base for user names (default: \"\") LDAP_USER_FILTER The name of the login field in the users search base (default: \"username\") LDAP_GROUP_BASEDN The distinguished name of the search base for user's groups names (default: \"\") LDAP_GROUP_FILTER The filter for user's groups (default: \"\", example: objectClass=person )","title":"LDAP authentication settings"},{"location":"managing-workflow/tuning-component-settings/#global-and-per-application-settings","text":"Setting Description DEIS_DEPLOY_BATCHES the number of pods to bring up and take down sequentially during a scale (default: number of available nodes) DEIS_DEPLOY_TIMEOUT deploy timeout in seconds per deploy batch (default: 120) IMAGE_PULL_POLICY the kubernetes image pull policy for application images (default: \"IfNotPresent\") (allowed values: \"Always\", \"IfNotPresent\") KUBERNETES_DEPLOYMENTS_REVISION_HISTORY_LIMIT how many revisions Kubernetes keeps around of a given Deployment (default: all revisions) KUBERNETES_POD_TERMINATION_GRACE_PERIOD_SECONDS how many seconds kubernetes waits for a pod to finish work after a SIGTERM before sending SIGKILL (default: 30) See the Deploying Apps guide for more detailed information on those.","title":"Global and per application settings"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-database","text":"The following environment variables are tunable for the Database component: Setting Description BACKUP_FREQUENCY how often the database should perform a base backup (default: \"12h\") BACKUPS_TO_RETAIN number of base backups the backing store should retain (default: 5)","title":"Customizing the Database"},{"location":"managing-workflow/tuning-component-settings/#customizing-fluentd","text":"The following values can be changed in the values.yaml file or by using the --set flag with the Helm CLI. Key Default Description syslog.host \"\" Host value of a syslog endpoint syslog.port \"\" Port value of a syslog endpoint sources.start_script false Capture kubernetes start script logs sources.docker false Capture docker daemon logs sources.etcd false Capture etcd logs sources.kubelet false Capture kubelet logs sources.kube_api false Capture Kubernetes API logs sources.controller false Capture Kubernetes Controller logs sources.scheduler false Capture Kubernetes Scheduler logs output.disable_deis false Disable the Deis output plugin boot.install_build_tools false Install the build tools package. This is useful when using custom plugins daemon_environment Takes key-value pairs and turns them into environment variables. For more information about the various environment variables that can be set please see the README","title":"Customizing Fluentd"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-logger","text":"The following environment variables are tunable for the Logger component: Setting Description STORAGE_ADAPTER How to store logs that are sent to the logger. Legal values are \"file\", \"memory\", and \"redis\". (default: \"redis\") NUMBER_OF_LINES How many lines to store in the ring buffer (default: 1000)","title":"Customizing the Logger"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-monitor","text":"","title":"Customizing the Monitor"},{"location":"managing-workflow/tuning-component-settings/#grafana","text":"We have exposed some of the more useful configuration values directly in the chart. This allows them to be set using either the values.yaml file or by using the --set flag with the Helm CLI. You can see these options below: Setting | Default Value | Description ----------------- | -------------- |------------ | user | \"admin\" | The first user created in the database (this user has admin privileges) password | \"admin\" | Password for the first user. allow_sign_up | \"true\" | Allows users to sign up for an account. For a list of other options you can set by using environment variables please see the configuration file in Github.","title":"Grafana"},{"location":"managing-workflow/tuning-component-settings/#telegraf","text":"For a list of configuration values that can be set by using environment variables please see the following configuration file .","title":"Telegraf"},{"location":"managing-workflow/tuning-component-settings/#influxdb","text":"You can find a list of values that can be set using environment variables here .","title":"InfluxDB"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-registry","text":"The Registry component can be tuned by following the teamhephy/distribution config doc .","title":"Customizing the Registry"},{"location":"managing-workflow/tuning-component-settings/#customizing-the-router","text":"The majority of router settings are tunable through annotations, which allows the router to be re-configured with zero downtime post-installation. You can find the list of annotations to tune here . The following environment variables are tunable for the Router component: Setting Description POD_NAMESPACE The pod namespace the router resides in. This is set by the Kubernetes downward API .","title":"Customizing the Router"},{"location":"managing-workflow/tuning-component-settings/#customizing-workflow-manager","text":"The following environment variables are tunable for Workflow Manager : Setting Description CHECK_VERSIONS Enables the external version check at https://versions.teamhephy.info/ (default: \"true\") POLL_INTERVAL_SEC The interval when Workflow Manager performs a version check, in seconds (default: 43200, or 12 hours) VERSIONS_API_URL The versions API URL (default: \" https://versions-staging.teamhephy.info \") DOCTOR_API_URL The doctor API URL (default: \" https://doctor-staging.teamhephy.info \") API_VERSION The version number Workflow Manager sends to the versions API (default: \"v2\")","title":"Customizing Workflow Manager"},{"location":"managing-workflow/upgrading-workflow/","text":"Upgrading Workflow \u00b6 Deis Workflow releases may be upgraded in-place with minimal downtime. This upgrade process requires: Helm version 2.1.0 or newer Configured Off-Cluster Storage A Kubernetes cluster with more than one node is required for the rolling upgrade of the deis-router (as it is a rolling upgrade with host ports) Off-Cluster Storage Required \u00b6 A Workflow upgrade requires using off-cluster object storage, since the default in-cluster storage is ephemeral. Upgrading Workflow with the in-cluster default of Minio will result in data loss. See Configuring Object Storage to learn how to store your Workflow data off-cluster. Upgrade Process \u00b6 Note If upgrading from a Helm Classic install, you'll need to 'migrate' the cluster to a Kubernetes Helm installation. See Workflow-Migration for steps. Step 1: Apply the Workflow upgrade \u00b6 Helm will remove all components from the previous release. Traffic to applications deployed through Workflow will continue to flow during the upgrade. No service interruptions should occur. If Workflow is not configured to use off-cluster Postgres, the Workflow API will experience a brief period of downtime while the database recovers from backup. First, find the name of the release helm gave to your deployment with helm ls , then run $ helm repo update $ helm upgrade <release-name> hephy/workflow Note: If using off-cluster object storage on gcs and/or off-cluster registry using gcr and intending to upgrade from a pre- v2.10.0 chart to v2.10.0 or greater, the key_json values will now need to be pre-base64-encoded. Therefore, assuming the rest of the custom/off-cluster values are defined in the existing values.yaml used for previous installs, the following may be run: $ B64_KEY_JSON=\"$(cat ~/path/to/key.json | base64 -w 0)\" $ helm upgrade <release_name> hephy/workflow -f values.yaml --set gcs.key_json=\"${B64_KEY_JSON}\",registry-token-refresher.gcr.key_json=\"${B64_KEY_JSON}\" Alternatively, simply replace the appropriate values in values.yaml and do without the --set parameter. Make sure to wrap it in single quotes as double quotes will give a parser error when upgrading. Step 2: Verify Upgrade \u00b6 Verify that all components have started and passed their readiness checks: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-2448122224-3cibz 1/1 Running 0 5m deis-controller-1410285775-ipc34 1/1 Running 3 5m deis-database-e7c5z 1/1 Running 0 5m deis-logger-cgjup 1/1 Running 3 5m deis-logger-fluentd-45h7j 1/1 Running 0 5m deis-logger-fluentd-4z7lw 1/1 Running 0 5m deis-logger-fluentd-k2wsw 1/1 Running 0 5m deis-logger-fluentd-skdw4 1/1 Running 0 5m deis-logger-redis-8nazu 1/1 Running 0 5m deis-monitor-grafana-tm266 1/1 Running 0 5m deis-monitor-influxdb-ah8io 1/1 Running 0 5m deis-monitor-telegraf-51zel 1/1 Running 1 5m deis-monitor-telegraf-cdasg 1/1 Running 0 5m deis-monitor-telegraf-hea6x 1/1 Running 0 5m deis-monitor-telegraf-r7lsg 1/1 Running 0 5m deis-nsqd-3yrg2 1/1 Running 0 5m deis-registry-1814324048-yomz5 1/1 Running 0 5m deis-registry-proxy-4m3o4 1/1 Running 0 5m deis-registry-proxy-no3r1 1/1 Running 0 5m deis-registry-proxy-ou8is 1/1 Running 0 5m deis-registry-proxy-zyajl 1/1 Running 0 5m deis-router-1357759721-a3ard 1/1 Running 0 5m deis-workflow-manager-2654760652-kitf9 1/1 Running 0 5m Step 3: Upgrade the Deis Client \u00b6 Users of Deis Workflow should now upgrade their deis client to avoid getting WARNING: Client and server API versions do not match. Please consider upgrading. warnings. curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 && sudo mv deis $(which deis)","title":"Upgrading Workflow"},{"location":"managing-workflow/upgrading-workflow/#upgrading-workflow","text":"Deis Workflow releases may be upgraded in-place with minimal downtime. This upgrade process requires: Helm version 2.1.0 or newer Configured Off-Cluster Storage A Kubernetes cluster with more than one node is required for the rolling upgrade of the deis-router (as it is a rolling upgrade with host ports)","title":"Upgrading Workflow"},{"location":"managing-workflow/upgrading-workflow/#off-cluster-storage-required","text":"A Workflow upgrade requires using off-cluster object storage, since the default in-cluster storage is ephemeral. Upgrading Workflow with the in-cluster default of Minio will result in data loss. See Configuring Object Storage to learn how to store your Workflow data off-cluster.","title":"Off-Cluster Storage Required"},{"location":"managing-workflow/upgrading-workflow/#upgrade-process","text":"Note If upgrading from a Helm Classic install, you'll need to 'migrate' the cluster to a Kubernetes Helm installation. See Workflow-Migration for steps.","title":"Upgrade Process"},{"location":"managing-workflow/upgrading-workflow/#step-1-apply-the-workflow-upgrade","text":"Helm will remove all components from the previous release. Traffic to applications deployed through Workflow will continue to flow during the upgrade. No service interruptions should occur. If Workflow is not configured to use off-cluster Postgres, the Workflow API will experience a brief period of downtime while the database recovers from backup. First, find the name of the release helm gave to your deployment with helm ls , then run $ helm repo update $ helm upgrade <release-name> hephy/workflow Note: If using off-cluster object storage on gcs and/or off-cluster registry using gcr and intending to upgrade from a pre- v2.10.0 chart to v2.10.0 or greater, the key_json values will now need to be pre-base64-encoded. Therefore, assuming the rest of the custom/off-cluster values are defined in the existing values.yaml used for previous installs, the following may be run: $ B64_KEY_JSON=\"$(cat ~/path/to/key.json | base64 -w 0)\" $ helm upgrade <release_name> hephy/workflow -f values.yaml --set gcs.key_json=\"${B64_KEY_JSON}\",registry-token-refresher.gcr.key_json=\"${B64_KEY_JSON}\" Alternatively, simply replace the appropriate values in values.yaml and do without the --set parameter. Make sure to wrap it in single quotes as double quotes will give a parser error when upgrading.","title":"Step 1: Apply the Workflow upgrade"},{"location":"managing-workflow/upgrading-workflow/#step-2-verify-upgrade","text":"Verify that all components have started and passed their readiness checks: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-2448122224-3cibz 1/1 Running 0 5m deis-controller-1410285775-ipc34 1/1 Running 3 5m deis-database-e7c5z 1/1 Running 0 5m deis-logger-cgjup 1/1 Running 3 5m deis-logger-fluentd-45h7j 1/1 Running 0 5m deis-logger-fluentd-4z7lw 1/1 Running 0 5m deis-logger-fluentd-k2wsw 1/1 Running 0 5m deis-logger-fluentd-skdw4 1/1 Running 0 5m deis-logger-redis-8nazu 1/1 Running 0 5m deis-monitor-grafana-tm266 1/1 Running 0 5m deis-monitor-influxdb-ah8io 1/1 Running 0 5m deis-monitor-telegraf-51zel 1/1 Running 1 5m deis-monitor-telegraf-cdasg 1/1 Running 0 5m deis-monitor-telegraf-hea6x 1/1 Running 0 5m deis-monitor-telegraf-r7lsg 1/1 Running 0 5m deis-nsqd-3yrg2 1/1 Running 0 5m deis-registry-1814324048-yomz5 1/1 Running 0 5m deis-registry-proxy-4m3o4 1/1 Running 0 5m deis-registry-proxy-no3r1 1/1 Running 0 5m deis-registry-proxy-ou8is 1/1 Running 0 5m deis-registry-proxy-zyajl 1/1 Running 0 5m deis-router-1357759721-a3ard 1/1 Running 0 5m deis-workflow-manager-2654760652-kitf9 1/1 Running 0 5m","title":"Step 2: Verify Upgrade"},{"location":"managing-workflow/upgrading-workflow/#step-3-upgrade-the-deis-client","text":"Users of Deis Workflow should now upgrade their deis client to avoid getting WARNING: Client and server API versions do not match. Please consider upgrading. warnings. curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 && sudo mv deis $(which deis)","title":"Step 3: Upgrade the Deis Client"},{"location":"quickstart/","text":"Quick Start \u00b6 Get started with Deis Workflow in three easy steps. Install CLI tools for Helm and Deis Workflow Boot a Kubernetes and install Deis Workflow Deploy your first application This guide will help you set up a cluster suitable for evaluation, development and testing. When you are ready for staging and production, view our production checklist . Step 1: Install CLI tools \u00b6 For the quickstart we will install both Helm and Deis Workflow CLI . Step 2: Boot Kubernetes and Install Deis Workflow \u00b6 There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kube-up.sh to boot a cluster on AWS EC2. Azure Container Service : uses Azure Container Service to provision Kubernetes and install Workflow. If you would like to test on your local machine follow, our guide for Minikube . If you have already created a Kubernetes cluster, check out the system requirements and then proceed to install Deis Workflow on your own Kubernetes cluster . Step 3: Deploy your first app \u00b6 Last but not least, register a user and deploy your first application .","title":"Overview"},{"location":"quickstart/#quick-start","text":"Get started with Deis Workflow in three easy steps. Install CLI tools for Helm and Deis Workflow Boot a Kubernetes and install Deis Workflow Deploy your first application This guide will help you set up a cluster suitable for evaluation, development and testing. When you are ready for staging and production, view our production checklist .","title":"Quick Start"},{"location":"quickstart/#step-1-install-cli-tools","text":"For the quickstart we will install both Helm and Deis Workflow CLI .","title":"Step 1: Install CLI tools"},{"location":"quickstart/#step-2-boot-kubernetes-and-install-deis-workflow","text":"There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kube-up.sh to boot a cluster on AWS EC2. Azure Container Service : uses Azure Container Service to provision Kubernetes and install Workflow. If you would like to test on your local machine follow, our guide for Minikube . If you have already created a Kubernetes cluster, check out the system requirements and then proceed to install Deis Workflow on your own Kubernetes cluster .","title":"Step 2: Boot Kubernetes and Install Deis Workflow"},{"location":"quickstart/#step-3-deploy-your-first-app","text":"Last but not least, register a user and deploy your first application .","title":"Step 3: Deploy your first app"},{"location":"quickstart/deploy-an-app/","text":"Determine Your Host and Hostname Values \u00b6 For the rest of this example we will refer to a special variables called $hostname . Please choose one of the two methods for building your $hostname . Option 1: Standard Installation \u00b6 For a standard installation that includes deis-router, you can calculate the hostname value using its public IP address and a wildcard DNS record. If your router IP is 1.1.1.1 , its $hostname will be deis.1.1.1.1.nip.io . You can find your IP address by running: kubectl --namespace=deis describe svc deis-router If you do not have an load balancer IP, the router automatically forwards traffic from a kubernetes node to the router. In this case, use the IP of a kubernetes node and the node port that routes to port 80 on the controller. Deis workflow requires a wildcard DNS record to dynamically map app names to the router. Option 2: Experimental Native Ingress Installation \u00b6 In this example, the user should already have DNS set up pointing to their known host. The $hostname value can be calculated by prepending deis. to the value set in controller.platform_domain . Register an Admin User \u00b6 The first user to register against Deis Workflow will automatically be given administrative privileges. Use the controller $hostname to register a user in the cluster. $ deis register http://$hostname username: admin password: password (confirm): email: jhansen@deis.com Registered admin Logged in as admin $ deis whoami You are admin at http://$hostname You have now registered your first user and you are ready to deploy an application. Deploy an Application \u00b6 Deis Workflow supports three different types of applications, Buildpacks, Dockerfiles and Docker Images. Our first application will be a simple Docker Image-based application, so you don't have to wrestle with checking out code. Run deis create to create a new application on Deis Workflow. If you do not specify a name for your application, Workflow automatically generates a friendly (and sometimes funny) name. $ deis create --no-remote Creating Application... done, created proper-barbecue If you want to add a git remote for this app later, use `deis git:remote -a proper-barbecue` Our application has been created and named proper-barbecue . As with the deis hostname, any HTTP traffic to proper-barbecue will be automatically routed to your application pods by the edge router. Let's use the CLI to tell the platform to deploy an application and then use curl to send a request to the app: $ deis pull deis/example-go -a proper-barbecue Creating build... done $ curl http://proper-barbecue.$hostname Powered by Deis Note If you see a 404 error, make sure you specified your application name with -a <appname> ! Workflow's edge router knows all about application names and automatically sends traffic to the right application. The router sends traffic for proper-barbecue.104.197.125.75.nip.io to your app, just like deis.104.197.125.75.nip.io was sent to the Workflow API service. Change Application Configuration \u00b6 Next, let's change some configuration using the CLI. Our example app is built to read configuration from the environment. By using deis config:set we can change how the application behaves: $ deis config:set POWERED_BY=\"Docker Images + Kubernetes\" -a proper-barbecue Creating config... done === proper-barbecue Config POWERED_BY Docker Images + Kubernetes Behind the scenes, Workflow creates a new release for your application and uses Kubernetes to provide a zero-downtime rolling deploy to the new release! Validate that our configuration change has worked: $ curl http://proper-barbecue.104.197.125.75.nip.io Powered by Docker Images + Kubernetes Scale Your Application \u00b6 Last, let's scale our application by adding more application processes. Using the CLI you can easily add and remove additional processes to service requests: $ deis scale cmd=2 -a proper-barbecue Scaling processes... but first, coffee! done in 36s === proper-barbecue Processes --- cmd: proper-barbecue-v18-cmd-rk644 up (v18) proper-barbecue-v18-cmd-0ag04 up (v18) Congratulations! You have deployed, configured, and scaled your first application using Deis Workflow. Going Further \u00b6 There is a lot more you can do with Deis Workflow, play around with the CLI: Important In order to have permission to push an app you must add a SSH key to your user on the Deis Workflow. For more information, please check Users and SSH Keys and Troubleshooting Workflow . Roll back to a previous release with deis rollback -a proper-barbecue See application logs with deis logs -a proper-barbecue Try one of our other example applications like: deis/example-ruby-sinatra deis/example-nodejs-express deis/example-java-jetty Read about using application Buildpacks or Dockerfiles Join our #community slack channel and meet the team!","title":"Deploy Your First App"},{"location":"quickstart/deploy-an-app/#determine-your-host-and-hostname-values","text":"For the rest of this example we will refer to a special variables called $hostname . Please choose one of the two methods for building your $hostname .","title":"Determine Your Host and Hostname Values"},{"location":"quickstart/deploy-an-app/#option-1-standard-installation","text":"For a standard installation that includes deis-router, you can calculate the hostname value using its public IP address and a wildcard DNS record. If your router IP is 1.1.1.1 , its $hostname will be deis.1.1.1.1.nip.io . You can find your IP address by running: kubectl --namespace=deis describe svc deis-router If you do not have an load balancer IP, the router automatically forwards traffic from a kubernetes node to the router. In this case, use the IP of a kubernetes node and the node port that routes to port 80 on the controller. Deis workflow requires a wildcard DNS record to dynamically map app names to the router.","title":"Option 1: Standard Installation"},{"location":"quickstart/deploy-an-app/#option-2-experimental-native-ingress-installation","text":"In this example, the user should already have DNS set up pointing to their known host. The $hostname value can be calculated by prepending deis. to the value set in controller.platform_domain .","title":"Option 2: Experimental Native Ingress Installation"},{"location":"quickstart/deploy-an-app/#register-an-admin-user","text":"The first user to register against Deis Workflow will automatically be given administrative privileges. Use the controller $hostname to register a user in the cluster. $ deis register http://$hostname username: admin password: password (confirm): email: jhansen@deis.com Registered admin Logged in as admin $ deis whoami You are admin at http://$hostname You have now registered your first user and you are ready to deploy an application.","title":"Register an Admin User"},{"location":"quickstart/deploy-an-app/#deploy-an-application","text":"Deis Workflow supports three different types of applications, Buildpacks, Dockerfiles and Docker Images. Our first application will be a simple Docker Image-based application, so you don't have to wrestle with checking out code. Run deis create to create a new application on Deis Workflow. If you do not specify a name for your application, Workflow automatically generates a friendly (and sometimes funny) name. $ deis create --no-remote Creating Application... done, created proper-barbecue If you want to add a git remote for this app later, use `deis git:remote -a proper-barbecue` Our application has been created and named proper-barbecue . As with the deis hostname, any HTTP traffic to proper-barbecue will be automatically routed to your application pods by the edge router. Let's use the CLI to tell the platform to deploy an application and then use curl to send a request to the app: $ deis pull deis/example-go -a proper-barbecue Creating build... done $ curl http://proper-barbecue.$hostname Powered by Deis Note If you see a 404 error, make sure you specified your application name with -a <appname> ! Workflow's edge router knows all about application names and automatically sends traffic to the right application. The router sends traffic for proper-barbecue.104.197.125.75.nip.io to your app, just like deis.104.197.125.75.nip.io was sent to the Workflow API service.","title":"Deploy an Application"},{"location":"quickstart/deploy-an-app/#change-application-configuration","text":"Next, let's change some configuration using the CLI. Our example app is built to read configuration from the environment. By using deis config:set we can change how the application behaves: $ deis config:set POWERED_BY=\"Docker Images + Kubernetes\" -a proper-barbecue Creating config... done === proper-barbecue Config POWERED_BY Docker Images + Kubernetes Behind the scenes, Workflow creates a new release for your application and uses Kubernetes to provide a zero-downtime rolling deploy to the new release! Validate that our configuration change has worked: $ curl http://proper-barbecue.104.197.125.75.nip.io Powered by Docker Images + Kubernetes","title":"Change Application Configuration"},{"location":"quickstart/deploy-an-app/#scale-your-application","text":"Last, let's scale our application by adding more application processes. Using the CLI you can easily add and remove additional processes to service requests: $ deis scale cmd=2 -a proper-barbecue Scaling processes... but first, coffee! done in 36s === proper-barbecue Processes --- cmd: proper-barbecue-v18-cmd-rk644 up (v18) proper-barbecue-v18-cmd-0ag04 up (v18) Congratulations! You have deployed, configured, and scaled your first application using Deis Workflow.","title":"Scale Your Application"},{"location":"quickstart/deploy-an-app/#going-further","text":"There is a lot more you can do with Deis Workflow, play around with the CLI: Important In order to have permission to push an app you must add a SSH key to your user on the Deis Workflow. For more information, please check Users and SSH Keys and Troubleshooting Workflow . Roll back to a previous release with deis rollback -a proper-barbecue See application logs with deis logs -a proper-barbecue Try one of our other example applications like: deis/example-ruby-sinatra deis/example-nodejs-express deis/example-java-jetty Read about using application Buildpacks or Dockerfiles Join our #community slack channel and meet the team!","title":"Going Further"},{"location":"quickstart/install-cli-tools/","text":"Deis Workflow Client CLI \u00b6 The Deis command-line interface (CLI), lets you interact with Deis Workflow. Use the CLI to create and configure and manage applications. Install the latest deis client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 The installer places the deis binary in your current directory, but you should move it somewhere in your $PATH: $ sudo ln -fs $PWD/deis /usr/local/bin/deis or : $ sudo mv $PWD/deis /usr/local/bin/deis Check your work by running deis version : $ deis version v2.17.0 Note Note that version numbers may vary as new releases become available Helm Installation \u00b6 We will install Deis Workflow using Helm which is a tool for installing and managing software in a Kubernetes cluster. Install the latest helm cli for Linux or Mac OS X by following the installation instructions . Step 2: Boot a Kubernetes Cluster and Install Deis Workflow \u00b6 There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kops to boot a cluster on AWS EC2. Azure Container Service : provides a managed Kubernetes environment. If you would like to test on your local machine follow our guide for Minikube .","title":"Install CLI Tools"},{"location":"quickstart/install-cli-tools/#deis-workflow-client-cli","text":"The Deis command-line interface (CLI), lets you interact with Deis Workflow. Use the CLI to create and configure and manage applications. Install the latest deis client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 The installer places the deis binary in your current directory, but you should move it somewhere in your $PATH: $ sudo ln -fs $PWD/deis /usr/local/bin/deis or : $ sudo mv $PWD/deis /usr/local/bin/deis Check your work by running deis version : $ deis version v2.17.0 Note Note that version numbers may vary as new releases become available","title":"Deis Workflow Client CLI"},{"location":"quickstart/install-cli-tools/#helm-installation","text":"We will install Deis Workflow using Helm which is a tool for installing and managing software in a Kubernetes cluster. Install the latest helm cli for Linux or Mac OS X by following the installation instructions .","title":"Helm Installation"},{"location":"quickstart/install-cli-tools/#step-2-boot-a-kubernetes-cluster-and-install-deis-workflow","text":"There are many ways to boot and run Kubernetes. You may choose to get up and running in cloud environments or locally on your laptop. Cloud-based options: Google Container Engine : provides a managed Kubernetes environment, available with a few clicks. Amazon Web Services : uses Kubernetes upstream kops to boot a cluster on AWS EC2. Azure Container Service : provides a managed Kubernetes environment. If you would like to test on your local machine follow our guide for Minikube .","title":"Step 2: Boot a Kubernetes Cluster and Install Deis Workflow"},{"location":"quickstart/provider/aws/boot/","text":"Booting Kubernetes on Amazon Elastic Compute with kops \u00b6 Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides compute capacity in the cloud. This quickstart guide uses AWS EC2 to boot a Kubernetes cluster using kubernetes kops . Installing kops \u00b6 Download the latest version of kops macOS \u00b6 $ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-darwin-amd64 -O $ chmod +x kops-darwin-amd64 $ sudo mv kops-darwin-amd64 /usr/local/bin/kops linux \u00b6 $ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-linux-amd64 -O $ chmod +x kops-linux-amd64 $ sudo mv kops-linux-amd64 /usr/local/bin/kops For more information see the official kops installation guide . Validate kops is installed \u00b6 $ kops version Version 1.5.3 Install kubectl if you haven't done so yet \u00b6 $ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl $ chmod +x kubectl $ sudo mv kubectl /usr/local/bin/ Setup your AWS account \u00b6 Install the awscli tool \u00b6 The officially supported way of installing the tool is with pip as in $ pip install awscli You can also grab the tool with homebrew (for macOS users only ), although this is not officially supported by AWS. $ brew update && brew install awscli Configure the awscli tool \u00b6 The first thing you need to do is get valid AWS credentials out of the console. See the official documentation on how to find your SecretAccessKey and AccessKeyID . Once you have those you can configure the awscli tool with $ aws configure # Input your credentials here Setting up IAM permission for kops \u00b6 The recommended practice is to use a dedicated IAM user for kops. At a minimum kops will require the following IAM permissions to function properly. AmazonEC2FullAccess This is used to deploy to instances in EC2 AmazonRoute53FullAccess This is used so kops can automatically create friendly DNS records for your cluster resources AmazonS3FullAccess This is used to store meta configuration about your cluster. We will need read/write here to use S3 as a virtual filesystem in kops. IAMFullAccess This is used because kops will create new IAM users for some of its resources. Those resources will have permissions managed securely by kops. AmazonVPCFullAccess This used to create a VPC which serves as the foundation of all networking components in kops. Without a VPC, kops wouldn't be able to deploy any resources dependent on a network. (Optional) Create a dedicated IAM user from the command line \u00b6 Note : This can only be done AFTER you already have valid aws credentials in place. We will use the official kops provided convenience script to configure a new user with the following syntax: sh new-iam-user.sh $group $user $ curl -O https://raw.githubusercontent.com/kubernetes/kops/master/hack/new-iam-user.sh $ sh new-iam-user.sh kops-group kops-user Note the SecretAccessKey and AccessKeyID so you can enter them in the following commands $ aws configure # Input your credentials here $ aws iam list-users Configure DNS \u00b6 In order to build a Kubernetes cluster with kops , we need to prepare somewhere to build the required DNS records. There are three scenarios below and you should choose the one that most closely matches your AWS situation. Scenario 1a: A Domain purchased/hosted via AWS \u00b6 If you bought your domain with AWS, then you should already have a hosted zone in Route53. If you plan to use this domain then no more work is needed. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.example.com You can now skip to testing your DNS setup Scenario 1b: A subdomain under a domain purchased/hosted via AWS \u00b6 In this scenario you want to contain all kubernetes records under a subdomain of a domain you host in Route53. This requires creating a second hosted zone in route53, and then setting up route delegation to the new zone. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.kubernetes.example.com This is copying the NS servers of your SUBDOMAIN up to the PARENT domain in Route53. To do this you should: $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers Note your PARENT hosted zone ID # Note: This example assumes you have jq installed locally. aws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id' Create a new JSON file with your values ( subdomain.json ) Note: The NS values here are for the SUBDOMAIN { \"Comment\": \"Create a subdomain NS record in the parent domain\", \"Changes\": [ { \"Action\": \"CREATE\", \"ResourceRecordSet\": { \"Name\": \"subdomain.example.com\", \"Type\": \"NS\", \"TTL\": 300, \"ResourceRecords\": [ { \"Value\": \"ns-1.awsdns-1.co.uk\" }, { \"Value\": \"ns-2.awsdns-2.org\" }, { \"Value\": \"ns-3.awsdns-3.com\" }, { \"Value\": \"ns-4.awsdns-4.net\" } ] } } ] } Apply the SUBDOMAIN NS records to the PARENT hosted zone. $ aws route53 change-resource-record-sets \\ --hosted-zone-id <parent-zone-id> \\ --change-batch file://subdomain.json Now traffic to *.example.com will be routed to the correct subdomain hosted zone in Route53. You can now skip to testing your DNS setup Scenario 2: Setting up Route53 for a domain purchased with another registrar \u00b6 If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide here You can now skip to testing your DNS setup Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar \u00b6 If you bought your domain elsewhere, but only want to use a subdomain in AWS Route53 you must modify your registrar's NS (NameServer) records. We'll create a hosted zone in Route53, and then migrate the subdomain's NS records to your other registrar. You might need to install jq for some of these instructions. $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.kubernetes.com --caller-reference $ID | jq .DelegationSet.NameServers You will now go to your registrar's page and log in. You will need to create a new SUBDOMAIN , and use the 4 NS records listed above for the new SUBDOMAIN . This MUST be done in order to use your cluster. Do NOT change your top level NS record, or you might take your site offline. Information on adding NS records with Godaddy.com Information on adding NS records with Google Cloud Platform You can now skip to testing your DNS setup Using Public/Private DNS (Kops 1.5+) \u00b6 By default the assumption is that NS records are publically available. If you require private DNS records you should modify the commands we run later in this guide to include: $ kops create cluster --dns private $NAME Testing your DNS setup \u00b6 You should now able to dig your domain (or subdomain) and see the AWS Name Servers on the other end. $ dig ns subdomain.example.com Should return something similar to: ;; ANSWER SECTION: subdomain.example.com. 172800 IN NS ns-1.awsdns-1.net. subdomain.example.com. 172800 IN NS ns-2.awsdns-2.org. subdomain.example.com. 172800 IN NS ns-3.awsdns-3.com. subdomain.example.com. 172800 IN NS ns-4.awsdns-4.co.uk. This is a critical component of setting up clusters. If you are experiencing problems with the Kubernetes API not coming up, chances are something is wrong with the cluster's DNS. Please DO NOT MOVE ON until you have validated your NS records! Cluster State storage \u00b6 In order to store the state of your cluster, and the representation of your cluster, we need to create a dedicated S3 bucket for kops to use. This bucket will become the source of truth for our cluster configuration. In this guide we'll call this bucket example-com-state-store , but you should add a custom prefix as bucket names need to be unique. We recommend keeping the creation of this bucket confined to us-east-1, otherwise more work will be required. $ aws s3api create-bucket --bucket prefix-example-com-state-store --region us-east-1 Note: We STRONGLY recommend versioning your S3 bucket in case you ever need to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket prefix-example-com-state-store --versioning-configuration Status=Enabled Creating your first cluster \u00b6 Prepare local environment \u00b6 We're ready to start creating our first cluster! Let's first setup a few environment variables to make this process easier. $ export NAME=myfirstcluster.example.com $ export KOPS_STATE_STORE=s3://prefix-example-com-state-store Note: You don\u2019t have to use environmental variables here. You can always define the values using the \u2013name and \u2013state flags later. Create cluster configuration \u00b6 We will need to note which availability zones are available to us. In this example we will be deploying our cluster to the us-west-2 region. $ aws ec2 describe-availability-zones --region us-west-2 Below is a basic create cluster command. The below command will generate a cluster configuration, but not start building it. $ kops create cluster \\ --zones us-west-2a \\ ${NAME} All instances created by kops will be built within ASG (Auto Scaling Groups), which means each instance will be automatically monitored and rebuilt by AWS if it suffers any failure. Customize Cluster Configuration \u00b6 Now we have a cluster configuration, we can look at every aspect that defines our cluster by editing the description. $ kops edit cluster ${NAME} This opens your editor (as defined by $EDITOR) and allows you to edit the configuration. The configuration is loaded from the S3 bucket we created earlier, and automatically updated when we save and exit the editor. We'll leave everything set to the defaults for now, but the rest of the kops documentation covers additional settings and configuration you can enable. Build the Cluster \u00b6 Now we take the final step of actually building the cluster. This'll take a while. Once it finishes you'll have to wait longer while the booted instances finish downloading Kubernetes components and reach a \"ready\" state. $ kops update cluster ${NAME} --yes Use the Cluster \u00b6 Remember when you installed kubectl earlier? The configuration for your cluster was automatically generated and written to ~/.kube/config for you! Optionally you can always pull the configuration with the following command: $ kops export kubecfg --name ${NAME} A simple Kubernetes API call can be used to check if the API is online and listening. Let's use kubectl to check the nodes. $ kubectl get nodes You will see a list of nodes that should match the --zones flag defined earlier. This is a great sign that your Kubernetes cluster is online and working. Also kops ships with a handy validation tool that can be ran to ensure your cluster is working as expected. $ kubectl cluster-info You can look at all the system components with the following command. $ kubectl -n kube-system get po You are now ready to install Deis Workflow","title":"Boot"},{"location":"quickstart/provider/aws/boot/#booting-kubernetes-on-amazon-elastic-compute-with-kops","text":"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides compute capacity in the cloud. This quickstart guide uses AWS EC2 to boot a Kubernetes cluster using kubernetes kops .","title":"Booting Kubernetes on Amazon Elastic Compute with kops"},{"location":"quickstart/provider/aws/boot/#installing-kops","text":"Download the latest version of kops","title":"Installing kops"},{"location":"quickstart/provider/aws/boot/#macos","text":"$ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-darwin-amd64 -O $ chmod +x kops-darwin-amd64 $ sudo mv kops-darwin-amd64 /usr/local/bin/kops","title":"macOS"},{"location":"quickstart/provider/aws/boot/#linux","text":"$ curl -sSL https://github.com/kubernetes/kops/releases/download/1.5.3/kops-linux-amd64 -O $ chmod +x kops-linux-amd64 $ sudo mv kops-linux-amd64 /usr/local/bin/kops For more information see the official kops installation guide .","title":"linux"},{"location":"quickstart/provider/aws/boot/#validate-kops-is-installed","text":"$ kops version Version 1.5.3","title":"Validate kops is installed"},{"location":"quickstart/provider/aws/boot/#install-kubectl-if-you-havent-done-so-yet","text":"$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl $ chmod +x kubectl $ sudo mv kubectl /usr/local/bin/","title":"Install kubectl if you haven't done so yet"},{"location":"quickstart/provider/aws/boot/#setup-your-aws-account","text":"","title":"Setup your AWS account"},{"location":"quickstart/provider/aws/boot/#install-the-awscli-tool","text":"The officially supported way of installing the tool is with pip as in $ pip install awscli You can also grab the tool with homebrew (for macOS users only ), although this is not officially supported by AWS. $ brew update && brew install awscli","title":"Install the awscli tool"},{"location":"quickstart/provider/aws/boot/#configure-the-awscli-tool","text":"The first thing you need to do is get valid AWS credentials out of the console. See the official documentation on how to find your SecretAccessKey and AccessKeyID . Once you have those you can configure the awscli tool with $ aws configure # Input your credentials here","title":"Configure the awscli tool"},{"location":"quickstart/provider/aws/boot/#setting-up-iam-permission-for-kops","text":"The recommended practice is to use a dedicated IAM user for kops. At a minimum kops will require the following IAM permissions to function properly. AmazonEC2FullAccess This is used to deploy to instances in EC2 AmazonRoute53FullAccess This is used so kops can automatically create friendly DNS records for your cluster resources AmazonS3FullAccess This is used to store meta configuration about your cluster. We will need read/write here to use S3 as a virtual filesystem in kops. IAMFullAccess This is used because kops will create new IAM users for some of its resources. Those resources will have permissions managed securely by kops. AmazonVPCFullAccess This used to create a VPC which serves as the foundation of all networking components in kops. Without a VPC, kops wouldn't be able to deploy any resources dependent on a network.","title":"Setting up IAM permission for kops"},{"location":"quickstart/provider/aws/boot/#optional-create-a-dedicated-iam-user-from-the-command-line","text":"Note : This can only be done AFTER you already have valid aws credentials in place. We will use the official kops provided convenience script to configure a new user with the following syntax: sh new-iam-user.sh $group $user $ curl -O https://raw.githubusercontent.com/kubernetes/kops/master/hack/new-iam-user.sh $ sh new-iam-user.sh kops-group kops-user Note the SecretAccessKey and AccessKeyID so you can enter them in the following commands $ aws configure # Input your credentials here $ aws iam list-users","title":"(Optional) Create a dedicated IAM user from the command line"},{"location":"quickstart/provider/aws/boot/#configure-dns","text":"In order to build a Kubernetes cluster with kops , we need to prepare somewhere to build the required DNS records. There are three scenarios below and you should choose the one that most closely matches your AWS situation.","title":"Configure DNS"},{"location":"quickstart/provider/aws/boot/#scenario-1a-a-domain-purchasedhosted-via-aws","text":"If you bought your domain with AWS, then you should already have a hosted zone in Route53. If you plan to use this domain then no more work is needed. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.example.com You can now skip to testing your DNS setup","title":"Scenario 1a: A Domain purchased/hosted via AWS"},{"location":"quickstart/provider/aws/boot/#scenario-1b-a-subdomain-under-a-domain-purchasedhosted-via-aws","text":"In this scenario you want to contain all kubernetes records under a subdomain of a domain you host in Route53. This requires creating a second hosted zone in route53, and then setting up route delegation to the new zone. In this example you own example.com and your records for Kubernetes would look like etcd-us-east-1c.internal.clustername.kubernetes.example.com This is copying the NS servers of your SUBDOMAIN up to the PARENT domain in Route53. To do this you should: $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers Note your PARENT hosted zone ID # Note: This example assumes you have jq installed locally. aws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id' Create a new JSON file with your values ( subdomain.json ) Note: The NS values here are for the SUBDOMAIN { \"Comment\": \"Create a subdomain NS record in the parent domain\", \"Changes\": [ { \"Action\": \"CREATE\", \"ResourceRecordSet\": { \"Name\": \"subdomain.example.com\", \"Type\": \"NS\", \"TTL\": 300, \"ResourceRecords\": [ { \"Value\": \"ns-1.awsdns-1.co.uk\" }, { \"Value\": \"ns-2.awsdns-2.org\" }, { \"Value\": \"ns-3.awsdns-3.com\" }, { \"Value\": \"ns-4.awsdns-4.net\" } ] } } ] } Apply the SUBDOMAIN NS records to the PARENT hosted zone. $ aws route53 change-resource-record-sets \\ --hosted-zone-id <parent-zone-id> \\ --change-batch file://subdomain.json Now traffic to *.example.com will be routed to the correct subdomain hosted zone in Route53. You can now skip to testing your DNS setup","title":"Scenario 1b: A subdomain under a domain purchased/hosted via AWS"},{"location":"quickstart/provider/aws/boot/#scenario-2-setting-up-route53-for-a-domain-purchased-with-another-registrar","text":"If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide here You can now skip to testing your DNS setup","title":"Scenario 2: Setting up Route53 for a domain purchased with another registrar"},{"location":"quickstart/provider/aws/boot/#scenario-3-subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar","text":"If you bought your domain elsewhere, but only want to use a subdomain in AWS Route53 you must modify your registrar's NS (NameServer) records. We'll create a hosted zone in Route53, and then migrate the subdomain's NS records to your other registrar. You might need to install jq for some of these instructions. $ ID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.kubernetes.com --caller-reference $ID | jq .DelegationSet.NameServers You will now go to your registrar's page and log in. You will need to create a new SUBDOMAIN , and use the 4 NS records listed above for the new SUBDOMAIN . This MUST be done in order to use your cluster. Do NOT change your top level NS record, or you might take your site offline. Information on adding NS records with Godaddy.com Information on adding NS records with Google Cloud Platform You can now skip to testing your DNS setup","title":"Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar"},{"location":"quickstart/provider/aws/boot/#using-publicprivate-dns-kops-15","text":"By default the assumption is that NS records are publically available. If you require private DNS records you should modify the commands we run later in this guide to include: $ kops create cluster --dns private $NAME","title":"Using Public/Private DNS (Kops 1.5+)"},{"location":"quickstart/provider/aws/boot/#testing-your-dns-setup","text":"You should now able to dig your domain (or subdomain) and see the AWS Name Servers on the other end. $ dig ns subdomain.example.com Should return something similar to: ;; ANSWER SECTION: subdomain.example.com. 172800 IN NS ns-1.awsdns-1.net. subdomain.example.com. 172800 IN NS ns-2.awsdns-2.org. subdomain.example.com. 172800 IN NS ns-3.awsdns-3.com. subdomain.example.com. 172800 IN NS ns-4.awsdns-4.co.uk. This is a critical component of setting up clusters. If you are experiencing problems with the Kubernetes API not coming up, chances are something is wrong with the cluster's DNS. Please DO NOT MOVE ON until you have validated your NS records!","title":"Testing your DNS setup"},{"location":"quickstart/provider/aws/boot/#cluster-state-storage","text":"In order to store the state of your cluster, and the representation of your cluster, we need to create a dedicated S3 bucket for kops to use. This bucket will become the source of truth for our cluster configuration. In this guide we'll call this bucket example-com-state-store , but you should add a custom prefix as bucket names need to be unique. We recommend keeping the creation of this bucket confined to us-east-1, otherwise more work will be required. $ aws s3api create-bucket --bucket prefix-example-com-state-store --region us-east-1 Note: We STRONGLY recommend versioning your S3 bucket in case you ever need to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket prefix-example-com-state-store --versioning-configuration Status=Enabled","title":"Cluster State storage"},{"location":"quickstart/provider/aws/boot/#creating-your-first-cluster","text":"","title":"Creating your first cluster"},{"location":"quickstart/provider/aws/boot/#prepare-local-environment","text":"We're ready to start creating our first cluster! Let's first setup a few environment variables to make this process easier. $ export NAME=myfirstcluster.example.com $ export KOPS_STATE_STORE=s3://prefix-example-com-state-store Note: You don\u2019t have to use environmental variables here. You can always define the values using the \u2013name and \u2013state flags later.","title":"Prepare local environment"},{"location":"quickstart/provider/aws/boot/#create-cluster-configuration","text":"We will need to note which availability zones are available to us. In this example we will be deploying our cluster to the us-west-2 region. $ aws ec2 describe-availability-zones --region us-west-2 Below is a basic create cluster command. The below command will generate a cluster configuration, but not start building it. $ kops create cluster \\ --zones us-west-2a \\ ${NAME} All instances created by kops will be built within ASG (Auto Scaling Groups), which means each instance will be automatically monitored and rebuilt by AWS if it suffers any failure.","title":"Create cluster configuration"},{"location":"quickstart/provider/aws/boot/#customize-cluster-configuration","text":"Now we have a cluster configuration, we can look at every aspect that defines our cluster by editing the description. $ kops edit cluster ${NAME} This opens your editor (as defined by $EDITOR) and allows you to edit the configuration. The configuration is loaded from the S3 bucket we created earlier, and automatically updated when we save and exit the editor. We'll leave everything set to the defaults for now, but the rest of the kops documentation covers additional settings and configuration you can enable.","title":"Customize Cluster Configuration"},{"location":"quickstart/provider/aws/boot/#build-the-cluster","text":"Now we take the final step of actually building the cluster. This'll take a while. Once it finishes you'll have to wait longer while the booted instances finish downloading Kubernetes components and reach a \"ready\" state. $ kops update cluster ${NAME} --yes","title":"Build the Cluster"},{"location":"quickstart/provider/aws/boot/#use-the-cluster","text":"Remember when you installed kubectl earlier? The configuration for your cluster was automatically generated and written to ~/.kube/config for you! Optionally you can always pull the configuration with the following command: $ kops export kubecfg --name ${NAME} A simple Kubernetes API call can be used to check if the API is online and listening. Let's use kubectl to check the nodes. $ kubectl get nodes You will see a list of nodes that should match the --zones flag defined earlier. This is a great sign that your Kubernetes cluster is online and working. Also kops ships with a handy validation tool that can be ran to ensure your cluster is working as expected. $ kubectl cluster-info You can look at all the system components with the following command. $ kubectl -n kube-system get po You are now ready to install Deis Workflow","title":"Use the Cluster"},{"location":"quickstart/provider/aws/dns/","text":"Find Your Load Balancer Hostname \u00b6 On EC2, Deis Workflow will automatically provision and attach an Elastic Load Balancer (ELB) to the Router . The Router is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow, as well as streaming TCP requests to the Builder . By describing the deis-router service, you can see what hostname allocated by AWS for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com Prepare the Hostname \u00b6 Using DNS \u00b6 Now that we have the hostname of the load balancer, let's create the wildcard DNS record that directs requests from your machine to the application. First, if you haven't already done so, register your domain name. The Internet Corporation for Assigned Names and Numbers (ICANN) manages domain names on the Internet. You register a domain name using a domain name registrar, an ICANN-accredited organization that manages the registry of domain names. The website for your registrar will provide detailed instructions and pricing information for registering your domain name. For more information, see the following resources: To use Amazon Route 53 to register a domain name, see Registering Domain Names Using Amazon Route 53 . For a list of accredited registrars, see the Accredited Registrar Directory . Next, use your DNS service, such as your domain registrar, to create a wildcard CNAME record to route queries to your load balancer. For more information, see the documentation for your DNS service. Alternatively, you can use Amazon Route 53 as your DNS service. You create a hosted zone, which contains information about how to route traffic on the Internet for your domain, and an alias resource record set, which routes queries for your domain name to your load balancer. To create a hosted zone and an alias record set for your domain using Amazon Route 53: Open the Amazon Route 53 console at https://console.aws.amazon.com/route53/. Create a Public Hosted Zone with your domain name. Select the hosted zone that you just created for your domain. Click Go to Record Sets. Create a Record Set with the name as * , the type as CNAME - Canonical Name , and as an alias of the Load Balancer created from the router. Using nip.io \u00b6 If you do not have registered a domain name and just want to try out Workflow on AWS, we can use the nip.io wildcard DNS service to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Note this is not how you should connect to your cluster after the quickstart. This is for demonstration purposes only. Instead, you will want to use your own domain name routed to the ELB through your domain registrar. AWS actively manages the ELB IPv4 addresses, so what may be an IP address associated with your ELB today will be something else later on. First, pick one of the IP addresses allocated to your ELB: $ host abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 52.8.166.233 abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 54.193.5.73 Grab either address for the next step. We'll use 52.8.166.233 for this example. To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 52.8.166.233.nip.io . Nip answers with the ip address no matter the hostname: $ host 52.8.166.233.nip.io 52.8.166.233.nip.io has address 52.8.166.233 $ host something-random.52.8.166.233.nip.io something-random.52.8.166.233.nip.io has address 52.8.166.233 By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.52.8.166.233.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app . next: deploy your first app","title":"DNS"},{"location":"quickstart/provider/aws/dns/#find-your-load-balancer-hostname","text":"On EC2, Deis Workflow will automatically provision and attach an Elastic Load Balancer (ELB) to the Router . The Router is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow, as well as streaming TCP requests to the Builder . By describing the deis-router service, you can see what hostname allocated by AWS for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com","title":"Find Your Load Balancer Hostname"},{"location":"quickstart/provider/aws/dns/#prepare-the-hostname","text":"","title":"Prepare the Hostname"},{"location":"quickstart/provider/aws/dns/#using-dns","text":"Now that we have the hostname of the load balancer, let's create the wildcard DNS record that directs requests from your machine to the application. First, if you haven't already done so, register your domain name. The Internet Corporation for Assigned Names and Numbers (ICANN) manages domain names on the Internet. You register a domain name using a domain name registrar, an ICANN-accredited organization that manages the registry of domain names. The website for your registrar will provide detailed instructions and pricing information for registering your domain name. For more information, see the following resources: To use Amazon Route 53 to register a domain name, see Registering Domain Names Using Amazon Route 53 . For a list of accredited registrars, see the Accredited Registrar Directory . Next, use your DNS service, such as your domain registrar, to create a wildcard CNAME record to route queries to your load balancer. For more information, see the documentation for your DNS service. Alternatively, you can use Amazon Route 53 as your DNS service. You create a hosted zone, which contains information about how to route traffic on the Internet for your domain, and an alias resource record set, which routes queries for your domain name to your load balancer. To create a hosted zone and an alias record set for your domain using Amazon Route 53: Open the Amazon Route 53 console at https://console.aws.amazon.com/route53/. Create a Public Hosted Zone with your domain name. Select the hosted zone that you just created for your domain. Click Go to Record Sets. Create a Record Set with the name as * , the type as CNAME - Canonical Name , and as an alias of the Load Balancer created from the router.","title":"Using DNS"},{"location":"quickstart/provider/aws/dns/#using-nipio","text":"If you do not have registered a domain name and just want to try out Workflow on AWS, we can use the nip.io wildcard DNS service to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Note this is not how you should connect to your cluster after the quickstart. This is for demonstration purposes only. Instead, you will want to use your own domain name routed to the ELB through your domain registrar. AWS actively manages the ELB IPv4 addresses, so what may be an IP address associated with your ELB today will be something else later on. First, pick one of the IP addresses allocated to your ELB: $ host abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 52.8.166.233 abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com has address 54.193.5.73 Grab either address for the next step. We'll use 52.8.166.233 for this example. To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 52.8.166.233.nip.io . Nip answers with the ip address no matter the hostname: $ host 52.8.166.233.nip.io 52.8.166.233.nip.io has address 52.8.166.233 $ host something-random.52.8.166.233.nip.io something-random.52.8.166.233.nip.io has address 52.8.166.233 By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.52.8.166.233.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app . next: deploy your first app","title":"Using nip.io"},{"location":"quickstart/provider/aws/install-aws/","text":"Installing Deis Workflow on Amazon Web Services \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application. Configure your AWS Load Balancer \u00b6 After installing Workflow on your cluster, you will need to adjust your load balancer configuration. By default, the connection timeout for Elastic Load Blancers is 60 seconds. Unfortunately, this timeout is too short for long running connections when using git push functionality of Deis Workflow. Deis Workflow will automatically provision and attach a Elastic Loadbalancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. By describing the deis-router service, you can see what IP hostname has been allocated by AWS for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com The AWS name for the ELB is the first part of hostname, before the - . List all of your ELBs by name to confirm: $ aws elb describe-load-balancers --query 'LoadBalancerDescriptions[*].LoadBalancerName' abce0d48217d311e69a470643b4d9062 Set the connection timeout to 1200 seconds, make sure you use your load balancer name: $ aws elb modify-load-balancer-attributes \\ --load-balancer-name abce0d48217d311e69a470643b4d9062 \\ --load-balancer-attributes \"{\\\"ConnectionSettings\\\":{\\\"IdleTimeout\\\":1200}}\" abce0d48217d311e69a470643b4d9062 CONNECTIONSETTINGS 1200","title":"Install Workflow"},{"location":"quickstart/provider/aws/install-aws/#installing-deis-workflow-on-amazon-web-services","text":"","title":"Installing Deis Workflow on Amazon Web Services"},{"location":"quickstart/provider/aws/install-aws/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/aws/install-aws/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"quickstart/provider/aws/install-aws/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Deis Workflow"},{"location":"quickstart/provider/aws/install-aws/#configure-your-aws-load-balancer","text":"After installing Workflow on your cluster, you will need to adjust your load balancer configuration. By default, the connection timeout for Elastic Load Blancers is 60 seconds. Unfortunately, this timeout is too short for long running connections when using git push functionality of Deis Workflow. Deis Workflow will automatically provision and attach a Elastic Loadbalancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. By describing the deis-router service, you can see what IP hostname has been allocated by AWS for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | egrep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: abce0d48217d311e69a470643b4d9062-2074277678.us-west-1.elb.amazonaws.com The AWS name for the ELB is the first part of hostname, before the - . List all of your ELBs by name to confirm: $ aws elb describe-load-balancers --query 'LoadBalancerDescriptions[*].LoadBalancerName' abce0d48217d311e69a470643b4d9062 Set the connection timeout to 1200 seconds, make sure you use your load balancer name: $ aws elb modify-load-balancer-attributes \\ --load-balancer-name abce0d48217d311e69a470643b4d9062 \\ --load-balancer-attributes \"{\\\"ConnectionSettings\\\":{\\\"IdleTimeout\\\":1200}}\" abce0d48217d311e69a470643b4d9062 CONNECTIONSETTINGS 1200","title":"Configure your AWS Load Balancer"},{"location":"quickstart/provider/azure-acs/boot/","text":"Booting Kubernetes on Azure Container Service \u00b6 Azure Container Service (ACS) is an optimized container hosting solution that works with all the open source tools you know. Azure is great for Kubernetes and Deis Workflow. If you don't yet have a Microsoft Azure account, start a trial with $200 of free credit here . Prerequisites \u00b6 You should be able to run the az command, which is used to provision resources in the Azure cloud. Either install Azure CLI to your computer or open a Cloud Shell by clicking this icon near the upper right of the Azure Portal : You need an SSH key to deploy the Kubernetes cluster. For help, see Microsoft's documentation about creating SSH key pairs for Linux VMs on Azure. Configure the Azure CLI \u00b6 If you use Cloud Shell , the az client command is already configured. If you installed az locally, log in to your Azure account by typing az login at a command prompt and complete the confirmation code process. You can verify which account is active with the az account show command. Note Your Azure account needs ownership or contributor permissions on an Azure subscription. If the subscription has 2FA enabled, your Azure account must have ownership credentials in order to create the service principal. Create an ACS Kubernetes Cluster \u00b6 Azure Container Service can create a Kubernetes cluster using either the az command line or the Azure web portal . Option 1: Command Line \u00b6 Create a group to contain the ACS Kubernetes cluster resources. Export the resource group's name and location to environment variables for use by later commands: $ # list worldwide datacenter locations so we can pick one $ az account list-locations --query [].name --output tsv $ export AZURE_DC_LOCATION=southcentralus # for example $ export AZURE_RG_NAME=myresourcegroup $ az group create --name \"${AZURE_RG_NAME}\" --location \"${AZURE_DC_LOCATION}\" Run the az acs create command to create your Kubernetes cluster, replacing the --dns-prefix and --ssh-key-value arguments below with your values: $ export AZURE_SERVICE_NAME=myacs $ export AZURE_DNS_PREFIX=mydnsprefix $ az acs create --resource-group=\"${AZURE_RG_NAME}\" --location=\"${AZURE_DC_LOCATION}\" \\ --orchestrator-type=kubernetes --master-count=1 --agent-count=1 \\ --agent-vm-size=\"Standard_D2_v2\" \\ --admin-username=\"k8sadmin\" \\ --name=\"${AZURE_SERVICE_NAME}\" --dns-prefix=\"${AZURE_DNS_PREFIX}\" \\ --ssh-key-value @$HOME/.ssh/id_rsa.pub Azure Container Services immediately begins creating the Kubernetes cluster. After a few minutes, the command returns with information about the new deployment: { \"id\": \"/subscriptions/a123b456-1234-1ab2-12ab-12345678abcd/resourceGroups/myresourcegroup/providers/Microsoft.Resources/deployments/azurecli1496357873.8344654\", \"name\": \"azurecli1496357873.8344654\", \"properties\": { \"correlationId\": \"eae284bc-4380-484c-9302-f355e278c651\", \"debugSetting\": null, \"dependencies\": [], \"mode\": \"Incremental\", \"outputs\": null, ... }, \"resourceGroup\": \"myresourcegroup\" } Your Kubernetes cluster on Azure is ready. Skip the next section and connect to the ACS Kubernetes cluster . Option 2: Web Portal \u00b6 Sign in to the Azure Portal and create a new Azure Container Service. Click on the + New link, then the Compute link, then Azure Container Service . Select Resource Manager as the deployment model: Then click the Create button. Basics \u00b6 Provide these Basics for a new Azure Kubernetes cluster: Orchestrator: Kubernetes Subscription: choose the Azure subscription to be charged for cloud resources Resource group: \"Create new\" with a unique name Location: choose one of Azure's worldwide datacenters Then click the OK button to move on to Master configuration . Master configuration \u00b6 First take a slight detour to create a service principal to access resources. Then supply the Master configuration options for your Kubernetes cluster: DNS name prefix: the first section of the cluster's hostname User name: name of a unix user who will be added to all Kubernetes nodes SSH public Key: a public key to authenticate the unix user specified above Service principal client ID: the appId field of the service principal Service principal client secret: the password field of the service principal Master count: number of Kubernetes masters for the cluster When you are satisfied with your choices, click OK to move on to Agent Configuration . Agent configuration \u00b6 Choose Agent configuration options for your Kubernetes cluster: Agent count: number of Kubernetes nodes to create Agent virtual machine size: \"Standard DS2\" or better is recommended Operating system: Linux When you are satisfied with your choices, click OK to move on to Summary . Summary \u00b6 Confirm the Summary of configuration choices for your Kubernetes cluster: Click OK to tell Azure Container Services to start creating your new Kubernetes cluster. You can monitor the progress of the deployment on the Azure dashboard, or just wait for a notification that it has completed. Your Kubernetes cluster on Azure is ready. Now make sure you can connect to the ACS Kubernetes cluster . Connect to the ACS Kubernetes Cluster \u00b6 kubectl is the Kubernetes command line client. If you don't already have it installed, you can install it with: az acs kubernetes install-cli Download the master kubernetes cluster configuration to the ~/.kube/config file by running the following command: az acs kubernetes get-credentials --resource-group=$AZURE_RG_NAME --name=$AZURE_SERVICE_NAME Note: If the cluster was provisioned using any other SSH key than /home/myusername/.ssh/id_rsa then the --ssh-key-file parameter must be used pointing to the SSH key utilized to provision the cluster. Verify connectivity to the new ACS Kubernetes cluster by running kubectl cluster-info $ kubectl cluster-info Kubernetes master is running at https://mydnsprefix.myregion.cloudapp.azure.com Heapster is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard You are now ready to install Deis Workflow","title":"Boot"},{"location":"quickstart/provider/azure-acs/boot/#booting-kubernetes-on-azure-container-service","text":"Azure Container Service (ACS) is an optimized container hosting solution that works with all the open source tools you know. Azure is great for Kubernetes and Deis Workflow. If you don't yet have a Microsoft Azure account, start a trial with $200 of free credit here .","title":"Booting Kubernetes on Azure Container Service"},{"location":"quickstart/provider/azure-acs/boot/#prerequisites","text":"You should be able to run the az command, which is used to provision resources in the Azure cloud. Either install Azure CLI to your computer or open a Cloud Shell by clicking this icon near the upper right of the Azure Portal : You need an SSH key to deploy the Kubernetes cluster. For help, see Microsoft's documentation about creating SSH key pairs for Linux VMs on Azure.","title":"Prerequisites"},{"location":"quickstart/provider/azure-acs/boot/#configure-the-azure-cli","text":"If you use Cloud Shell , the az client command is already configured. If you installed az locally, log in to your Azure account by typing az login at a command prompt and complete the confirmation code process. You can verify which account is active with the az account show command. Note Your Azure account needs ownership or contributor permissions on an Azure subscription. If the subscription has 2FA enabled, your Azure account must have ownership credentials in order to create the service principal.","title":"Configure the Azure CLI"},{"location":"quickstart/provider/azure-acs/boot/#create-an-acs-kubernetes-cluster","text":"Azure Container Service can create a Kubernetes cluster using either the az command line or the Azure web portal .","title":"Create an ACS Kubernetes Cluster"},{"location":"quickstart/provider/azure-acs/boot/#option-1-command-line","text":"Create a group to contain the ACS Kubernetes cluster resources. Export the resource group's name and location to environment variables for use by later commands: $ # list worldwide datacenter locations so we can pick one $ az account list-locations --query [].name --output tsv $ export AZURE_DC_LOCATION=southcentralus # for example $ export AZURE_RG_NAME=myresourcegroup $ az group create --name \"${AZURE_RG_NAME}\" --location \"${AZURE_DC_LOCATION}\" Run the az acs create command to create your Kubernetes cluster, replacing the --dns-prefix and --ssh-key-value arguments below with your values: $ export AZURE_SERVICE_NAME=myacs $ export AZURE_DNS_PREFIX=mydnsprefix $ az acs create --resource-group=\"${AZURE_RG_NAME}\" --location=\"${AZURE_DC_LOCATION}\" \\ --orchestrator-type=kubernetes --master-count=1 --agent-count=1 \\ --agent-vm-size=\"Standard_D2_v2\" \\ --admin-username=\"k8sadmin\" \\ --name=\"${AZURE_SERVICE_NAME}\" --dns-prefix=\"${AZURE_DNS_PREFIX}\" \\ --ssh-key-value @$HOME/.ssh/id_rsa.pub Azure Container Services immediately begins creating the Kubernetes cluster. After a few minutes, the command returns with information about the new deployment: { \"id\": \"/subscriptions/a123b456-1234-1ab2-12ab-12345678abcd/resourceGroups/myresourcegroup/providers/Microsoft.Resources/deployments/azurecli1496357873.8344654\", \"name\": \"azurecli1496357873.8344654\", \"properties\": { \"correlationId\": \"eae284bc-4380-484c-9302-f355e278c651\", \"debugSetting\": null, \"dependencies\": [], \"mode\": \"Incremental\", \"outputs\": null, ... }, \"resourceGroup\": \"myresourcegroup\" } Your Kubernetes cluster on Azure is ready. Skip the next section and connect to the ACS Kubernetes cluster .","title":"Option 1: Command Line"},{"location":"quickstart/provider/azure-acs/boot/#option-2-web-portal","text":"Sign in to the Azure Portal and create a new Azure Container Service. Click on the + New link, then the Compute link, then Azure Container Service . Select Resource Manager as the deployment model: Then click the Create button.","title":"Option 2: Web Portal"},{"location":"quickstart/provider/azure-acs/boot/#basics","text":"Provide these Basics for a new Azure Kubernetes cluster: Orchestrator: Kubernetes Subscription: choose the Azure subscription to be charged for cloud resources Resource group: \"Create new\" with a unique name Location: choose one of Azure's worldwide datacenters Then click the OK button to move on to Master configuration .","title":"Basics"},{"location":"quickstart/provider/azure-acs/boot/#master-configuration","text":"First take a slight detour to create a service principal to access resources. Then supply the Master configuration options for your Kubernetes cluster: DNS name prefix: the first section of the cluster's hostname User name: name of a unix user who will be added to all Kubernetes nodes SSH public Key: a public key to authenticate the unix user specified above Service principal client ID: the appId field of the service principal Service principal client secret: the password field of the service principal Master count: number of Kubernetes masters for the cluster When you are satisfied with your choices, click OK to move on to Agent Configuration .","title":"Master configuration"},{"location":"quickstart/provider/azure-acs/boot/#agent-configuration","text":"Choose Agent configuration options for your Kubernetes cluster: Agent count: number of Kubernetes nodes to create Agent virtual machine size: \"Standard DS2\" or better is recommended Operating system: Linux When you are satisfied with your choices, click OK to move on to Summary .","title":"Agent configuration"},{"location":"quickstart/provider/azure-acs/boot/#summary","text":"Confirm the Summary of configuration choices for your Kubernetes cluster: Click OK to tell Azure Container Services to start creating your new Kubernetes cluster. You can monitor the progress of the deployment on the Azure dashboard, or just wait for a notification that it has completed. Your Kubernetes cluster on Azure is ready. Now make sure you can connect to the ACS Kubernetes cluster .","title":"Summary"},{"location":"quickstart/provider/azure-acs/boot/#connect-to-the-acs-kubernetes-cluster","text":"kubectl is the Kubernetes command line client. If you don't already have it installed, you can install it with: az acs kubernetes install-cli Download the master kubernetes cluster configuration to the ~/.kube/config file by running the following command: az acs kubernetes get-credentials --resource-group=$AZURE_RG_NAME --name=$AZURE_SERVICE_NAME Note: If the cluster was provisioned using any other SSH key than /home/myusername/.ssh/id_rsa then the --ssh-key-file parameter must be used pointing to the SSH key utilized to provision the cluster. Verify connectivity to the new ACS Kubernetes cluster by running kubectl cluster-info $ kubectl cluster-info Kubernetes master is running at https://mydnsprefix.myregion.cloudapp.azure.com Heapster is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://mydnsprefix.myregion.cloudapp.azure.com/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard You are now ready to install Deis Workflow","title":"Connect to the ACS Kubernetes Cluster"},{"location":"quickstart/provider/azure-acs/dns/","text":"Find the Load Balancer Address \u00b6 On Azure Container Engine, Deis Workflow will automatically provision and attach a Azure Load Balancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. Discover the ip address assigned to the deis-router , by describing the deis-router service: $ kubectl --namespace=deis get service deis-router NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE deis-router 10.0.60.172 13.82.148.57 80/TCP,443/TCP,2222/TCP,9090/TCP 54m If the EXTERNAL-IP column shows <pending> instead of an ip address continue to wait until Azure finishes provisioning and attaching the load balancer. Prepare the Hostname \u00b6 Now that an ip address has been attached to the load balancer use the nip.io DNS service to route arbitrary hostnames to the Deis Workflow edge router. Usage of nip.io is not recommended for long-term use and is intended here as a short cut to prevent fiddling with DNS. To verify connectivity to the Workflow API server and nip.io, construct the hostname by taking the ip address of load balancer and adding nip.io . For our example above, the address would be: 13.82.148.57.nip.io . Nip answers with the ip address no matter the hostname: $ host 13.82.148.57.nip.io 13.82.148.57.nip.io has address 13.82.148.57 $ host something-random.13.82.148.57.nip.io something-random.13.82.148.57.nip.io has address 13.82.148.57 By default, any HTTP traffic destined for the hostname deis is automatically sent to the Workflow API service. To test that everything is connected properly use curl : $ curl http://deis.13.82.148.57.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} Since no authentication information has been provided, curl will return an error. However this does validate that curl has reached the Workflow API service. Remember the hostname, it will used in the next step. You are now ready to register an admin user and deploy your first app .","title":"DNS"},{"location":"quickstart/provider/azure-acs/dns/#find-the-load-balancer-address","text":"On Azure Container Engine, Deis Workflow will automatically provision and attach a Azure Load Balancer to the router component. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. Discover the ip address assigned to the deis-router , by describing the deis-router service: $ kubectl --namespace=deis get service deis-router NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE deis-router 10.0.60.172 13.82.148.57 80/TCP,443/TCP,2222/TCP,9090/TCP 54m If the EXTERNAL-IP column shows <pending> instead of an ip address continue to wait until Azure finishes provisioning and attaching the load balancer.","title":"Find the Load Balancer Address"},{"location":"quickstart/provider/azure-acs/dns/#prepare-the-hostname","text":"Now that an ip address has been attached to the load balancer use the nip.io DNS service to route arbitrary hostnames to the Deis Workflow edge router. Usage of nip.io is not recommended for long-term use and is intended here as a short cut to prevent fiddling with DNS. To verify connectivity to the Workflow API server and nip.io, construct the hostname by taking the ip address of load balancer and adding nip.io . For our example above, the address would be: 13.82.148.57.nip.io . Nip answers with the ip address no matter the hostname: $ host 13.82.148.57.nip.io 13.82.148.57.nip.io has address 13.82.148.57 $ host something-random.13.82.148.57.nip.io something-random.13.82.148.57.nip.io has address 13.82.148.57 By default, any HTTP traffic destined for the hostname deis is automatically sent to the Workflow API service. To test that everything is connected properly use curl : $ curl http://deis.13.82.148.57.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} Since no authentication information has been provided, curl will return an error. However this does validate that curl has reached the Workflow API service. Remember the hostname, it will used in the next step. You are now ready to register an admin user and deploy your first app .","title":"Prepare the Hostname"},{"location":"quickstart/provider/azure-acs/install-azure-acs/","text":"Install Deis Workflow on Azure Container Service \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Finally, initialize Helm: helm init Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Create New Azure Storage Account \u00b6 It is recommended to use a dedicated storage account for the operational aspects of Workflow, which includes storing slug and container images, database backups, and disaster recovery. This storage account is passed as parameters during the helm install command in the next step. Replace the AZURE_SA_NAME variable with a unique name for your storage account and execute these commands. $ export AZURE_SA_NAME=YourGlobalUniqueName $ az storage account create -n $AZURE_SA_NAME -l $AZURE_DC_LOCATION -g $AZURE_RG_NAME --sku Standard_LRS $ export AZURE_SA_KEY=`az storage account keys list -n $AZURE_SA_NAME -g $AZURE_RG_NAME --query [0].value --output tsv` Note: Premium Storage skus are not supported yet due to lack of block blob storage support required for the deis database to function. Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace=deis --set global.storage=azure,azure.accountname=$AZURE_SA_NAME,azure.accountkey=$AZURE_SA_KEY,azure.registry_container=registry,azure.database_container=database,azure.builder_container=builder Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Workflow"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#install-deis-workflow-on-azure-container-service","text":"","title":"Install Deis Workflow on Azure Container Service"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Finally, initialize Helm: helm init Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#create-new-azure-storage-account","text":"It is recommended to use a dedicated storage account for the operational aspects of Workflow, which includes storing slug and container images, database backups, and disaster recovery. This storage account is passed as parameters during the helm install command in the next step. Replace the AZURE_SA_NAME variable with a unique name for your storage account and execute these commands. $ export AZURE_SA_NAME=YourGlobalUniqueName $ az storage account create -n $AZURE_SA_NAME -l $AZURE_DC_LOCATION -g $AZURE_RG_NAME --sku Standard_LRS $ export AZURE_SA_KEY=`az storage account keys list -n $AZURE_SA_NAME -g $AZURE_RG_NAME --query [0].value --output tsv` Note: Premium Storage skus are not supported yet due to lack of block blob storage support required for the deis database to function.","title":"Create New Azure Storage Account"},{"location":"quickstart/provider/azure-acs/install-azure-acs/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace=deis --set global.storage=azure,azure.accountname=$AZURE_SA_NAME,azure.accountkey=$AZURE_SA_KEY,azure.registry_container=registry,azure.database_container=database,azure.builder_container=builder Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Deis Workflow"},{"location":"quickstart/provider/gke/boot/","text":"Booting Kubernetes on Google Container Engine \u00b6 Google Container Engine (GKE) is a managed Kubernetes environment which is great for hosting Deis Workflow. Google Container Engine manages the Kubernetes master and you pay for the compute nodes. Clusters smaller than five nodes are charged only for the compute. Clusters six nodes are larger cost $0.15/hour per cluster. If you do not already have a Google Cloud account, you can start a trial with $300 of free credit here . After completing sign up, you must add your billing information. Create Your Google Cloud Project \u00b6 Sign in to your Google Cloud Platform Console and create a new project: Pick a project name. A project groups resources together and can hold more than one container cluster: Note the project ID. This is a unique name across all Google Cloud projects. Later, we will refer to this as PROJECT_ID . Next, enable billing in the console. Next, enable the Container Engine API and Compute Engine API . You must complete all three steps before continuing. Create Your GKE Cluster \u00b6 From the navigation hamburger in the upper left corner, find and select Container Engine : Select Create Container Cluster : For development and testing, we recommend you use the n1-standard-2 machine type which has 2 VCPUs and 7.5 GB of RAM per server, and a cluster size of at least 2: Click \"Create\" and Google Container Engine will provision your cluster. The process will take a few minutes to complete. Check Kubernetes version \u00b6 ] After the cluster is created, check the node version. See Kubernetes Versions under System Requirements for more details. Install and configure the Google Cloud CLI \u00b6 While your container cluster is booting. You will need to install the Google Cloud CLI tools. We will use the tools to fetch cluster credentials to authenitcate to your new Kubernetes cluster. Google maintains a number of quickstart guides which walk you through the installation. Once you have installed the CLI tooling set your default project and list your container clusters: $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER ascendant-yeti-130419 My First Cluster 614974141267 Set your default project: $ gcloud config set project ascendant-yeti-130419 Then list your container clusters: $ gcloud container clusters list NAME ZONE MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS cluster-1 us-central1-b 1.4.0 104.154.234.246 n1-standard-2 1.4.0 * 2 RUNNING If you haven't configured your default zone, make sure it matches the ZONE for your cluster: $ gcloud config set compute/zone us-central1-b Now you may fetch credentials to connect to Kubernetes: $ gcloud auth application-default login Your browser has been opened to visit: https://accounts.google.com/o/oauth2/auth?redirect_uri=.... Credentials saved to file: [~/.config/gcloud/application_default_credentials.json] These credentials will be used by any library that requests Application Default Credentials. If you don't have kubectl CLI setup just yet, run this to get it available locally: $ gcloud components install kubectl Your local kubectl utility should now be pointed at your new container cluster. You can verify your credentials and local configuration by running: $ kubectl cluster-info Kubernetes master is running at https://104.154.234.246 GLBCDefaultBackend is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/default-http-backend Heapster is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard If kubectl cluster-info returned with the following error: The connection to the server localhost:8080 was refused - did you specify the right host or port? You'll need to run: $ gcloud container clusters get-credentials To download the credentials necessary. The kubectl cluster-info command should then work as intended. You are now ready to install Deis Workflow","title":"Boot"},{"location":"quickstart/provider/gke/boot/#booting-kubernetes-on-google-container-engine","text":"Google Container Engine (GKE) is a managed Kubernetes environment which is great for hosting Deis Workflow. Google Container Engine manages the Kubernetes master and you pay for the compute nodes. Clusters smaller than five nodes are charged only for the compute. Clusters six nodes are larger cost $0.15/hour per cluster. If you do not already have a Google Cloud account, you can start a trial with $300 of free credit here . After completing sign up, you must add your billing information.","title":"Booting Kubernetes on Google Container Engine"},{"location":"quickstart/provider/gke/boot/#create-your-google-cloud-project","text":"Sign in to your Google Cloud Platform Console and create a new project: Pick a project name. A project groups resources together and can hold more than one container cluster: Note the project ID. This is a unique name across all Google Cloud projects. Later, we will refer to this as PROJECT_ID . Next, enable billing in the console. Next, enable the Container Engine API and Compute Engine API . You must complete all three steps before continuing.","title":"Create Your Google Cloud Project"},{"location":"quickstart/provider/gke/boot/#create-your-gke-cluster","text":"From the navigation hamburger in the upper left corner, find and select Container Engine : Select Create Container Cluster : For development and testing, we recommend you use the n1-standard-2 machine type which has 2 VCPUs and 7.5 GB of RAM per server, and a cluster size of at least 2: Click \"Create\" and Google Container Engine will provision your cluster. The process will take a few minutes to complete.","title":"Create Your GKE Cluster"},{"location":"quickstart/provider/gke/boot/#check-kubernetes-version","text":"] After the cluster is created, check the node version. See Kubernetes Versions under System Requirements for more details.","title":"Check Kubernetes version"},{"location":"quickstart/provider/gke/boot/#install-and-configure-the-google-cloud-cli","text":"While your container cluster is booting. You will need to install the Google Cloud CLI tools. We will use the tools to fetch cluster credentials to authenitcate to your new Kubernetes cluster. Google maintains a number of quickstart guides which walk you through the installation. Once you have installed the CLI tooling set your default project and list your container clusters: $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER ascendant-yeti-130419 My First Cluster 614974141267 Set your default project: $ gcloud config set project ascendant-yeti-130419 Then list your container clusters: $ gcloud container clusters list NAME ZONE MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS cluster-1 us-central1-b 1.4.0 104.154.234.246 n1-standard-2 1.4.0 * 2 RUNNING If you haven't configured your default zone, make sure it matches the ZONE for your cluster: $ gcloud config set compute/zone us-central1-b Now you may fetch credentials to connect to Kubernetes: $ gcloud auth application-default login Your browser has been opened to visit: https://accounts.google.com/o/oauth2/auth?redirect_uri=.... Credentials saved to file: [~/.config/gcloud/application_default_credentials.json] These credentials will be used by any library that requests Application Default Credentials. If you don't have kubectl CLI setup just yet, run this to get it available locally: $ gcloud components install kubectl Your local kubectl utility should now be pointed at your new container cluster. You can verify your credentials and local configuration by running: $ kubectl cluster-info Kubernetes master is running at https://104.154.234.246 GLBCDefaultBackend is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/default-http-backend Heapster is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/heapster KubeDNS is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://104.154.234.246/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard If kubectl cluster-info returned with the following error: The connection to the server localhost:8080 was refused - did you specify the right host or port? You'll need to run: $ gcloud container clusters get-credentials To download the credentials necessary. The kubectl cluster-info command should then work as intended. You are now ready to install Deis Workflow","title":"Install and configure the Google Cloud CLI"},{"location":"quickstart/provider/gke/dns/","text":"Find Your Load Balancer Address \u00b6 On Google Container Engine, Deis Workflow will automatically provision and attach a Google Cloud Loadbalancer to the router copmonent. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. By describing the deis-router service, you can see what IP address has been allocated by Google Cloud for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | grep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: 104.197.125.75 Prepare the Hostname \u00b6 Now that you have the ip address of your load balancer we can use the nip.io DNS service to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 104.197.125.75.nip.io . Nip answers with the ip address no matter the hostname: $ host 104.197.125.75.nip.io 104.197.125.75.nip.io has address 104.197.125.75 $ host something-random.104.197.125.75.nip.io something-random.104.197.125.75.nip.io has address 104.197.125.75 By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.104.197.125.75.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app .","title":"DNS"},{"location":"quickstart/provider/gke/dns/#find-your-load-balancer-address","text":"On Google Container Engine, Deis Workflow will automatically provision and attach a Google Cloud Loadbalancer to the router copmonent. This component is responsible for routing HTTP and HTTPS requests from the public internet to applications that are deployed and managed by Deis Workflow. By describing the deis-router service, you can see what IP address has been allocated by Google Cloud for your Deis Workflow cluster: $ kubectl --namespace=deis describe svc deis-router | grep LoadBalancer Type: LoadBalancer LoadBalancer Ingress: 104.197.125.75","title":"Find Your Load Balancer Address"},{"location":"quickstart/provider/gke/dns/#prepare-the-hostname","text":"Now that you have the ip address of your load balancer we can use the nip.io DNS service to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be: 104.197.125.75.nip.io . Nip answers with the ip address no matter the hostname: $ host 104.197.125.75.nip.io 104.197.125.75.nip.io has address 104.197.125.75 $ host something-random.104.197.125.75.nip.io something-random.104.197.125.75.nip.io has address 104.197.125.75 By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.104.197.125.75.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. You are now ready to register an admin user and deploy your first app .","title":"Prepare the Hostname"},{"location":"quickstart/provider/gke/install-gke/","text":"Install Deis Workflow on Google Compute Engine \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Workflow"},{"location":"quickstart/provider/gke/install-gke/#install-deis-workflow-on-google-compute-engine","text":"","title":"Install Deis Workflow on Google Compute Engine"},{"location":"quickstart/provider/gke/install-gke/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/gke/install-gke/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"quickstart/provider/gke/install-gke/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Deis Workflow"},{"location":"quickstart/provider/minikube/boot/","text":"Booting Kubernetes Using Minikube \u00b6 This guide will walk you through the process of installing a small development Kubernetes cluster on your local machine using minikube . Pre-requisites \u00b6 OS X xhyve driver , VirtualBox or VMware Fusion installation Linux VirtualBox or KVM installation Windows Hyper-V VT-x/AMD-v virtualization must be enabled in BIOS The most recent version of kubectl . You can install kubectl following these steps . Internet connection You will need a decent internet connection running minikube start for the first time for Minikube to pull its Docker images. It might take Minikube some time to start. Download and Unpack Minikube \u00b6 See the installation instructions for the latest release of minikube . Set your VM driver (optional) \u00b6 You can set your preferred driver (virtualbox - default, vmwarefusion, kvm, xhyve) using the following command: minikube config set vm-driver virtualbox Boot Your First Cluster \u00b6 We are now ready to boot our first Kubernetes cluster using Minikube! $ minikube start --disk-size=60g --memory=4096 Starting local Kubernetes cluster... Kubectl is now configured to use the cluster. Now that the cluster is up and ready, minikube automatically configures kubectl on your machine with the appropriate authentication and endpoint information. $ kubectl cluster-info Kubernetes master is running at https://192.168.99.100:8443 KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. You are now ready to install Deis Workflow","title":"Boot"},{"location":"quickstart/provider/minikube/boot/#booting-kubernetes-using-minikube","text":"This guide will walk you through the process of installing a small development Kubernetes cluster on your local machine using minikube .","title":"Booting Kubernetes Using Minikube"},{"location":"quickstart/provider/minikube/boot/#pre-requisites","text":"OS X xhyve driver , VirtualBox or VMware Fusion installation Linux VirtualBox or KVM installation Windows Hyper-V VT-x/AMD-v virtualization must be enabled in BIOS The most recent version of kubectl . You can install kubectl following these steps . Internet connection You will need a decent internet connection running minikube start for the first time for Minikube to pull its Docker images. It might take Minikube some time to start.","title":"Pre-requisites"},{"location":"quickstart/provider/minikube/boot/#download-and-unpack-minikube","text":"See the installation instructions for the latest release of minikube .","title":"Download and Unpack Minikube"},{"location":"quickstart/provider/minikube/boot/#set-your-vm-driver-optional","text":"You can set your preferred driver (virtualbox - default, vmwarefusion, kvm, xhyve) using the following command: minikube config set vm-driver virtualbox","title":"Set your VM driver (optional)"},{"location":"quickstart/provider/minikube/boot/#boot-your-first-cluster","text":"We are now ready to boot our first Kubernetes cluster using Minikube! $ minikube start --disk-size=60g --memory=4096 Starting local Kubernetes cluster... Kubectl is now configured to use the cluster. Now that the cluster is up and ready, minikube automatically configures kubectl on your machine with the appropriate authentication and endpoint information. $ kubectl cluster-info Kubernetes master is running at https://192.168.99.100:8443 KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. You are now ready to install Deis Workflow","title":"Boot Your First Cluster"},{"location":"quickstart/provider/minikube/dns/","text":"Find Your Load Balancer Address \u00b6 During installation, Deis Workflow specifies that Kubernetes should provision and attach a load balancer to the router component. The router component is responsible for routing HTTP and HTTPS requests from outside the cluster to applications that are managed by Deis Worfklow. In cloud environments, Kubernetes provisions and attaches a load balancer for you. Since we are running in a local environment, we need to do a little bit of extra work to send requests to the router. First, determine the ip address allocated to the worker node. $ minikube ip 192.168.99.100 Prepare the Hostname \u00b6 Now that you have the ip address of your virtual machine, we can use the nip.io DNS service or dnsmasq to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS! Using nip.io \u00b6 To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be 192.168.99.100 . Nip answers with the ip address no matter the hostname: $ host 192.168.99.100.nip.io 192.168.99.100.nip.io has address 192.168.99.100 $ host something-random.192.168.99.100.nip.io something-random.192.168.99.100.nip.io has address 192.168.99.100 Using DNSMasq \u00b6 If nip.io is working for you, you can skip this section, and proceed to verify the hostname. If you prefer not to use nip.io or cannot (because your DNS provider might have blocked it), you can use dnsmasq on Linux and macOS or Acrylic on Windows. You can install and configure dnsmasq on macOS with Homebrew with the following commands: # Installing dnsmasq $ brew install dnsmasq # Configure `.minikube` subdomains to always use minikube IP: $ echo \"address=/.minikube/`minikube ip`\" >> /usr/local/etc/dnsmasq.conf $ sudo brew services start dnsmasq # Make the system resolver use dnsmasq to resolve addresses: $ sudo mkdir /etc/resolver $ echo nameserver 127.0.0.1 | sudo tee /etc/resolver/minikube # You might need to clear the DNS resolver cache: $ sudo killall -HUP mDNSResponder You may need to ensure that the dnsmasq service at 127.0.0.1 is listed as a DNS server for your network connection. You may check this using the following command: $ scutil --dns | grep minikube -B 1 -A 3 resolver #8 domain : minikube nameserver[0] : 127.0.0.1 flags : Request A records, Request AAAA records reach : Reachable, Local Address, Directly Reachable Address To verify the hostname, you will need to use deis.minikube as hostname instead of deis.192.168.99.100.nip.io in the next section. We will also use it in the next step. Verify the hostname \u00b6 By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.192.168.99.100.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. next: deploy your first app","title":"DNS"},{"location":"quickstart/provider/minikube/dns/#find-your-load-balancer-address","text":"During installation, Deis Workflow specifies that Kubernetes should provision and attach a load balancer to the router component. The router component is responsible for routing HTTP and HTTPS requests from outside the cluster to applications that are managed by Deis Worfklow. In cloud environments, Kubernetes provisions and attaches a load balancer for you. Since we are running in a local environment, we need to do a little bit of extra work to send requests to the router. First, determine the ip address allocated to the worker node. $ minikube ip 192.168.99.100","title":"Find Your Load Balancer Address"},{"location":"quickstart/provider/minikube/dns/#prepare-the-hostname","text":"Now that you have the ip address of your virtual machine, we can use the nip.io DNS service or dnsmasq to route arbitrary hostnames to the Deis Workflow edge router. This lets us point the Workflow CLI at your cluster without having to either use your own domain or update DNS!","title":"Prepare the Hostname"},{"location":"quickstart/provider/minikube/dns/#using-nipio","text":"To verify the Workflow API server and nip.io, construct your hostname by taking the ip address for your load balancer and adding nip.io . For our example above, the address would be 192.168.99.100 . Nip answers with the ip address no matter the hostname: $ host 192.168.99.100.nip.io 192.168.99.100.nip.io has address 192.168.99.100 $ host something-random.192.168.99.100.nip.io something-random.192.168.99.100.nip.io has address 192.168.99.100","title":"Using nip.io"},{"location":"quickstart/provider/minikube/dns/#using-dnsmasq","text":"If nip.io is working for you, you can skip this section, and proceed to verify the hostname. If you prefer not to use nip.io or cannot (because your DNS provider might have blocked it), you can use dnsmasq on Linux and macOS or Acrylic on Windows. You can install and configure dnsmasq on macOS with Homebrew with the following commands: # Installing dnsmasq $ brew install dnsmasq # Configure `.minikube` subdomains to always use minikube IP: $ echo \"address=/.minikube/`minikube ip`\" >> /usr/local/etc/dnsmasq.conf $ sudo brew services start dnsmasq # Make the system resolver use dnsmasq to resolve addresses: $ sudo mkdir /etc/resolver $ echo nameserver 127.0.0.1 | sudo tee /etc/resolver/minikube # You might need to clear the DNS resolver cache: $ sudo killall -HUP mDNSResponder You may need to ensure that the dnsmasq service at 127.0.0.1 is listed as a DNS server for your network connection. You may check this using the following command: $ scutil --dns | grep minikube -B 1 -A 3 resolver #8 domain : minikube nameserver[0] : 127.0.0.1 flags : Request A records, Request AAAA records reach : Reachable, Local Address, Directly Reachable Address To verify the hostname, you will need to use deis.minikube as hostname instead of deis.192.168.99.100.nip.io in the next section. We will also use it in the next step.","title":"Using DNSMasq"},{"location":"quickstart/provider/minikube/dns/#verify-the-hostname","text":"By default, any HTTP traffic for the hostname deis will be sent to the Workflow API service. To test that everything is connected properly you may validate connectivity using curl : $ curl http://deis.192.168.99.100.nip.io/v2/ && echo {\"detail\":\"Authentication credentials were not provided.\"} You should see a failed request because we provided no credentials to the API server. Remember the hostname, we will use it in the next step. next: deploy your first app","title":"Verify the hostname"},{"location":"quickstart/provider/minikube/install-minikube/","text":"Install Deis Workflow on Minikube \u00b6 Check Your Setup \u00b6 First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster. Add the Deis Chart Repository \u00b6 The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow Install Deis Workflow \u00b6 Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis --set router.host_port.enabled=true Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Workflow"},{"location":"quickstart/provider/minikube/install-minikube/#install-deis-workflow-on-minikube","text":"","title":"Install Deis Workflow on Minikube"},{"location":"quickstart/provider/minikube/install-minikube/#check-your-setup","text":"First check that the helm command is available and the version is v2.5.0 or newer. $ helm version Client: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Server: &version.Version{SemVer:\"v2.5.0\", GitCommit:\"012cb0ac1a1b2f888144ef5a67b8dab6c2d45be6\", GitTreeState:\"clean\"} Ensure the kubectl client is installed and can connect to your Kubernetes cluster.","title":"Check Your Setup"},{"location":"quickstart/provider/minikube/install-minikube/#add-the-deis-chart-repository","text":"The Deis Chart Repository contains everything needed to install Deis Workflow onto a Kubernetes cluster, with a single helm install deis/workflow --namespace deis command. Add this repository to Helm: $ helm repo add deis https://charts.deis.com/workflow","title":"Add the Deis Chart Repository"},{"location":"quickstart/provider/minikube/install-minikube/#install-deis-workflow","text":"Now that Helm is installed and the repository has been added, install Workflow by running: $ helm install deis/workflow --namespace deis --set router.host_port.enabled=true Helm will install a variety of Kubernetes resources in the deis namespace. Wait for the pods that Helm launched to be ready. Monitor their status by running: $ kubectl --namespace=deis get pods If it's preferred to have kubectl automatically update as the pod states change, run (type Ctrl-C to stop the watch): $ kubectl --namespace=deis get pods -w Depending on the order in which the Workflow components initialize, some pods may restart. This is common during the installation: if a component's dependencies are not yet available, that component will exit and Kubernetes will automatically restart it. Here, it can be seen that the controller, builder and registry all took a few loops before they were able to start: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-hy3xv 1/1 Running 5 5m deis-controller-g3cu8 1/1 Running 5 5m deis-database-rad1o 1/1 Running 0 5m deis-logger-fluentd-1v8uk 1/1 Running 0 5m deis-logger-fluentd-esm60 1/1 Running 0 5m deis-logger-sm8b3 1/1 Running 0 5m deis-minio-4ww3t 1/1 Running 0 5m deis-registry-asozo 1/1 Running 1 5m deis-router-k1ond 1/1 Running 0 5m deis-workflow-manager-68nu6 1/1 Running 0 5m Once all of the pods are in the READY state, Deis Workflow is up and running! Next, configure dns so you can register your first user and deploy an application.","title":"Install Deis Workflow"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/","text":"Creating a Self-Signed SSL Certificate \u00b6 When using the app ssl feature for non-production applications or when installing SSL for the platform , you can avoid the costs associated with the SSL certificate by using a self-signed SSL certificate. Though the certificate implements full encryption, visitors to your site will see a browser warning indicating that the certificate should not be trusted. Prerequisites \u00b6 The openssl library is required to generate your own certificate. Run the following command in your local environment to see if you already have openssl installed. $ which openssl /usr/bin/openssl If the which command does not return a path then you will need to install openssl yourself: If you have... Install with... Mac OS X Homebrew: brew install openssl Windows complete package .exe installed Ubuntu Linux apt-get install openssl Generate Private Key and Certificate Signing Request \u00b6 A private key and certificate signing request are required to create an SSL certificate. These can be generated with a few simple commands. When the openssl req command asks for a \u201cchallenge password\u201d, just press return, leaving the password empty. $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 ... $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr ... Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:California ... A challenge password []: ... Generate SSL Certificate \u00b6 The self-signed SSL certificate is generated from the server.key private key and server.csr files. $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt The server.crt file is your site certificate suitable for use with Deis's SSL endpoint along with the server.key private key.","title":"Creating a Self-Signed SSL Certificate"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#creating-a-self-signed-ssl-certificate","text":"When using the app ssl feature for non-production applications or when installing SSL for the platform , you can avoid the costs associated with the SSL certificate by using a self-signed SSL certificate. Though the certificate implements full encryption, visitors to your site will see a browser warning indicating that the certificate should not be trusted.","title":"Creating a Self-Signed SSL Certificate"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#prerequisites","text":"The openssl library is required to generate your own certificate. Run the following command in your local environment to see if you already have openssl installed. $ which openssl /usr/bin/openssl If the which command does not return a path then you will need to install openssl yourself: If you have... Install with... Mac OS X Homebrew: brew install openssl Windows complete package .exe installed Ubuntu Linux apt-get install openssl","title":"Prerequisites"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#generate-private-key-and-certificate-signing-request","text":"A private key and certificate signing request are required to create an SSL certificate. These can be generated with a few simple commands. When the openssl req command asks for a \u201cchallenge password\u201d, just press return, leaving the password empty. $ openssl genrsa -des3 -passout pass:x -out server.pass.key 2048 ... $ openssl rsa -passin pass:x -in server.pass.key -out server.key writing RSA key $ rm server.pass.key $ openssl req -new -key server.key -out server.csr ... Country Name (2 letter code) [AU]:US State or Province Name (full name) [Some-State]:California ... A challenge password []: ...","title":"Generate Private Key and Certificate Signing Request"},{"location":"reference-guide/creating-a-self-signed-ssl-certificate/#generate-ssl-certificate","text":"The self-signed SSL certificate is generated from the server.key private key and server.csr files. $ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt The server.crt file is your site certificate suitable for use with Deis's SSL endpoint along with the server.key private key.","title":"Generate SSL Certificate"},{"location":"reference-guide/migration/","text":"Migrating from Deis v1 \u00b6 Workflow uses kubectl and helm to manage the cluster. These tools are equivalent to Deis v1's fleetctl and deisctl . These two tools are used for managing the cluster's state, installing the platform and inspecting its state. This document is a \"cheat sheet\" for users migrating from Deis v1 to Workflow (v2). It lists most of the known commands administrators would use with deisctl and translates their usage in Workflow. Listing all Components \u00b6 # Deis v1 $ deisctl list # Workflow $ kubectl --namespace=deis get deployments Listing all Nodes \u00b6 # Deis v1 $ fleetctl list-machines # Workflow $ kubectl get nodes Custom Configuration \u00b6 # Deis v1 $ deisctl config controller set registrationMode=admin_only # Workflow $ kubectl --namespace=deis patch deployment deis-controller -p '{\"spec\":{\"containers\":{\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"admin_only\"}]}}}' View Component Configuration \u00b6 # Deis v1 $ deisctl config router get bodySize # Workflow $ kubectl --namespace=deis get deployment deis-router -o yaml Running a Command Within a Component \u00b6 # Deis v1 $ deisctl dock router@1 # Workflow $ kubectl get po --namespace=deis -l app=deis-router --output=\"jsonpath={.items[0].metadata.name}\" deis-router-1930478716-iz6oq $ kubectl --namespace=deis exec -it deis-router-1930478716-iz6oq bash Follow the Logs for a Component \u00b6 # Deis v1 $ fleetctl journal -f deis-builder # Workflow $ kubectl get po --namespace=deis -l app=deis-builder --output=\"jsonpath={.items[0].metadata.name}\" deis-builder-1851090495-5n0sn $ kubectl --namespace=deis logs -f deis-builder-1851090495-5n0sn","title":"Migrating from Deis v1"},{"location":"reference-guide/migration/#migrating-from-deis-v1","text":"Workflow uses kubectl and helm to manage the cluster. These tools are equivalent to Deis v1's fleetctl and deisctl . These two tools are used for managing the cluster's state, installing the platform and inspecting its state. This document is a \"cheat sheet\" for users migrating from Deis v1 to Workflow (v2). It lists most of the known commands administrators would use with deisctl and translates their usage in Workflow.","title":"Migrating from Deis v1"},{"location":"reference-guide/migration/#listing-all-components","text":"# Deis v1 $ deisctl list # Workflow $ kubectl --namespace=deis get deployments","title":"Listing all Components"},{"location":"reference-guide/migration/#listing-all-nodes","text":"# Deis v1 $ fleetctl list-machines # Workflow $ kubectl get nodes","title":"Listing all Nodes"},{"location":"reference-guide/migration/#custom-configuration","text":"# Deis v1 $ deisctl config controller set registrationMode=admin_only # Workflow $ kubectl --namespace=deis patch deployment deis-controller -p '{\"spec\":{\"containers\":{\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"admin_only\"}]}}}'","title":"Custom Configuration"},{"location":"reference-guide/migration/#view-component-configuration","text":"# Deis v1 $ deisctl config router get bodySize # Workflow $ kubectl --namespace=deis get deployment deis-router -o yaml","title":"View Component Configuration"},{"location":"reference-guide/migration/#running-a-command-within-a-component","text":"# Deis v1 $ deisctl dock router@1 # Workflow $ kubectl get po --namespace=deis -l app=deis-router --output=\"jsonpath={.items[0].metadata.name}\" deis-router-1930478716-iz6oq $ kubectl --namespace=deis exec -it deis-router-1930478716-iz6oq bash","title":"Running a Command Within a Component"},{"location":"reference-guide/migration/#follow-the-logs-for-a-component","text":"# Deis v1 $ fleetctl journal -f deis-builder # Workflow $ kubectl get po --namespace=deis -l app=deis-builder --output=\"jsonpath={.items[0].metadata.name}\" deis-builder-1851090495-5n0sn $ kubectl --namespace=deis logs -f deis-builder-1851090495-5n0sn","title":"Follow the Logs for a Component"},{"location":"reference-guide/terms/","text":"Terms \u00b6 Application \u00b6 An application services requests and background jobs for a deployed git repository. Each application includes a set of Containers used to run isolated processes, and a Release that defines the current Build and Config deployed by containers. Build \u00b6 Deis builds are created automatically on the controller when a developer uses git push deis master . When a new build is created, a new Release is created automatically. Config \u00b6 Config refers to a set of environment variables used by Containers in as Application. When Config is changed, a new Release is created automatically. Container \u00b6 Deis containers are instances of Docker containers used to run Applications. Containers perform the actual work of an Application by servicing requests or by running background tasks as part of the cluster. Ephemeral Filesystem \u00b6 Each container gets its own ephemeral filesystem, with a fresh copy of the most recently deployed code. During the container\u2019s lifetime, its running processes can use the filesystem as a temporary scratchpad, but no files that are written are visible to processes in any other container. Any files written to the ephemeral filesystem will be discarded the moment the container is either stopped or restarted. Container States \u00b6 There are several states that a container can be in at any time. The states are: initialized - the state of the container before it is created created - the container is built and ready for operation up - the container is running down - the container crashed or is stopped destroyed - the container has been destroyed Controller \u00b6 The controller is the \"brain\" of the Deis platform. A controller manages Applications and their lifecycle. The controller is in charge of: Authenticating and authorizing clients Processing client API calls Managing containers that perform work for applications Managing proxies that route traffic to containers Managing users, keys and other base configuration The Controller stack includes: Django API Server for handling API calls Key \u00b6 Deis keys are SSH Keys used during the git push process. Each user can use the client to manage a list of keys on the Controller. Release \u00b6 A Deis release is a combination of a Build with a Config. Each Application is associated with one release at a time. Deis releases are numbered and new releases always increment by one (e.g. v1, v2, v3). Containers that host an application use these release versions to pull the correct code and configuration. Scheduler \u00b6 The Scheduler is responsible for creating, starting, stopping, and destroying Containers. For example, a command such as deis scale cmd=10 tells the Scheduler to run ten Containers from the Docker image for your Application. The Scheduler must decide which machines are eligible to run these container jobs. Scheduler backends vary in the details of their job allocation policies and whether or not they are resource-aware, among other features. The Deis scheduler client is implemented in the Controller component. Service \u00b6 A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. In Workflow, a Service is used to load-balance an application's Containers internally through a virtual IP address.","title":"Terms"},{"location":"reference-guide/terms/#terms","text":"","title":"Terms"},{"location":"reference-guide/terms/#application","text":"An application services requests and background jobs for a deployed git repository. Each application includes a set of Containers used to run isolated processes, and a Release that defines the current Build and Config deployed by containers.","title":"Application"},{"location":"reference-guide/terms/#build","text":"Deis builds are created automatically on the controller when a developer uses git push deis master . When a new build is created, a new Release is created automatically.","title":"Build"},{"location":"reference-guide/terms/#config","text":"Config refers to a set of environment variables used by Containers in as Application. When Config is changed, a new Release is created automatically.","title":"Config"},{"location":"reference-guide/terms/#container","text":"Deis containers are instances of Docker containers used to run Applications. Containers perform the actual work of an Application by servicing requests or by running background tasks as part of the cluster.","title":"Container"},{"location":"reference-guide/terms/#ephemeral-filesystem","text":"Each container gets its own ephemeral filesystem, with a fresh copy of the most recently deployed code. During the container\u2019s lifetime, its running processes can use the filesystem as a temporary scratchpad, but no files that are written are visible to processes in any other container. Any files written to the ephemeral filesystem will be discarded the moment the container is either stopped or restarted.","title":"Ephemeral Filesystem"},{"location":"reference-guide/terms/#container-states","text":"There are several states that a container can be in at any time. The states are: initialized - the state of the container before it is created created - the container is built and ready for operation up - the container is running down - the container crashed or is stopped destroyed - the container has been destroyed","title":"Container States"},{"location":"reference-guide/terms/#controller","text":"The controller is the \"brain\" of the Deis platform. A controller manages Applications and their lifecycle. The controller is in charge of: Authenticating and authorizing clients Processing client API calls Managing containers that perform work for applications Managing proxies that route traffic to containers Managing users, keys and other base configuration The Controller stack includes: Django API Server for handling API calls","title":"Controller"},{"location":"reference-guide/terms/#key","text":"Deis keys are SSH Keys used during the git push process. Each user can use the client to manage a list of keys on the Controller.","title":"Key"},{"location":"reference-guide/terms/#release","text":"A Deis release is a combination of a Build with a Config. Each Application is associated with one release at a time. Deis releases are numbered and new releases always increment by one (e.g. v1, v2, v3). Containers that host an application use these release versions to pull the correct code and configuration.","title":"Release"},{"location":"reference-guide/terms/#scheduler","text":"The Scheduler is responsible for creating, starting, stopping, and destroying Containers. For example, a command such as deis scale cmd=10 tells the Scheduler to run ten Containers from the Docker image for your Application. The Scheduler must decide which machines are eligible to run these container jobs. Scheduler backends vary in the details of their job allocation policies and whether or not they are resource-aware, among other features. The Deis scheduler client is implemented in the Controller component.","title":"Scheduler"},{"location":"reference-guide/terms/#service","text":"A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. In Workflow, a Service is used to load-balance an application's Containers internally through a virtual IP address.","title":"Service"},{"location":"reference-guide/controller-api/v2.0/","text":"Controller API v2.0 \u00b6 This is the v2.0 REST API for the Controller. What's New \u00b6 New! format of POST /v2/apps/<app id>/run has changed. Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 3 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 4 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 4 { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.0"},{"location":"reference-guide/controller-api/v2.0/#controller-api-v20","text":"This is the v2.0 REST API for the Controller.","title":"Controller API v2.0"},{"location":"reference-guide/controller-api/v2.0/#whats-new","text":"New! format of POST /v2/apps/<app id>/run has changed.","title":"What's New"},{"location":"reference-guide/controller-api/v2.0/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.0/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.0/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.0/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.0/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.0/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.0/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.0/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.0/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.0/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.0/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.0/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.0/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.0/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.0/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.0/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.0/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.0/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.0/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.0/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.0/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.0/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.0/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.0/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.0/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.0/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.0/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.0/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.0/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.0/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.0/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 3 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.0/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 4 { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.0/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.0/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.0/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.0/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.0/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.0/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.0/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json X-Deis-Release: 4 { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.0/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.0/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.0/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.0/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.0/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.0/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.0/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.0/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.0/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.0/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.0/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.0/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.0/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.0/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.0/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.0/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.0/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.0 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.1/","text":"Controller API v2.1 \u00b6 This is the v2.1 REST API for the Controller. What's New \u00b6 New! healthcheck field in configuration, deprecates the HEALTHCHECK_* environment variables. New! Unsetting a configuration variable that does not exist will return a 422. New! Creating an identical sequential release returns a 409 rather than create a no-op release. Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.1"},{"location":"reference-guide/controller-api/v2.1/#controller-api-v21","text":"This is the v2.1 REST API for the Controller.","title":"Controller API v2.1"},{"location":"reference-guide/controller-api/v2.1/#whats-new","text":"New! healthcheck field in configuration, deprecates the HEALTHCHECK_* environment variables. New! Unsetting a configuration variable that does not exist will return a 422. New! Creating an identical sequential release returns a 409 rather than create a no-op release.","title":"What's New"},{"location":"reference-guide/controller-api/v2.1/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.1/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.1/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.1/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.1/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.1/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.1/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.1/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.1/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.1/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.1/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.1/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.1/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.1/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.1/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.1/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.1/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.1/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.1/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.1/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.1/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.1/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.1/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.1/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.1/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.1/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.1/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.1/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.1/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.1/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.1/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.1/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.1/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.1/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.1/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.1/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.1/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.1/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.1/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.1/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.1/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.1/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.1/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.1/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.1/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.1/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.1/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.1/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.1/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.1/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.1/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.1/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.1/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.1/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.1/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.1/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.1 DEIS_PLATFORM_VERSION: 2.1.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.2/","text":"Controller API v2.2 \u00b6 This is the v2.2 REST API for the Controller. What's New \u00b6 New! /v2/auth/whoami endpoint Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Who Am I \u00b6 Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.2"},{"location":"reference-guide/controller-api/v2.2/#controller-api-v22","text":"This is the v2.2 REST API for the Controller.","title":"Controller API v2.2"},{"location":"reference-guide/controller-api/v2.2/#whats-new","text":"New! /v2/auth/whoami endpoint","title":"What's New"},{"location":"reference-guide/controller-api/v2.2/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.2/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.2/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.2/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.2/#who-am-i","text":"Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Who Am I"},{"location":"reference-guide/controller-api/v2.2/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.2/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.2/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.2/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.2/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.2/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.2/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.2/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.2/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.2/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.2/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.2/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.2/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.2/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22T22:24:20Z\", \"updated\": \"2016-06-22T22:24:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.2/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.2/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.2/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.2/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.2/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.2/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.2/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.2/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.2/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.2/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.2/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.2/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.2/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.2/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.2/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.2/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.2/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.2/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.2/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.2/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.2/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.2/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.2/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"202d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.2/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.2/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.2/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.2/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.2/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.2/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.2/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.2/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.2/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.2/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.2/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.2/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.2/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.2/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.2/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.2 DEIS_PLATFORM_VERSION: 2.2.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"reference-guide/controller-api/v2.3/","text":"Controller API v2.3 \u00b6 This is the v2.3 REST API for the Controller. What's New \u00b6 New! /v2/apps/{name}/logs endpoint was fixed and no longer returns b'log data' and instead returns a normal string log data Authentication \u00b6 Register a New User \u00b6 Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Log in \u00b6 Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"} Cancel Account \u00b6 Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Who Am I \u00b6 Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } Regenerate Token \u00b6 note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"} Change Password \u00b6 Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Applications \u00b6 List all Applications \u00b6 Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create an Application \u00b6 Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Destroy an Application \u00b6 Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 List Application Details \u00b6 Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Update Application Details \u00b6 Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json Retrieve Application Logs \u00b6 Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\" Run one-off Commands \u00b6 POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"} Certificates \u00b6 List all Certificates \u00b6 Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] } Get Certificate Details \u00b6 Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Create Certificate \u00b6 Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } Destroy a Certificate \u00b6 Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Attach a Domain to a Certificate \u00b6 Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Remove a Domain from a Certificate \u00b6 Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Enable or disable TLS \u00b6 Example Request: POST /v2/apps/example-go/tls/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"https_enforced\": true } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": true, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Get TLS status \u00b6 Example Request: GET /v2/apps/example-go/tls/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": false, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Pods \u00b6 List all Pods \u00b6 Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } List all Pods by Type \u00b6 Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] } Restart All Pods \u00b6 Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type \u00b6 Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Restart Pods by Type and Name \u00b6 Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ] Scale Pods \u00b6 Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Configuration \u00b6 List Application Configuration \u00b6 Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Create new Config \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Unset Config Variable \u00b6 Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Domains \u00b6 List Application Domains \u00b6 Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] } Add Domain \u00b6 Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } Remove Domain \u00b6 Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Builds \u00b6 List Application Builds \u00b6 Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Create Application Build \u00b6 Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Releases \u00b6 List Application Releases \u00b6 Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] } List Release Details \u00b6 Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } Rollback Release \u00b6 Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"version\": 5} Keys \u00b6 List Keys \u00b6 Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] } Add Key to User \u00b6 Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } Remove Key from User \u00b6 Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Permissions \u00b6 List Application Permissions \u00b6 note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] } Create Application Permission \u00b6 Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Remove Application Permission \u00b6 Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 List Administrators \u00b6 Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] } Grant User Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Remove User's Administrative Privileges \u00b6 note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Users \u00b6 List all users \u00b6 note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"Controller API v2.3"},{"location":"reference-guide/controller-api/v2.3/#controller-api-v23","text":"This is the v2.3 REST API for the Controller.","title":"Controller API v2.3"},{"location":"reference-guide/controller-api/v2.3/#whats-new","text":"New! /v2/apps/{name}/logs endpoint was fixed and no longer returns b'log data' and instead returns a normal string log data","title":"What's New"},{"location":"reference-guide/controller-api/v2.3/#authentication","text":"","title":"Authentication"},{"location":"reference-guide/controller-api/v2.3/#register-a-new-user","text":"Example Request: POST /v2/auth/register/ HTTP/1.1 Host: deis.example.com Content-Type: application/json { \"username\": \"test\", \"password\": \"opensesame\", \"email\": \"test@example.com\" } Optional Parameters: { \"first_name\": \"test\", \"last_name\": \"testerson\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Register a New User"},{"location":"reference-guide/controller-api/v2.3/#log-in","text":"Example Request: POST /v2/auth/login/ HTTP/1.1 Host: deis.example.com Content-Type: application/json {\"username\": \"test\", \"password\": \"opensesame\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Log in"},{"location":"reference-guide/controller-api/v2.3/#cancel-account","text":"Example Request: DELETE /v2/auth/cancel/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Cancel Account"},{"location":"reference-guide/controller-api/v2.3/#who-am-i","text":"Example Request: GET /v2/auth/whoami/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] }","title":"Who Am I"},{"location":"reference-guide/controller-api/v2.3/#regenerate-token","text":"note This command could require administrative privileges Example Request: POST /v2/auth/tokens/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional Parameters: { \"username\" : \"test\" \"all\" : \"true\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"token\": \"abc123\"}","title":"Regenerate Token"},{"location":"reference-guide/controller-api/v2.3/#change-password","text":"Example Request: POST /v2/auth/passwd/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"password\": \"foo\", \"new_password\": \"bar\" } Optional parameters: {\"username\": \"testuser\"} note Using the username parameter requires administrative privileges and makes the password parameter optional. Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Change Password"},{"location":"reference-guide/controller-api/v2.3/#applications","text":"","title":"Applications"},{"location":"reference-guide/controller-api/v2.3/#list-all-applications","text":"Example Request: GET /v2/apps HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List all Applications"},{"location":"reference-guide/controller-api/v2.3/#create-an-application","text":"Example Request: POST /v2/apps/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 Optional parameters: {\"id\": \"example-go\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create an Application"},{"location":"reference-guide/controller-api/v2.3/#destroy-an-application","text":"Example Request: DELETE /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Destroy an Application"},{"location":"reference-guide/controller-api/v2.3/#list-application-details","text":"Example Request: GET /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example-go\", \"owner\": \"test\", \"structure\": {}, \"updated\": \"2014-01-01T00:00:00UTC\", \"url\": \"example-go.example.com\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Details"},{"location":"reference-guide/controller-api/v2.3/#update-application-details","text":"Example Request: POST /v2/apps/example-go/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional parameters: { \"owner\": \"test\" } Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 1.8.0 Content-Type: application/json","title":"Update Application Details"},{"location":"reference-guide/controller-api/v2.3/#retrieve-application-logs","text":"Example Request: GET /v2/apps/example-go/logs/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Optional URL Query Parameters: ?log_lines= Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: text/plain \"16:51:14 deis[api]: test created initial release\\n\"","title":"Retrieve Application Logs"},{"location":"reference-guide/controller-api/v2.3/#run-one-off-commands","text":"POST /v2/apps/example-go/run/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"command\": \"echo hi\"} Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"exit_code\": 0, \"output\": \"hi\\n\"}","title":"Run one-off Commands"},{"location":"reference-guide/controller-api/v2.3/#certificates","text":"","title":"Certificates"},{"location":"reference-guide/controller-api/v2.3/#list-all-certificates","text":"Example Request: GET /v2/certs HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" } ] }","title":"List all Certificates"},{"location":"reference-guide/controller-api/v2.3/#get-certificate-details","text":"Example Request: GET /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Get Certificate Details"},{"location":"reference-guide/controller-api/v2.3/#create-certificate","text":"Example Request: POST /v2/certs/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"name\": \"foo\" \"certificate\": \"-----BEGIN CERTIFICATE-----\", \"key\": \"-----BEGIN RSA PRIVATE KEY-----\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"id\": 22, \"owner\": \"test\", \"san\": [], \"domains\": [], \"created\": \"2016-06-22.32.34:20Z\", \"updated\": \"2016-06-22.32.34:20Z\", \"name\": \"foo\", \"common_name\": \"bar.com\", \"fingerprint\": \"7A:CA:B8:50:FF:8D:EB:03:3D:AC:AD:13:4F:EE:03:D5:5D:EB:5E:37:51:8C:E0:98:F8:1B:36:2B:20:83:0D:C0\", \"expires\": \"2017-01-14T23:57:57Z\", \"starts\": \"2016-01-15T23:57:57Z\", \"issuer\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\", \"subject\": \"/C=US/ST=CA/L=San Francisco/O=Deis/OU=Engineering/CN=bar.com/emailAddress=engineering@deis.com\" }","title":"Create Certificate"},{"location":"reference-guide/controller-api/v2.3/#destroy-a-certificate","text":"Example Request: DELETE /v2/certs/foo HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Destroy a Certificate"},{"location":"reference-guide/controller-api/v2.3/#attach-a-domain-to-a-certificate","text":"Example Request: POST /v2/certs/foo/domain/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"domain\": \"test.com\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Attach a Domain to a Certificate"},{"location":"reference-guide/controller-api/v2.3/#remove-a-domain-from-a-certificate","text":"Example Request: DELETE /v2/certs/foo/domain/test.com/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Remove a Domain from a Certificate"},{"location":"reference-guide/controller-api/v2.3/#enable-or-disable-tls","text":"Example Request: POST /v2/apps/example-go/tls/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 { \"https_enforced\": true } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": true, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Enable or disable TLS"},{"location":"reference-guide/controller-api/v2.3/#get-tls-status","text":"Example Request: GET /v2/apps/example-go/tls/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"app\": \"example-go\", \"owner\": \"test\", \"https_enforced\": false, \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Get TLS status"},{"location":"reference-guide/controller-api/v2.3/#pods","text":"","title":"Pods"},{"location":"reference-guide/controller-api/v2.3/#list-all-pods","text":"Example Request: GET /v2/apps/example-go/pods/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods"},{"location":"reference-guide/controller-api/v2.3/#list-all-pods-by-type","text":"Example Request: GET /v2/apps/example-go/pods/web/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"results\": [ { \"name\": \"go-v2-web-e7dej\", \"release\": \"v2\", \"started\": \"2014-01-01T00:00:00Z\", \"state\": \"up\", \"type\": \"web\" } ] }","title":"List all Pods by Type"},{"location":"reference-guide/controller-api/v2.3/#restart-all-pods","text":"Example Request: POST /v2/apps/example-go/pods/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart All Pods"},{"location":"reference-guide/controller-api/v2.3/#restart-pods-by-type","text":"Example Request: POST /v2/apps/example-go/pods/web/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type"},{"location":"reference-guide/controller-api/v2.3/#restart-pods-by-type-and-name","text":"Example Request: POST /v2/apps/example-go/pods/go-v2-web-atots/restart/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json [ { \"name\": \"go-v2-web-atots\", \"release\": \"v2\", \"started\": \"2016-04-11T21:07:54Z\", \"state\": \"up\", \"type\": \"web\" } ]","title":"Restart Pods by Type and Name"},{"location":"reference-guide/controller-api/v2.3/#scale-pods","text":"Example Request: POST /v2/apps/example-go/scale/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"web\": 3} Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Scale Pods"},{"location":"reference-guide/controller-api/v2.3/#configuration","text":"","title":"Configuration"},{"location":"reference-guide/controller-api/v2.3/#list-application-configuration","text":"Example Request: GET /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"List Application Configuration"},{"location":"reference-guide/controller-api/v2.3/#create-new-config","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": \"world\", \"PLATFORM\": \"deis\"}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v3\", \"HELLO\": \"world\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create new Config"},{"location":"reference-guide/controller-api/v2.3/#unset-config-variable","text":"Example Request: POST /v2/apps/example-go/config/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"values\": {\"HELLO\": null}} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"owner\": \"test\", \"app\": \"example-go\", \"values\": { \"DEIS_APP\": \"example-go\", \"DEIS_RELEASE\": \"v4\", \"PLATFORM\": \"deis\" }, \"memory\": {}, \"cpu\": {}, \"tags\": {}, \"healthcheck\": {}, \"created\": \"2014-01-01T00:00:00UTC\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Unset Config Variable"},{"location":"reference-guide/controller-api/v2.3/#domains","text":"","title":"Domains"},{"location":"reference-guide/controller-api/v2.3/#list-application-domains","text":"Example Request: GET /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" } ] }","title":"List Application Domains"},{"location":"reference-guide/controller-api/v2.3/#add-domain","text":"Example Request: POST /v2/apps/example-go/domains/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {'domain': 'example.example.com'} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"domain\": \"example.example.com\", \"owner\": \"test\", \"updated\": \"2014-01-01T00:00:00UTC\" }","title":"Add Domain"},{"location":"reference-guide/controller-api/v2.3/#remove-domain","text":"Example Request: DELETE /v2/apps/example-go/domains/example.example.com HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Remove Domain"},{"location":"reference-guide/controller-api/v2.3/#builds","text":"","title":"Builds"},{"location":"reference-guide/controller-api/v2.3/#list-application-builds","text":"Example Request: GET /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"FROM deis/slugrunner RUN mkdir -p /app WORKDIR /app ENTRYPOINT [\\\"/runner/init\\\"] ADD slug.tgz /app ENV GIT_SHA 060da68f654e75fac06dbedd1995d5f8ad9084db\", \"image\": \"example-go\", \"owner\": \"test\", \"procfile\": { \"web\": \"example-go\" }, \"sha\": \"060da68f\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Application Builds"},{"location":"reference-guide/controller-api/v2.3/#create-application-build","text":"Example Request: POST /v2/apps/example-go/builds/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"image\": \"deis/example-go:latest\"} Optional Parameters: { \"procfile\": { \"web\": \"./cmd\" } } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"created\": \"2014-01-01T00:00:00UTC\", \"dockerfile\": \"\", \"image\": \"deis/example-go:latest\", \"owner\": \"test\", \"procfile\": {}, \"sha\": \"\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Create Application Build"},{"location":"reference-guide/controller-api/v2.3/#releases","text":"","title":"Releases"},{"location":"reference-guide/controller-api/v2.3/#list-application-releases","text":"Example Request: GET /v2/apps/example-go/releases/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"ed637ceb-5d32-44bd-9406-d326a777a513\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test changed nothing\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 3 }, { \"app\": \"example-go\", \"build\": \"2.3d8e4b-600e-4425-a85c-ffc7ea607f61\", \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test deployed 060da68\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 2 }, { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 } ] }","title":"List Application Releases"},{"location":"reference-guide/controller-api/v2.3/#list-release-details","text":"Example Request: GET /v2/apps/example-go/releases/v2/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"app\": \"example-go\", \"build\": null, \"config\": \"95bd6dea-1685-4f78-a03d-fd7270b058d1\", \"created\": \"2014-01-01T00:00:00UTC\", \"owner\": \"test\", \"summary\": \"test created initial release\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\", \"version\": 1 }","title":"List Release Details"},{"location":"reference-guide/controller-api/v2.3/#rollback-release","text":"Example Request: POST /v2/apps/example-go/releases/rollback/ HTTP/1.1 Host: deis.example.com Content-Type: application/json Authorization: token abc123 {\"version\": 1} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json {\"version\": 5}","title":"Rollback Release"},{"location":"reference-guide/controller-api/v2.3/#keys","text":"","title":"Keys"},{"location":"reference-guide/controller-api/v2.3/#list-keys","text":"Example Request: GET /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"test@example.com\", \"owner\": \"test\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" } ] }","title":"List Keys"},{"location":"reference-guide/controller-api/v2.3/#add-key-to-user","text":"Example Request: POST /v2/keys/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 { \"id\": \"example\", \"public\": \"ssh-rsa <...>\" } Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"created\": \"2014-01-01T00:00:00UTC\", \"id\": \"example\", \"owner\": \"example\", \"public\": \"ssh-rsa <...>\", \"updated\": \"2014-01-01T00:00:00UTC\", \"uuid\": \"de1bf5b5-4a72-4f94-a10c-d2a3741cdf75\" }","title":"Add Key to User"},{"location":"reference-guide/controller-api/v2.3/#remove-key-from-user","text":"Example Request: DELETE /v2/keys/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Remove Key from User"},{"location":"reference-guide/controller-api/v2.3/#permissions","text":"","title":"Permissions"},{"location":"reference-guide/controller-api/v2.3/#list-application-permissions","text":"note This does not include the app owner. Example Request: GET /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"users\": [ \"test\", \"foo\" ] }","title":"List Application Permissions"},{"location":"reference-guide/controller-api/v2.3/#create-application-permission","text":"Example Request: POST /v2/apps/example-go/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Create Application Permission"},{"location":"reference-guide/controller-api/v2.3/#remove-application-permission","text":"Example Request: DELETE /v2/apps/example-go/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Remove Application Permission"},{"location":"reference-guide/controller-api/v2.3/#list-administrators","text":"Example Request: GET /v2/admin/perms/ HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 2, \"next\": null \"previous\": null, \"results\": [ { \"username\": \"test\", \"is_superuser\": true }, { \"username\": \"foo\", \"is_superuser\": true } ] }","title":"List Administrators"},{"location":"reference-guide/controller-api/v2.3/#grant-user-administrative-privileges","text":"note This command requires administrative privileges Example Request: POST /v2/admin/perms HTTP/1.1 Host: deis.example.com Authorization: token abc123 {\"username\": \"example\"} Example Response: HTTP/1.1 201 CREATED DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Grant User Administrative Privileges"},{"location":"reference-guide/controller-api/v2.3/#remove-users-administrative-privileges","text":"note This command requires administrative privileges Example Request: DELETE /v2/admin/perms/example HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 204 NO CONTENT DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0","title":"Remove User's Administrative Privileges"},{"location":"reference-guide/controller-api/v2.3/#users","text":"","title":"Users"},{"location":"reference-guide/controller-api/v2.3/#list-all-users","text":"note This command requires administrative privileges Example Request: GET /v2/users HTTP/1.1 Host: deis.example.com Authorization: token abc123 Example Response: HTTP/1.1 200 OK DEIS_API_VERSION: 2.3 DEIS_PLATFORM_VERSION: 2.3.0 Content-Type: application/json { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": 1, \"last_login\": \"2014-10-19T22:01:00.601Z\", \"is_superuser\": true, \"username\": \"test\", \"first_name\": \"test\", \"last_name\": \"testerson\", \"email\": \"test@example.com\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2014-10-19T22:01:00.601Z\", \"groups\": [], \"user_permissions\": [] } ] }","title":"List all users"},{"location":"roadmap/planning-process/","text":"Planning Process \u00b6 Deis features a lightweight process that emphasizes openness and ensures every community member can be an integral part of planning for the future. The Role of Maintainers \u00b6 Maintainers lead the Deis projects. Their duties include proposing the Roadmap, reviewing and integrating contributions and maintaining the vision of the project. Open Roadmap \u00b6 The Deis Roadmap is a community document. While Maintainers propose the Roadmap, it gets discussed and refined in Release Planning Meetings. Contributing to the Roadmap \u00b6 Proposals and issues can be opened by anyone. Every member of the community is welcome to participate in the discussion by providing feedback and/or offering counter-proposals. Release Milestones \u00b6 The Roadmap gets delivered progressively via the Release Schedule . Releases are defined during Release Planning Meetings and managed using GitHub Milestones which track specific deliverables and work-in-progress. Release Planning Meetings \u00b6 Major decisions affecting the Roadmap are discussed during Release Planning Meetings on the first Thursday of each month, aligned with the Release Schedule . Release Planning Meetings are open to the public with access coordinated via the Deis #community Slack channel . Notes from past meetings are below, along with links to a recording of the entire meeting on YouTube. Credits \u00b6 Thanks to Amy Lindburg and our friends at Docker for their inspiration.","title":"Planning Process"},{"location":"roadmap/planning-process/#planning-process","text":"Deis features a lightweight process that emphasizes openness and ensures every community member can be an integral part of planning for the future.","title":"Planning Process"},{"location":"roadmap/planning-process/#the-role-of-maintainers","text":"Maintainers lead the Deis projects. Their duties include proposing the Roadmap, reviewing and integrating contributions and maintaining the vision of the project.","title":"The Role of Maintainers"},{"location":"roadmap/planning-process/#open-roadmap","text":"The Deis Roadmap is a community document. While Maintainers propose the Roadmap, it gets discussed and refined in Release Planning Meetings.","title":"Open Roadmap"},{"location":"roadmap/planning-process/#contributing-to-the-roadmap","text":"Proposals and issues can be opened by anyone. Every member of the community is welcome to participate in the discussion by providing feedback and/or offering counter-proposals.","title":"Contributing to the Roadmap"},{"location":"roadmap/planning-process/#release-milestones","text":"The Roadmap gets delivered progressively via the Release Schedule . Releases are defined during Release Planning Meetings and managed using GitHub Milestones which track specific deliverables and work-in-progress.","title":"Release Milestones"},{"location":"roadmap/planning-process/#release-planning-meetings","text":"Major decisions affecting the Roadmap are discussed during Release Planning Meetings on the first Thursday of each month, aligned with the Release Schedule . Release Planning Meetings are open to the public with access coordinated via the Deis #community Slack channel . Notes from past meetings are below, along with links to a recording of the entire meeting on YouTube.","title":"Release Planning Meetings"},{"location":"roadmap/planning-process/#credits","text":"Thanks to Amy Lindburg and our friends at Docker for their inspiration.","title":"Credits"},{"location":"roadmap/releases/","text":"Releases \u00b6 Deis uses a continuous delivery approach for creating releases. Every merged commit that passes testing results in a deliverable that can be given a semantic version tag and shipped. The master git branch of a project should always work. Only changes considered ready to be released publicly are merged. Components Release as Needed \u00b6 Deis components release new versions as often as needed. Fixing a high priority bug requires the project maintainer to create a new patch release. Merging a backward-compatible feature implies a minor release. By releasing often, each component release becomes a safe and routine event. This makes it faster and easier for users to obtain specific fixes. Continuous delivery also reduces the work necessary to release a product such as Deis Workflow, which integrates several components. \"Components\" applies not just to Deis Workflow projects, but also to development and release tools, to Docker base images, and to other Deis projects that do semantic version releases. See \" How to Release a Component \" for more detail. Workflow Releases Each Month \u00b6 Deis Workflow has a regular, public release cadence. From v2.8.0 onward, new Workflow feature releases arrive on the first Thursday of each month. Patch releases are created at any time, as needed. GitHub milestones are used to communicate the content and timing of major and minor releases, and longer-term planning is visible at the Roadmap . Workflow release timing is not linked to specific features. If a feature is merged before the release date, it is included in the next release. See \" How to Release Workflow \" for more detail. Semantic Versioning \u00b6 Deis releases comply with semantic versioning , with the \"public API\" broadly defined as: REST, gRPC, or other API that is network-accessible Library or framework API intended for public use \"Pluggable\" socket-level protocols users can redirect CLI commands and output formats In general, changes to anything a user might reasonably link to, customize, or integrate with should be backward-compatible, or else require a major release. Deis users can be confident that upgrading to a patch or to a minor release will not break anything. How to Release a Component \u00b6 Most Deis projects are \"components\" which produce a Docker image or binary executable as a deliverable. This section leads a maintainer through creating a component release. Step 1: Update Code and Run the Release Tool \u00b6 Major or minor releases should happen on the master branch. Patch releases should check out the previous release tag and cherry-pick specific commits from master. Note: if a patch release, the release artifact will have to be manually promoted by triggering the component-promote job with the following values: COMPONENT_NAME=<component name> COMPONENT_SHA=<patch commit sha> Make sure you have the deisrel release tool in your search $PATH . Run deisrel release once with a fake semver tag to proofread the changelog content. (If HEAD of master is not what is intended for the release, add the --sha flag as described in deisrel release --help .) $ deisrel release controller v0.0.0 Doing a dry run of the component release... skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v0.0.0 #### Fixes - [`615b834`](https://github.com/teamhephy/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DEIS_DEBUG==true for debug output Based on the changelog content, determine whether the component deserves a minor or patch release. Run the command again with that semver tag and --dry-run=false . You will still be asked for confirmation before the release is created: $ deisrel release controller v2.8.2 --dry-run=false skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v2.8.2 #### Fixes - [`615b834`](https://github.com/teamhephy/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DEIS_DEBUG==true for debug output Please review the above changelog contents and ensure: 1. All intended commits are mentioned 2. The changes agree with the semver release tag (major, minor, or patch) Create release for Deis Controller v2.8.2? [y/n]: y New release is available at https://github.com/teamhephy/controller/releases/tag/v2.8.2 Step 2: Verify the Component is Available \u00b6 Tagging the component (see Step 1 ) starts a CI job that eventually results in an artifact being made available for public download. Please see the CI flow diagrams for details. Double-check that the artifact is available, either by a docker pull command or by running the appropriate installer script. If the artifact can't be downloaded, ensure that its CI release jobs are still in progress, or fix whatever issue arose in the pipeline. For example, the master merge pipeline may have failed to promote the :git-abc1d23 candidate image and needs to be restarted with that component and commit. If the component has a correlating Kubernetes Helm chart, this chart will also be packaged, signed and uploaded to its production chart repo. Please verify it can be fetched (and verified): $ helm repo add controller https://charts.teamhephy.com/controller \"controller\" has been added to your repositories $ helm fetch --verify controller/controller --version v2.17.0 Verification: &{0xc4207ec870 sha256:026e766e918ff28d2a7041bc3d560d149ee7eb0cb84165c9d9d00a3045ff45c3 controller-v2.17.0.tgz} How to Release Workflow \u00b6 Deis Workflow integrates multiple component releases together with a Kubernetes Helm chart deliverable. This section leads a maintainer through creating a Workflow release. Step 1: Set Environment Variables \u00b6 Export two environment variables that will be used in later steps: export WORKFLOW_RELEASE=v2.17.0 WORKFLOW_PREV_RELEASE=v2.16.0 # for example Step 2: Tag Supporting Repositories \u00b6 Some Workflow components not in the Helm chart must also be tagged in sync with the release. Follow the component release process above and ensure that these components are tagged: teamhephy/workflow-cli teamhephy/workflow-e2e The version number for teamhephy/workflow-cli should always match the overall Workflow version number. Step 3: Create Helm Chart \u00b6 To create and stage a release candidate chart for Workflow, we will build the workflow-chart-stage job with the following parameters: RELEASE_TAG=$WORKFLOW_RELEASE This job will gather all of the latest component release tags and use these to specify the versions of all component charts. It will then package the Workflow chart, upload it to the staging chart repo and kick off an e2e run against said chart. Step 4: Manual Testing \u00b6 Now it's time to go above and beyond current CI tests. Create a testing matrix spreadsheet (copying from the previous document is a good start) and sign up testers to cover all permutations. Testers should pay special attention to the overall user experience, make sure upgrading from earlier versions is smooth, and cover various storage configurations and Kubernetes versions and infrastructure providers. When showstopper-level bugs are found, the process is as follows: Create a component PR that fixes the bug. Once the PR passes and is reviewed, merge it and do a new component release Trigger the same workflow-chart-stage job as mentioned in Step 3 to upload the newly-generated Workflow release candidate chart to staging. Step 5: Release the Chart \u00b6 When testing has completed without uncovering any new showstopper bugs, kick off the workflow-chart-release job with the following parameter: RELEASE_TAG=$WORKFLOW_RELEASE This job will copy the release candidate chart (now approved by CI and manual testing) from the staging repo to the production repo, signing it if it has not done so already. Step 6: Assemble Master Changelog \u00b6 Each component already updated its release notes on GitHub with CHANGELOG content. We'll now generate the master changelog for the Workflow chart, consisting of all component and auxilliary repo changes. We'll employ the requirements.lock file from the WORKFLOW_PREV_RELEASE chart, as well as a repo-to-chart-name mapping file , this time invoking deisrel changelog global to get all component changes between the chart versions existing in the WORKFLOW_PREV_RELEASE chart and the most recent releases existing in GitHub. (Therefore, if there are any unreleased commits in a component repo, they will not appear here): helm repo add hephy https://charts.teamhephy.com/workflow helm fetch --untar hephy/workflow --version $WORKFLOW_PREV_RELEASE deisrel changelog global workflow/requirements.lock map.json > changelog-$WORKFLOW_RELEASE.md This master changelog should then be placed into a single gist. The file will also be added to the documentation update PR created in the next step. Step 7: Update Documentation \u00b6 Create a new pull request at teamhephy/workflow that updates version references to the new release. Use git grep $WORKFLOW_PREV_RELEASE to find any references, but be careful not to change CHANGELOG.md . Place the $WORKFLOW_RELEASE master changelog generated in Step 7 in the changelogs directory. Make sure to add a header to the page to make it clear that this is for a Workflow release, e.g.: ## Workflow v2.16.0 -> v2.17.0 Once the PR has been reviewed and merged, do a component release of teamhephy/workflow itself. The version number for teamhephy/workflow should always match the overall Workflow version number. Step 8: Close GitHub Milestones \u00b6 Create a pull request at seed-repo to close the release milestone and create the next one. When changes are merged to seed-repo, milestones on all relevant projects will be updated. If there are open issues attached to the milestone, move them to the next upcoming milestone before merging the pull request. Milestones map to Deis Workflow releases in teamhephy/workflow . These milestones do not correspond to individual component release tags. Step 9: Release Workflow CLI Stable \u00b6 Now that the $WORKFLOW_RELEASE version of Workflow CLI has been vetted, we can push stable artifacts based on this version. Kick off https://ci.teamhephy.info/job/workflow-cli-build-stable/ with the TAG build parameter of $WORKFLOW_RELEASE and then verify stable artifacts are available and appropriately updated after the job completes: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 $ ./deis version # (Should show $WORKFLOW_RELEASE) # FIXME: builds of CLI should match the current Workflow release.) Step 10: Let Everyone Know \u00b6 Let the rest of the team know they can start blogging and tweeting about the new Workflow release. Post a message to the #company channel on Slack. Include a link to the released chart and to the master CHANGELOG: @here Deis Workflow v2.17.0 is now live! Master CHANGELOG: https://teamhephy.info/docs/workflow/changelogs/v2.17.0/ You're done with the release. Nice job!","title":"Releases"},{"location":"roadmap/releases/#releases","text":"Deis uses a continuous delivery approach for creating releases. Every merged commit that passes testing results in a deliverable that can be given a semantic version tag and shipped. The master git branch of a project should always work. Only changes considered ready to be released publicly are merged.","title":"Releases"},{"location":"roadmap/releases/#components-release-as-needed","text":"Deis components release new versions as often as needed. Fixing a high priority bug requires the project maintainer to create a new patch release. Merging a backward-compatible feature implies a minor release. By releasing often, each component release becomes a safe and routine event. This makes it faster and easier for users to obtain specific fixes. Continuous delivery also reduces the work necessary to release a product such as Deis Workflow, which integrates several components. \"Components\" applies not just to Deis Workflow projects, but also to development and release tools, to Docker base images, and to other Deis projects that do semantic version releases. See \" How to Release a Component \" for more detail.","title":"Components Release as Needed"},{"location":"roadmap/releases/#workflow-releases-each-month","text":"Deis Workflow has a regular, public release cadence. From v2.8.0 onward, new Workflow feature releases arrive on the first Thursday of each month. Patch releases are created at any time, as needed. GitHub milestones are used to communicate the content and timing of major and minor releases, and longer-term planning is visible at the Roadmap . Workflow release timing is not linked to specific features. If a feature is merged before the release date, it is included in the next release. See \" How to Release Workflow \" for more detail.","title":"Workflow Releases Each Month"},{"location":"roadmap/releases/#semantic-versioning","text":"Deis releases comply with semantic versioning , with the \"public API\" broadly defined as: REST, gRPC, or other API that is network-accessible Library or framework API intended for public use \"Pluggable\" socket-level protocols users can redirect CLI commands and output formats In general, changes to anything a user might reasonably link to, customize, or integrate with should be backward-compatible, or else require a major release. Deis users can be confident that upgrading to a patch or to a minor release will not break anything.","title":"Semantic Versioning"},{"location":"roadmap/releases/#how-to-release-a-component","text":"Most Deis projects are \"components\" which produce a Docker image or binary executable as a deliverable. This section leads a maintainer through creating a component release.","title":"How to Release a Component"},{"location":"roadmap/releases/#step-1-update-code-and-run-the-release-tool","text":"Major or minor releases should happen on the master branch. Patch releases should check out the previous release tag and cherry-pick specific commits from master. Note: if a patch release, the release artifact will have to be manually promoted by triggering the component-promote job with the following values: COMPONENT_NAME=<component name> COMPONENT_SHA=<patch commit sha> Make sure you have the deisrel release tool in your search $PATH . Run deisrel release once with a fake semver tag to proofread the changelog content. (If HEAD of master is not what is intended for the release, add the --sha flag as described in deisrel release --help .) $ deisrel release controller v0.0.0 Doing a dry run of the component release... skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v0.0.0 #### Fixes - [`615b834`](https://github.com/teamhephy/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DEIS_DEBUG==true for debug output Based on the changelog content, determine whether the component deserves a minor or patch release. Run the command again with that semver tag and --dry-run=false . You will still be asked for confirmation before the release is created: $ deisrel release controller v2.8.2 --dry-run=false skipping commit 943a49267eeb28546819a266654806cfcbae0e38 Creating changelog for controller with tag v2.8.1 through commit 943a49267eeb28546819a266654806cfcbae0e38 ### v2.8.1 -> v2.8.2 #### Fixes - [`615b834`](https://github.com/teamhephy/controller/commit/615b834f39cb68a854cc1f1e2f0f82d862ea2731) boot: Ensure DEIS_DEBUG==true for debug output Please review the above changelog contents and ensure: 1. All intended commits are mentioned 2. The changes agree with the semver release tag (major, minor, or patch) Create release for Deis Controller v2.8.2? [y/n]: y New release is available at https://github.com/teamhephy/controller/releases/tag/v2.8.2","title":"Step 1: Update Code and Run the Release Tool"},{"location":"roadmap/releases/#step-2-verify-the-component-is-available","text":"Tagging the component (see Step 1 ) starts a CI job that eventually results in an artifact being made available for public download. Please see the CI flow diagrams for details. Double-check that the artifact is available, either by a docker pull command or by running the appropriate installer script. If the artifact can't be downloaded, ensure that its CI release jobs are still in progress, or fix whatever issue arose in the pipeline. For example, the master merge pipeline may have failed to promote the :git-abc1d23 candidate image and needs to be restarted with that component and commit. If the component has a correlating Kubernetes Helm chart, this chart will also be packaged, signed and uploaded to its production chart repo. Please verify it can be fetched (and verified): $ helm repo add controller https://charts.teamhephy.com/controller \"controller\" has been added to your repositories $ helm fetch --verify controller/controller --version v2.17.0 Verification: &{0xc4207ec870 sha256:026e766e918ff28d2a7041bc3d560d149ee7eb0cb84165c9d9d00a3045ff45c3 controller-v2.17.0.tgz}","title":"Step 2: Verify the Component is Available"},{"location":"roadmap/releases/#how-to-release-workflow","text":"Deis Workflow integrates multiple component releases together with a Kubernetes Helm chart deliverable. This section leads a maintainer through creating a Workflow release.","title":"How to Release Workflow"},{"location":"roadmap/releases/#step-1-set-environment-variables","text":"Export two environment variables that will be used in later steps: export WORKFLOW_RELEASE=v2.17.0 WORKFLOW_PREV_RELEASE=v2.16.0 # for example","title":"Step 1: Set Environment Variables"},{"location":"roadmap/releases/#step-2-tag-supporting-repositories","text":"Some Workflow components not in the Helm chart must also be tagged in sync with the release. Follow the component release process above and ensure that these components are tagged: teamhephy/workflow-cli teamhephy/workflow-e2e The version number for teamhephy/workflow-cli should always match the overall Workflow version number.","title":"Step 2: Tag Supporting Repositories"},{"location":"roadmap/releases/#step-3-create-helm-chart","text":"To create and stage a release candidate chart for Workflow, we will build the workflow-chart-stage job with the following parameters: RELEASE_TAG=$WORKFLOW_RELEASE This job will gather all of the latest component release tags and use these to specify the versions of all component charts. It will then package the Workflow chart, upload it to the staging chart repo and kick off an e2e run against said chart.","title":"Step 3: Create Helm Chart"},{"location":"roadmap/releases/#step-4-manual-testing","text":"Now it's time to go above and beyond current CI tests. Create a testing matrix spreadsheet (copying from the previous document is a good start) and sign up testers to cover all permutations. Testers should pay special attention to the overall user experience, make sure upgrading from earlier versions is smooth, and cover various storage configurations and Kubernetes versions and infrastructure providers. When showstopper-level bugs are found, the process is as follows: Create a component PR that fixes the bug. Once the PR passes and is reviewed, merge it and do a new component release Trigger the same workflow-chart-stage job as mentioned in Step 3 to upload the newly-generated Workflow release candidate chart to staging.","title":"Step 4: Manual Testing"},{"location":"roadmap/releases/#step-5-release-the-chart","text":"When testing has completed without uncovering any new showstopper bugs, kick off the workflow-chart-release job with the following parameter: RELEASE_TAG=$WORKFLOW_RELEASE This job will copy the release candidate chart (now approved by CI and manual testing) from the staging repo to the production repo, signing it if it has not done so already.","title":"Step 5: Release the Chart"},{"location":"roadmap/releases/#step-6-assemble-master-changelog","text":"Each component already updated its release notes on GitHub with CHANGELOG content. We'll now generate the master changelog for the Workflow chart, consisting of all component and auxilliary repo changes. We'll employ the requirements.lock file from the WORKFLOW_PREV_RELEASE chart, as well as a repo-to-chart-name mapping file , this time invoking deisrel changelog global to get all component changes between the chart versions existing in the WORKFLOW_PREV_RELEASE chart and the most recent releases existing in GitHub. (Therefore, if there are any unreleased commits in a component repo, they will not appear here): helm repo add hephy https://charts.teamhephy.com/workflow helm fetch --untar hephy/workflow --version $WORKFLOW_PREV_RELEASE deisrel changelog global workflow/requirements.lock map.json > changelog-$WORKFLOW_RELEASE.md This master changelog should then be placed into a single gist. The file will also be added to the documentation update PR created in the next step.","title":"Step 6: Assemble Master Changelog"},{"location":"roadmap/releases/#step-7-update-documentation","text":"Create a new pull request at teamhephy/workflow that updates version references to the new release. Use git grep $WORKFLOW_PREV_RELEASE to find any references, but be careful not to change CHANGELOG.md . Place the $WORKFLOW_RELEASE master changelog generated in Step 7 in the changelogs directory. Make sure to add a header to the page to make it clear that this is for a Workflow release, e.g.: ## Workflow v2.16.0 -> v2.17.0 Once the PR has been reviewed and merged, do a component release of teamhephy/workflow itself. The version number for teamhephy/workflow should always match the overall Workflow version number.","title":"Step 7: Update Documentation"},{"location":"roadmap/releases/#step-8-close-github-milestones","text":"Create a pull request at seed-repo to close the release milestone and create the next one. When changes are merged to seed-repo, milestones on all relevant projects will be updated. If there are open issues attached to the milestone, move them to the next upcoming milestone before merging the pull request. Milestones map to Deis Workflow releases in teamhephy/workflow . These milestones do not correspond to individual component release tags.","title":"Step 8: Close GitHub Milestones"},{"location":"roadmap/releases/#step-9-release-workflow-cli-stable","text":"Now that the $WORKFLOW_RELEASE version of Workflow CLI has been vetted, we can push stable artifacts based on this version. Kick off https://ci.teamhephy.info/job/workflow-cli-build-stable/ with the TAG build parameter of $WORKFLOW_RELEASE and then verify stable artifacts are available and appropriately updated after the job completes: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 $ ./deis version # (Should show $WORKFLOW_RELEASE) # FIXME: builds of CLI should match the current Workflow release.)","title":"Step 9: Release Workflow CLI Stable"},{"location":"roadmap/releases/#step-10-let-everyone-know","text":"Let the rest of the team know they can start blogging and tweeting about the new Workflow release. Post a message to the #company channel on Slack. Include a link to the released chart and to the master CHANGELOG: @here Deis Workflow v2.17.0 is now live! Master CHANGELOG: https://teamhephy.info/docs/workflow/changelogs/v2.17.0/ You're done with the release. Nice job!","title":"Step 10: Let Everyone Know"},{"location":"roadmap/roadmap/","text":"Deis Workflow Roadmap \u00b6 The Deis Workflow Roadmap is a community document created as part of the open Planning Process . Each roadmap item describes a high-level capability or grouping of features that are deemed important to the future of Deis. Given the project's rapid Release Schedule , roadmap items are designed to provide a sense of direction over many releases. Interactive deis run /bin/bash \u00b6 Provide the ability for developers to launch an interactive terminal session in their application environment. Related issues: https://github.com/teamhephy/workflow-cli/issues/28 https://github.com/deis/deis/issues/117 Log Streaming \u00b6 Stream application logs via deis logs -f https://github.com/deis/deis/issues/465 Teams and Permissions \u00b6 Teams and Permissions represents a more flexible permissions model to allow more nuanced control to applications, capabilities and resources on the platform. There have been a number of proposals in this area which need to be reconciled for Deis Workflow before we begin implementation. Related issues: Deploy Keys: https://github.com/deis/deis/issues/3875 Teams: https://github.com/deis/deis/issues/4173 Fine grained permissions: https://github.com/deis/deis/issues/4150 Admins create apps only: https://github.com/deis/deis/issues/4052 Admin Certificate Permissions: https://github.com/deis/deis/issues/4576#issuecomment-170987223 Monitoring \u00b6 Define and deliver alerts with Kapacitor: https://github.com/deis/monitor/issues/44 Workflow Addons/Services \u00b6 Developers should be able to quickly and easily provision application dependencies using a services or addon abstraction. https://github.com/deis/deis/issues/231 Inbound/Outbound Webhooks \u00b6 Deis Workflow should be able to send and receive webhooks from external systems. Facilitating integration with third party services like GitHub, Gitlab, Slack, Hipchat. Send webhook on platform events: https://github.com/deis/deis/issues/1486 (Workflow v2.10)","title":"Roadmap"},{"location":"roadmap/roadmap/#deis-workflow-roadmap","text":"The Deis Workflow Roadmap is a community document created as part of the open Planning Process . Each roadmap item describes a high-level capability or grouping of features that are deemed important to the future of Deis. Given the project's rapid Release Schedule , roadmap items are designed to provide a sense of direction over many releases.","title":"Deis Workflow Roadmap"},{"location":"roadmap/roadmap/#interactive-deis-run-binbash","text":"Provide the ability for developers to launch an interactive terminal session in their application environment. Related issues: https://github.com/teamhephy/workflow-cli/issues/28 https://github.com/deis/deis/issues/117","title":"Interactive deis run /bin/bash"},{"location":"roadmap/roadmap/#log-streaming","text":"Stream application logs via deis logs -f https://github.com/deis/deis/issues/465","title":"Log Streaming"},{"location":"roadmap/roadmap/#teams-and-permissions","text":"Teams and Permissions represents a more flexible permissions model to allow more nuanced control to applications, capabilities and resources on the platform. There have been a number of proposals in this area which need to be reconciled for Deis Workflow before we begin implementation. Related issues: Deploy Keys: https://github.com/deis/deis/issues/3875 Teams: https://github.com/deis/deis/issues/4173 Fine grained permissions: https://github.com/deis/deis/issues/4150 Admins create apps only: https://github.com/deis/deis/issues/4052 Admin Certificate Permissions: https://github.com/deis/deis/issues/4576#issuecomment-170987223","title":"Teams and Permissions"},{"location":"roadmap/roadmap/#monitoring","text":"Define and deliver alerts with Kapacitor: https://github.com/deis/monitor/issues/44","title":"Monitoring"},{"location":"roadmap/roadmap/#workflow-addonsservices","text":"Developers should be able to quickly and easily provision application dependencies using a services or addon abstraction. https://github.com/deis/deis/issues/231","title":"Workflow Addons/Services"},{"location":"roadmap/roadmap/#inboundoutbound-webhooks","text":"Deis Workflow should be able to send and receive webhooks from external systems. Facilitating integration with third party services like GitHub, Gitlab, Slack, Hipchat. Send webhook on platform events: https://github.com/deis/deis/issues/1486 (Workflow v2.10)","title":"Inbound/Outbound Webhooks"},{"location":"troubleshooting/","text":"Troubleshooting Workflow \u00b6 Common issues that users have run into when provisioning Workflow are detailed below. A Component Fails to Start \u00b6 For information on troubleshooting a failing component, see Troubleshooting with Kubectl . An Application Fails to Start \u00b6 For information on troubleshooting application deployment issues, see Troubleshooting Applications . Permission denied (publickey) \u00b6 The most common problem for this issue is the user forgetting to run deis keys:add or add their private key to their SSH agent. To do so, run ssh-add ~/.ssh/id_rsa and try running git push deis master again. If you happen get a Could not open a connection to your authentication agent error after trying to run ssh-add command above, you may need to load the SSH agent environment variables issuing the eval \"$(ssh-agent)\" command before. Other Issues \u00b6 Running into something not detailed here? Please open an issue or hop into #community on Slack for help!","title":"Troubleshooting Workflow"},{"location":"troubleshooting/#troubleshooting-workflow","text":"Common issues that users have run into when provisioning Workflow are detailed below.","title":"Troubleshooting Workflow"},{"location":"troubleshooting/#a-component-fails-to-start","text":"For information on troubleshooting a failing component, see Troubleshooting with Kubectl .","title":"A Component Fails to Start"},{"location":"troubleshooting/#an-application-fails-to-start","text":"For information on troubleshooting application deployment issues, see Troubleshooting Applications .","title":"An Application Fails to Start"},{"location":"troubleshooting/#permission-denied-publickey","text":"The most common problem for this issue is the user forgetting to run deis keys:add or add their private key to their SSH agent. To do so, run ssh-add ~/.ssh/id_rsa and try running git push deis master again. If you happen get a Could not open a connection to your authentication agent error after trying to run ssh-add command above, you may need to load the SSH agent environment variables issuing the eval \"$(ssh-agent)\" command before.","title":"Permission denied (publickey)"},{"location":"troubleshooting/#other-issues","text":"Running into something not detailed here? Please open an issue or hop into #community on Slack for help!","title":"Other Issues"},{"location":"troubleshooting/applications/","text":"Troubleshooting Applications \u00b6 This document describes how one can troubleshoot common issues when deploying or debugging an application that fails to start or deploy. Application has a Dockerfile, but a Buildpack Deployment Occurs \u00b6 When you deploy an application to Workflow using git push deis master and the Builder attempts to deploy using the Buildpack workflow, check the following steps: Are you deploying the correct project? Are you pushing the correct git branch ( git push deis <branch> )? Is the Dockerfile in the project's root directory? Have you committed the Dockerfile to the project? Application was Deployed, but is Failing to Start \u00b6 If you deployed your application but it is failing to start, you can use deis logs to check why the application fails to boot. Sometimes, the application container may fail to boot without logging any information about the error. This typically occurs when the healthcheck configured for the application fails. In this case, you can start by troubleshooting using kubectl . You can inspect the application's current state by examining the pod deployed in the application's namespace. To do that, run $ kubectl --namespace=myapp get pods NAME READY STATUS RESTARTS AGE myapp-cmd-1585713350-3brbo 0/1 CrashLoopBackOff 2 43s We can then describe the pod and determine why it is failing to boot: Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 43s 43s 1 {default-scheduler } Normal Scheduled Successfully assigned myapp-cmd-1585713350-3brbo to kubernetes-node-1 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Created Created container with docker id b86bd851a61f 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Started Started container with docker id b86bd851a61f 37s 35s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Warning Unhealthy Liveness probe failed: Get http://10.246.39.13:8000/healthz: dial tcp 10.246.39.13:8000: getsockopt: connection refused In this instance, we set the healthcheck initial delay timeout for the application at 1 second, which is too aggressive. The application needs some time to set up the API server after the container has booted. By increasing the healthcheck initial delay timeout to 10 seconds, the application is able to boot and is responding correctly. See Custom Health Checks for more information on how to customize the application's health checks to better suit the application's needs.","title":"Troubleshooting Applications"},{"location":"troubleshooting/applications/#troubleshooting-applications","text":"This document describes how one can troubleshoot common issues when deploying or debugging an application that fails to start or deploy.","title":"Troubleshooting Applications"},{"location":"troubleshooting/applications/#application-has-a-dockerfile-but-a-buildpack-deployment-occurs","text":"When you deploy an application to Workflow using git push deis master and the Builder attempts to deploy using the Buildpack workflow, check the following steps: Are you deploying the correct project? Are you pushing the correct git branch ( git push deis <branch> )? Is the Dockerfile in the project's root directory? Have you committed the Dockerfile to the project?","title":"Application has a Dockerfile, but a Buildpack Deployment Occurs"},{"location":"troubleshooting/applications/#application-was-deployed-but-is-failing-to-start","text":"If you deployed your application but it is failing to start, you can use deis logs to check why the application fails to boot. Sometimes, the application container may fail to boot without logging any information about the error. This typically occurs when the healthcheck configured for the application fails. In this case, you can start by troubleshooting using kubectl . You can inspect the application's current state by examining the pod deployed in the application's namespace. To do that, run $ kubectl --namespace=myapp get pods NAME READY STATUS RESTARTS AGE myapp-cmd-1585713350-3brbo 0/1 CrashLoopBackOff 2 43s We can then describe the pod and determine why it is failing to boot: Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 43s 43s 1 {default-scheduler } Normal Scheduled Successfully assigned myapp-cmd-1585713350-3brbo to kubernetes-node-1 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Created Created container with docker id b86bd851a61f 41s 41s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Normal Started Started container with docker id b86bd851a61f 37s 35s 1 {kubelet kubernetes-node-1} spec.containers{myapp-cmd} Warning Unhealthy Liveness probe failed: Get http://10.246.39.13:8000/healthz: dial tcp 10.246.39.13:8000: getsockopt: connection refused In this instance, we set the healthcheck initial delay timeout for the application at 1 second, which is too aggressive. The application needs some time to set up the API server after the container has booted. By increasing the healthcheck initial delay timeout to 10 seconds, the application is able to boot and is responding correctly. See Custom Health Checks for more information on how to customize the application's health checks to better suit the application's needs.","title":"Application was Deployed, but is Failing to Start"},{"location":"troubleshooting/kubectl/","text":"Troubleshooting using Kubectl \u00b6 This document describes how one can use kubectl to debug any issues with the cluster. Diving into the Components \u00b6 Using kubectl , one can inspect the cluster's current state. When Workflow is installed with helm , Workflow is installed into the deis namespace. To inspect if Workflow is running, run: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-gqum7 0/1 ContainerCreating 0 4s deis-controller-h6lk6 0/1 ContainerCreating 0 4s deis-database-56v39 0/1 ContainerCreating 0 4s deis-logger-fluentd-xihr1 0/1 Pending 0 2s deis-logger-grupg 0/1 ContainerCreating 0 3s deis-minio-c2exb 0/1 Pending 0 3s deis-monitor-grafana-9ccur 0/1 Pending 0 3s deis-monitor-influxdb-f9ftm 0/1 Pending 0 3s deis-monitor-stdout-novxs 0/1 Pending 0 3s deis-monitor-telegraf-dc3y3 0/1 Pending 0 2s deis-registry-5bor6 0/1 Pending 0 3s deis-router-r02sd 0/1 Pending 0 2s deis-workflow-manager-hizv6 0/1 Pending 0 2s Tip To save precious keystrokes, alias kubectl --namespace=deis to kd so it is easier to type in the future. To fetch the logs of a specific component, use kubectl logs : $ kubectl --namespace=deis logs deis-controller-h6lk6 system information: Django Version: 1.9.6 Python 3.5.1 addgroup: gid '0' in use Django checks: System check identified no issues (2 silenced). [...] To dive into a running container to inspect its environment, use kubectl exec : $ kubectl --namespace=deis exec -it deis-database-56v39 gosu postgres psql psql (9.4.7) Type \"help\" for help. postgres=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ----------------------------------+----------+----------+------------+------------+----------------------- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) postgres=# \\connect V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc You are now connected to database \"V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc\" as user \"postgres\". V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# \\dt List of relations Schema | Name | Type | Owner --------+--------------------------------+-------+---------------------------------- public | api_app | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_build | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_certificate | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_config | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_domain | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_key | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_push | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_release | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | auth_group | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc --More-- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# SELECT COUNT(*) from api_app; count ------- 0 (1 row)","title":"Troubleshooting using Kubectl"},{"location":"troubleshooting/kubectl/#troubleshooting-using-kubectl","text":"This document describes how one can use kubectl to debug any issues with the cluster.","title":"Troubleshooting using Kubectl"},{"location":"troubleshooting/kubectl/#diving-into-the-components","text":"Using kubectl , one can inspect the cluster's current state. When Workflow is installed with helm , Workflow is installed into the deis namespace. To inspect if Workflow is running, run: $ kubectl --namespace=deis get pods NAME READY STATUS RESTARTS AGE deis-builder-gqum7 0/1 ContainerCreating 0 4s deis-controller-h6lk6 0/1 ContainerCreating 0 4s deis-database-56v39 0/1 ContainerCreating 0 4s deis-logger-fluentd-xihr1 0/1 Pending 0 2s deis-logger-grupg 0/1 ContainerCreating 0 3s deis-minio-c2exb 0/1 Pending 0 3s deis-monitor-grafana-9ccur 0/1 Pending 0 3s deis-monitor-influxdb-f9ftm 0/1 Pending 0 3s deis-monitor-stdout-novxs 0/1 Pending 0 3s deis-monitor-telegraf-dc3y3 0/1 Pending 0 2s deis-registry-5bor6 0/1 Pending 0 3s deis-router-r02sd 0/1 Pending 0 2s deis-workflow-manager-hizv6 0/1 Pending 0 2s Tip To save precious keystrokes, alias kubectl --namespace=deis to kd so it is easier to type in the future. To fetch the logs of a specific component, use kubectl logs : $ kubectl --namespace=deis logs deis-controller-h6lk6 system information: Django Version: 1.9.6 Python 3.5.1 addgroup: gid '0' in use Django checks: System check identified no issues (2 silenced). [...] To dive into a running container to inspect its environment, use kubectl exec : $ kubectl --namespace=deis exec -it deis-database-56v39 gosu postgres psql psql (9.4.7) Type \"help\" for help. postgres=# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ----------------------------------+----------+----------+------------+------------+----------------------- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 | template0 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) postgres=# \\connect V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc You are now connected to database \"V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc\" as user \"postgres\". V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# \\dt List of relations Schema | Name | Type | Owner --------+--------------------------------+-------+---------------------------------- public | api_app | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_build | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_certificate | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_config | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_domain | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_key | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_push | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | api_release | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc public | auth_group | table | V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc --More-- V7wckOHIAn3MZ7mO5du4q5IRq7yib1Oc=# SELECT COUNT(*) from api_app; count ------- 0 (1 row)","title":"Diving into the Components"},{"location":"understanding-workflow/architecture/","text":"Architecture \u00b6 Deis Workflow is built using a service oriented architecture. All components are published as a set of container images which can be deployed to any compliant Kubernetes cluster. Overview \u00b6 Operators use Helm to configure and install the Workflow components which interface directly with the underlying Kubernetes cluster. Service discovery, container availability and networking are all delegated to Kubernetes, while Workflow provides a clean and simple developer experience. Platform Services \u00b6 Deis Workflow provides additional functionality to your Kubernetes cluster, including: Source to Image Builder which compiles your Application code via Buildpacks or Dockerfiles Cross-Pod Log Aggregation which gathers logs from all of your Application processes Simple REST API which powers the CLI and any external integrations Application release and rollback Authentication and Authorization to Application resources HTTP/HTTPS edge routing for your Applications Kubernetes-Native \u00b6 All platform components and applications deployed via Workflow expect to be running on an existing Kubernetes cluster. This means that you can happily run your Kubernetes-native workloads next to applications that are managed through Deis Workflow. Application Layout and Edge Routing \u00b6 By default Workflow creates per-application Namespaces and Services so you can easily connect your applications to other on-cluster services through standard Kubernetes mechanisms. The router component is responsible for routing HTTP/s traffic to your Applications as well as proxying git push and platform API traffic. By default, the router component is deployed as a Kubernetes service with type LoadBalancer ; which, depending on your configuration, will provision a cloud-native load balancer automatically. The router automatically discovers routable Applications, SSL/TLS certificates and application-specific configurations through the use of Kubernetes annotations. Any changes to router configuration or certificates are applied within seconds. Topologies \u00b6 Deis Workflow no longer dictates a specific topology or server count for your deployment. The platform components will happily run on single-server configurations as well as multi-server production clusters.","title":"Architecture"},{"location":"understanding-workflow/architecture/#architecture","text":"Deis Workflow is built using a service oriented architecture. All components are published as a set of container images which can be deployed to any compliant Kubernetes cluster.","title":"Architecture"},{"location":"understanding-workflow/architecture/#overview","text":"Operators use Helm to configure and install the Workflow components which interface directly with the underlying Kubernetes cluster. Service discovery, container availability and networking are all delegated to Kubernetes, while Workflow provides a clean and simple developer experience.","title":"Overview"},{"location":"understanding-workflow/architecture/#platform-services","text":"Deis Workflow provides additional functionality to your Kubernetes cluster, including: Source to Image Builder which compiles your Application code via Buildpacks or Dockerfiles Cross-Pod Log Aggregation which gathers logs from all of your Application processes Simple REST API which powers the CLI and any external integrations Application release and rollback Authentication and Authorization to Application resources HTTP/HTTPS edge routing for your Applications","title":"Platform Services"},{"location":"understanding-workflow/architecture/#kubernetes-native","text":"All platform components and applications deployed via Workflow expect to be running on an existing Kubernetes cluster. This means that you can happily run your Kubernetes-native workloads next to applications that are managed through Deis Workflow.","title":"Kubernetes-Native"},{"location":"understanding-workflow/architecture/#application-layout-and-edge-routing","text":"By default Workflow creates per-application Namespaces and Services so you can easily connect your applications to other on-cluster services through standard Kubernetes mechanisms. The router component is responsible for routing HTTP/s traffic to your Applications as well as proxying git push and platform API traffic. By default, the router component is deployed as a Kubernetes service with type LoadBalancer ; which, depending on your configuration, will provision a cloud-native load balancer automatically. The router automatically discovers routable Applications, SSL/TLS certificates and application-specific configurations through the use of Kubernetes annotations. Any changes to router configuration or certificates are applied within seconds.","title":"Application Layout and Edge Routing"},{"location":"understanding-workflow/architecture/#topologies","text":"Deis Workflow no longer dictates a specific topology or server count for your deployment. The platform components will happily run on single-server configurations as well as multi-server production clusters.","title":"Topologies"},{"location":"understanding-workflow/components/","text":"Components \u00b6 Workflow is comprised of a number of small, independent services that combine to create a distributed PaaS. All Workflow components are deployed as services (and associated controllers) in your Kubernetes cluster. If you are interested we have a more detailed exploration of the Workflow architecture . All of the componentry for Workflow is built with composability in mind. If you need to customize one of the components for your specific deployment or need the functionality in your own project we invite you to give it a shot! Controller \u00b6 Project Location: teamhephy/controller The controller component is an HTTP API server which serves as the endpoint for the deis CLI. The controller provides all of the platform functionality as well as interfacing with your Kubernetes cluster. The controller persists all of its data to the database component. Database \u00b6 Project Location: teamhephy/postgres The database component is a managed instance of PostgreSQL which holds a majority of the platforms state. Backups and WAL files are pushed to object storage via WAL-E . When the database is restarted, backups are fetched and replayed from object storage so no data is lost. Builder \u00b6 Project Location: teamhephy/builder The builder component is responsible for accepting code pushes via Git and managing the build process of your Application . The builder process is: Receives incoming git push requests over SSH Authenticates the user via SSH key fingerprint Authorizes the user's access to push code to the Application Starts the Application Build phase (see below) Triggers a new Release via the Controller Builder currently supports both buildpack and Dockerfile based builds. Project Location: teamhephy/slugbuilder For Buildpack-based deploys, the builder component will launch a one-shot Pod in the deis namespace. This pod runs slugbuilder component which handles default and custom buildpacks (specified by BUILDPACK_URL ). The \"compiled\" application results in a slug, consisting of your application code and all of its dependencies as determined by the buildpack. The slug is pushed to the cluster-configured object storage for later execution. For more information about buildpacks see using buildpacks . Project Location: teamhephy/dockerbuilder For Applications which contain a Dockerfile in the root of the repository, builder will instead launch the dockerbuilder to package your application. Instead of generating a slug, dockerbuilder generates a Docker image (using the underlying Docker engine). The completed image is pushed to the managed Docker registry on cluster. For more information see using Dockerfiles . Slugrunner \u00b6 Project Location: teamhephy/slugrunner Slugrunner is the component responsible for executing buildpack-based Applications. Slugrunner receives slug information from the controller and downloads the application slug just before launching your application processes. Object Storage \u00b6 Project Location: teamhephy/minio All of the Workflow components that need to persist data will ship them to the object storage that was configured for the cluster.For example, database ships its WAL files, registry stores Docker images, and slugbuilder stores slugs. Workflow supports either on or off-cluster storage. For production deployments we highly recommend that you configure off-cluster object storage . To facilitate experimentation, development and test environments, the default charts for Workflow include on-cluster object storage via minio . If you also feel comfortable using Kubernetes persistent volumes you may configure minio to use persistent storage available in your environment. Registry \u00b6 Project Location: teamhephy/registry The registry component is a managed docker registry which holds application images generated from the builder component. Registry persists the Docker image images to either local storage (in development mode) or to object storage configured for the cluster. Router \u00b6 Project Location: teamhephy/router The router component is based on Nginx and is responsible for routing inbound HTTP(S) traffic to your applications. The default workflow charts provision a Kubernetes service in the deis namespace with a service type of LoadBalancer . Depending on your Kubernetes configuration, this may provision a cloud-based loadbalancer automatically. The router component uses Kubernetes annotations for both Application discovery as well as router configuration. For more detailed documentation and possible configuration view the router project documentation . Logger: fluentd, logger \u00b6 The logging subsystem consists of two components. Fluentd handles log shipping and logger maintains a ring-buffer of application logs. Project Location: teamhephy/fluentd Fluentd is deployed to your Kubernetes cluster via Daemon Sets. Fluentd subscribes to all container logs, decorates the output with Kubernetes metadata and can be configured to drain logs to multiple destinations. By default, fluentd ships logs to the logger component, which powers deis logs . Project Location: teamhephy/logger The logger component receives log streams from fluentd , collating by Application name. Logger does not persist logs to disk, instead maintaining an in-memory ring buffer. For more information on logger see the project documentation . Monitor \u00b6 Project Location: teamhephy/monitor The monitoring subsystem consists of three components: Telegraf, InfluxDB and Grafana. Telegraf is the is the metrics collection agent that runs using the daemon set API. It runs on every worker node in the cluster, fetches information about the pods currently running and ships it to InfluxDB. InfluxDB is a database that stores the metrics collected by Telegraf. Out of the box, it does not persist to disk, but you can set it up to back it with a persisitent volume or swap this out with a more robust InfluxDB setup in a production setting. Grafana is a standalone graphing application. It natively supports InfluxDB as a datasource and provides a robust engine for creating dashboards on top of timeseries data. Workflow provides a few dashboards out of the box for monitoring Deis Workflow and Kubernetes. The dashboards can be used as a starting point for creating more custom dashboards to suit a user's needs. Workflow Manager \u00b6 Project Location: teamhephy/workflow-manager Workflow Manager will regularly check your cluster against the latest stable components. If components are missing due to failure or are simply out of date, Workflow operators will know at a glance. By default, this submits component and version information to Deis' version service. If you prefer, you may disable the function by setting WORKFLOW_MANAGER_CHECKVERSIONS to false in Workflow Manager's Deployment. See Also \u00b6 Workflow Concepts Workflow Architecture","title":"Components"},{"location":"understanding-workflow/components/#components","text":"Workflow is comprised of a number of small, independent services that combine to create a distributed PaaS. All Workflow components are deployed as services (and associated controllers) in your Kubernetes cluster. If you are interested we have a more detailed exploration of the Workflow architecture . All of the componentry for Workflow is built with composability in mind. If you need to customize one of the components for your specific deployment or need the functionality in your own project we invite you to give it a shot!","title":"Components"},{"location":"understanding-workflow/components/#controller","text":"Project Location: teamhephy/controller The controller component is an HTTP API server which serves as the endpoint for the deis CLI. The controller provides all of the platform functionality as well as interfacing with your Kubernetes cluster. The controller persists all of its data to the database component.","title":"Controller"},{"location":"understanding-workflow/components/#database","text":"Project Location: teamhephy/postgres The database component is a managed instance of PostgreSQL which holds a majority of the platforms state. Backups and WAL files are pushed to object storage via WAL-E . When the database is restarted, backups are fetched and replayed from object storage so no data is lost.","title":"Database"},{"location":"understanding-workflow/components/#builder","text":"Project Location: teamhephy/builder The builder component is responsible for accepting code pushes via Git and managing the build process of your Application . The builder process is: Receives incoming git push requests over SSH Authenticates the user via SSH key fingerprint Authorizes the user's access to push code to the Application Starts the Application Build phase (see below) Triggers a new Release via the Controller Builder currently supports both buildpack and Dockerfile based builds. Project Location: teamhephy/slugbuilder For Buildpack-based deploys, the builder component will launch a one-shot Pod in the deis namespace. This pod runs slugbuilder component which handles default and custom buildpacks (specified by BUILDPACK_URL ). The \"compiled\" application results in a slug, consisting of your application code and all of its dependencies as determined by the buildpack. The slug is pushed to the cluster-configured object storage for later execution. For more information about buildpacks see using buildpacks . Project Location: teamhephy/dockerbuilder For Applications which contain a Dockerfile in the root of the repository, builder will instead launch the dockerbuilder to package your application. Instead of generating a slug, dockerbuilder generates a Docker image (using the underlying Docker engine). The completed image is pushed to the managed Docker registry on cluster. For more information see using Dockerfiles .","title":"Builder"},{"location":"understanding-workflow/components/#slugrunner","text":"Project Location: teamhephy/slugrunner Slugrunner is the component responsible for executing buildpack-based Applications. Slugrunner receives slug information from the controller and downloads the application slug just before launching your application processes.","title":"Slugrunner"},{"location":"understanding-workflow/components/#object-storage","text":"Project Location: teamhephy/minio All of the Workflow components that need to persist data will ship them to the object storage that was configured for the cluster.For example, database ships its WAL files, registry stores Docker images, and slugbuilder stores slugs. Workflow supports either on or off-cluster storage. For production deployments we highly recommend that you configure off-cluster object storage . To facilitate experimentation, development and test environments, the default charts for Workflow include on-cluster object storage via minio . If you also feel comfortable using Kubernetes persistent volumes you may configure minio to use persistent storage available in your environment.","title":"Object Storage"},{"location":"understanding-workflow/components/#registry","text":"Project Location: teamhephy/registry The registry component is a managed docker registry which holds application images generated from the builder component. Registry persists the Docker image images to either local storage (in development mode) or to object storage configured for the cluster.","title":"Registry"},{"location":"understanding-workflow/components/#router","text":"Project Location: teamhephy/router The router component is based on Nginx and is responsible for routing inbound HTTP(S) traffic to your applications. The default workflow charts provision a Kubernetes service in the deis namespace with a service type of LoadBalancer . Depending on your Kubernetes configuration, this may provision a cloud-based loadbalancer automatically. The router component uses Kubernetes annotations for both Application discovery as well as router configuration. For more detailed documentation and possible configuration view the router project documentation .","title":"Router"},{"location":"understanding-workflow/components/#logger-fluentd-logger","text":"The logging subsystem consists of two components. Fluentd handles log shipping and logger maintains a ring-buffer of application logs. Project Location: teamhephy/fluentd Fluentd is deployed to your Kubernetes cluster via Daemon Sets. Fluentd subscribes to all container logs, decorates the output with Kubernetes metadata and can be configured to drain logs to multiple destinations. By default, fluentd ships logs to the logger component, which powers deis logs . Project Location: teamhephy/logger The logger component receives log streams from fluentd , collating by Application name. Logger does not persist logs to disk, instead maintaining an in-memory ring buffer. For more information on logger see the project documentation .","title":"Logger: fluentd, logger"},{"location":"understanding-workflow/components/#monitor","text":"Project Location: teamhephy/monitor The monitoring subsystem consists of three components: Telegraf, InfluxDB and Grafana. Telegraf is the is the metrics collection agent that runs using the daemon set API. It runs on every worker node in the cluster, fetches information about the pods currently running and ships it to InfluxDB. InfluxDB is a database that stores the metrics collected by Telegraf. Out of the box, it does not persist to disk, but you can set it up to back it with a persisitent volume or swap this out with a more robust InfluxDB setup in a production setting. Grafana is a standalone graphing application. It natively supports InfluxDB as a datasource and provides a robust engine for creating dashboards on top of timeseries data. Workflow provides a few dashboards out of the box for monitoring Deis Workflow and Kubernetes. The dashboards can be used as a starting point for creating more custom dashboards to suit a user's needs.","title":"Monitor"},{"location":"understanding-workflow/components/#workflow-manager","text":"Project Location: teamhephy/workflow-manager Workflow Manager will regularly check your cluster against the latest stable components. If components are missing due to failure or are simply out of date, Workflow operators will know at a glance. By default, this submits component and version information to Deis' version service. If you prefer, you may disable the function by setting WORKFLOW_MANAGER_CHECKVERSIONS to false in Workflow Manager's Deployment.","title":"Workflow Manager"},{"location":"understanding-workflow/components/#see-also","text":"Workflow Concepts Workflow Architecture","title":"See Also"},{"location":"understanding-workflow/concepts/","text":"Concepts \u00b6 Deis Workflow is a lightweight application platform that deploys and scales Twelve-Factor apps as containers across a Kubernetes cluster. Twelve-Factor Applications \u00b6 The Twelve-Factor App is a methodology for building modern applications that can be scaled across a distributed system. Twelve-factor is a valuable synthesis of years of experience with software-as-a-service apps in the wild, particularly on the Heroku platform. Workflow is designed to run applications that adhere to the Twelve-Factor App methodology and best practices. Kubernetes \u00b6 Kubernetes is an open-source cluster manager developed by Google and donated to the Cloud Native Compute Foundation . Kubernetes manages all the activity on your cluster, including: desired state convergence, stable service addresses, health monitoring, service discovery, and DNS resolution. Workflow builds upon Kubernetes abstractions like Services, Deployments and Pods to provide a developer-friendly experience. Building containers directly from application source code, aggregating logs, and managing deployment configurations and app releases are just some of the features Workflow adds. Deis Workflow is a set of Kubernetes-native components, installable via Helm . Systems engineers who are familiar with Kubernetes will feel right at home running Workflow. See the components overview for more detail. Docker \u00b6 Docker is an open source project to build, ship and run any application as a lightweight, portable, self-sufficient container. If you have not yet converted your application to containers, Workflow provides a simple and straightforward \"source to Docker image\" capability. Supporting multiple language runtimes via community buildpacks , building your application in a container can be as easy as git push deis master . Applications which are packaged via a buildpack are run in Docker containers as part of the slugrunner process. View the slugrunner component for more information. Applications which use either a Dockerfile or reference external Docker images are launched unmodified. Applications \u00b6 Workflow is designed around the concept of an application , or app. Applications come in one of three forms: a collection of source files stored in a git repository a Dockerfile and associated source files stored in a git repository a reference to an existing image at a Docker repository Applications are identified by a unique name for easy reference. If you do not specify a name when creating your application, Workflow generates one for you. Workflow also manages related information, including domain names, SSL certificates, and developer-provided configuration. Build, Release, Run \u00b6 Build Stage \u00b6 The builder component processes incoming git push deis master requests and manages your application packaging. If your application is using a buildpack , builder will launch an ephemeral job to extract and execute the packaging instructions. The resulting application artifact is stored by the platform for execution during the run stage. If instead builder finds a Dockerfile , it follows those instructions to create a Docker image. The resulting artifact is stored in a Deis-managed registry which will be referenced during the run stage. If another system already builds and packages your application, that container artifact can be used directly. When referencing an external Docker image , the builder component doesn't attempt to repackage your app. Release Stage \u00b6 During the release stage, a build is combined with application configuration to create a new, numbered release . New releases are created any time a new build is created or application configuration is changed. Tracking releases as a \"write-only ledger\" this way makes it easy to rollback to any previous release. Run Stage \u00b6 The run stage deploys the new release to the underlying Kubernetes cluster by changing the Deployment object which references the new release. By managing the desired replica count, Workflow orchestrates a zero-downtime, rolling update of your application. Once successfully updated, Workflow removes the last reference to the old release. Note that during the deploy, your application will be running in a mixed mode. Backing Services \u00b6 Workflow treats all persistent services such as databases, caches, storage, messaging systems, and other backing services as resources managed separately from your application. This philosophy aligns with Twelve-Factor best practices. Applications attach to backing services using environment variables . Because apps are decoupled from backing services, they are free to scale up independently, to use services provided by other apps, or to switch to external or third-party vendor services. See Also \u00b6 Workflow Architecture Workflow Components","title":"Concepts"},{"location":"understanding-workflow/concepts/#concepts","text":"Deis Workflow is a lightweight application platform that deploys and scales Twelve-Factor apps as containers across a Kubernetes cluster.","title":"Concepts"},{"location":"understanding-workflow/concepts/#twelve-factor-applications","text":"The Twelve-Factor App is a methodology for building modern applications that can be scaled across a distributed system. Twelve-factor is a valuable synthesis of years of experience with software-as-a-service apps in the wild, particularly on the Heroku platform. Workflow is designed to run applications that adhere to the Twelve-Factor App methodology and best practices.","title":"Twelve-Factor Applications"},{"location":"understanding-workflow/concepts/#kubernetes","text":"Kubernetes is an open-source cluster manager developed by Google and donated to the Cloud Native Compute Foundation . Kubernetes manages all the activity on your cluster, including: desired state convergence, stable service addresses, health monitoring, service discovery, and DNS resolution. Workflow builds upon Kubernetes abstractions like Services, Deployments and Pods to provide a developer-friendly experience. Building containers directly from application source code, aggregating logs, and managing deployment configurations and app releases are just some of the features Workflow adds. Deis Workflow is a set of Kubernetes-native components, installable via Helm . Systems engineers who are familiar with Kubernetes will feel right at home running Workflow. See the components overview for more detail.","title":"Kubernetes"},{"location":"understanding-workflow/concepts/#docker","text":"Docker is an open source project to build, ship and run any application as a lightweight, portable, self-sufficient container. If you have not yet converted your application to containers, Workflow provides a simple and straightforward \"source to Docker image\" capability. Supporting multiple language runtimes via community buildpacks , building your application in a container can be as easy as git push deis master . Applications which are packaged via a buildpack are run in Docker containers as part of the slugrunner process. View the slugrunner component for more information. Applications which use either a Dockerfile or reference external Docker images are launched unmodified.","title":"Docker"},{"location":"understanding-workflow/concepts/#applications","text":"Workflow is designed around the concept of an application , or app. Applications come in one of three forms: a collection of source files stored in a git repository a Dockerfile and associated source files stored in a git repository a reference to an existing image at a Docker repository Applications are identified by a unique name for easy reference. If you do not specify a name when creating your application, Workflow generates one for you. Workflow also manages related information, including domain names, SSL certificates, and developer-provided configuration.","title":"Applications"},{"location":"understanding-workflow/concepts/#build-release-run","text":"","title":"Build, Release, Run"},{"location":"understanding-workflow/concepts/#build-stage","text":"The builder component processes incoming git push deis master requests and manages your application packaging. If your application is using a buildpack , builder will launch an ephemeral job to extract and execute the packaging instructions. The resulting application artifact is stored by the platform for execution during the run stage. If instead builder finds a Dockerfile , it follows those instructions to create a Docker image. The resulting artifact is stored in a Deis-managed registry which will be referenced during the run stage. If another system already builds and packages your application, that container artifact can be used directly. When referencing an external Docker image , the builder component doesn't attempt to repackage your app.","title":"Build Stage"},{"location":"understanding-workflow/concepts/#release-stage","text":"During the release stage, a build is combined with application configuration to create a new, numbered release . New releases are created any time a new build is created or application configuration is changed. Tracking releases as a \"write-only ledger\" this way makes it easy to rollback to any previous release.","title":"Release Stage"},{"location":"understanding-workflow/concepts/#run-stage","text":"The run stage deploys the new release to the underlying Kubernetes cluster by changing the Deployment object which references the new release. By managing the desired replica count, Workflow orchestrates a zero-downtime, rolling update of your application. Once successfully updated, Workflow removes the last reference to the old release. Note that during the deploy, your application will be running in a mixed mode.","title":"Run Stage"},{"location":"understanding-workflow/concepts/#backing-services","text":"Workflow treats all persistent services such as databases, caches, storage, messaging systems, and other backing services as resources managed separately from your application. This philosophy aligns with Twelve-Factor best practices. Applications attach to backing services using environment variables . Because apps are decoupled from backing services, they are free to scale up independently, to use services provided by other apps, or to switch to external or third-party vendor services.","title":"Backing Services"},{"location":"understanding-workflow/concepts/#see-also","text":"Workflow Architecture Workflow Components","title":"See Also"},{"location":"users/cli/","text":"Deis Workflow CLI \u00b6 The Deis Workflow command-line interface (CLI), or client, allows you to interact with Deis Workflow. Installation \u00b6 Install the latest deis client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 The installer puts deis in your current directory, but you should move it somewhere in your $PATH: $ ln -fs $PWD/deis /usr/local/bin/deis Getting Help \u00b6 The Deis client comes with comprehensive documentation for every command. Use deis help to explore the commands available to you: $ deis help The Deis command-line client issues API calls to a Deis controller. Usage: deis <command> [<args>...] Auth commands:: register register a new user with a controller login login to a controller logout logout from the current controller Subcommands, use `deis help [subcommand]` to learn more:: ... To get help on subcommands, use deis help [subcommand] : $ deis help apps Valid commands for apps: apps:create create a new application apps:list list accessible applications apps:info view info about an application apps:open open the application in a browser apps:logs view aggregated application logs apps:run run a command in an ephemeral app container apps:destroy destroy an application Use `deis help [command]` to learn more Support for Multiple Profiles \u00b6 The CLI reads from the default client profile, which is located on your workstation at $HOME/.deis/client.json . Easily switch between multiple Deis Workflow installations or users by setting the $DEIS_PROFILE environment variable or by using the -c flag. There are two ways to set the $DEIS_PROFILE option. Path to a json configuration file. Profile name. If you set profile to just a name, it will be saved alongside the default profile, in $HOME/.deis/<name>.json . Examples: $ DEIS_PROFILE=production deis login deis.production.com ... Configuration saved to /home/testuser/.deis/production.json $ DEIS_PROFILE=~/config.json deis login deis.example.com ... Configuration saved to /home/testuser/config.json The configuration flag works identically to and overrides $DEIS_PROFILE : $ deis whoami -c ~/config.json You are deis at deis.example.com Proxy Support \u00b6 If your workstation uses a proxy to reach the network where the cluster lies, set the http_proxy or https_proxy environment variable to enable proxy support: $ export http_proxy=\"http://proxyip:port\" $ export https_proxy=\"http://proxyip:port\" Note Configuring a proxy is generally not necessary for local Minikube clusters. CLI Plugins \u00b6 Plugins allow developers to extend the functionality of the Deis Client, adding new commands or features. If an unknown command is specified, the client will attempt to execute the command as a dash-separated command. In this case, deis resource:command will execute deis-resource with the argument list command . In full form: $ # these two are identical $ deis accounts:list $ deis-accounts list Any flags after the command will also be sent to the plugin as an argument: $ # these two are identical $ deis accounts:list --debug $ deis-accounts list --debug But flags preceding the command will not: $ # these two are identical $ deis --debug accounts:list $ deis-accounts list","title":"Command Line Interface"},{"location":"users/cli/#deis-workflow-cli","text":"The Deis Workflow command-line interface (CLI), or client, allows you to interact with Deis Workflow.","title":"Deis Workflow  CLI"},{"location":"users/cli/#installation","text":"Install the latest deis client for Linux or Mac OS X with: $ curl -sSL https://raw.githubusercontent.com/teamhephy/workflow-cli/master/install-v2.sh | bash -s v2.18.0 The installer puts deis in your current directory, but you should move it somewhere in your $PATH: $ ln -fs $PWD/deis /usr/local/bin/deis","title":"Installation"},{"location":"users/cli/#getting-help","text":"The Deis client comes with comprehensive documentation for every command. Use deis help to explore the commands available to you: $ deis help The Deis command-line client issues API calls to a Deis controller. Usage: deis <command> [<args>...] Auth commands:: register register a new user with a controller login login to a controller logout logout from the current controller Subcommands, use `deis help [subcommand]` to learn more:: ... To get help on subcommands, use deis help [subcommand] : $ deis help apps Valid commands for apps: apps:create create a new application apps:list list accessible applications apps:info view info about an application apps:open open the application in a browser apps:logs view aggregated application logs apps:run run a command in an ephemeral app container apps:destroy destroy an application Use `deis help [command]` to learn more","title":"Getting Help"},{"location":"users/cli/#support-for-multiple-profiles","text":"The CLI reads from the default client profile, which is located on your workstation at $HOME/.deis/client.json . Easily switch between multiple Deis Workflow installations or users by setting the $DEIS_PROFILE environment variable or by using the -c flag. There are two ways to set the $DEIS_PROFILE option. Path to a json configuration file. Profile name. If you set profile to just a name, it will be saved alongside the default profile, in $HOME/.deis/<name>.json . Examples: $ DEIS_PROFILE=production deis login deis.production.com ... Configuration saved to /home/testuser/.deis/production.json $ DEIS_PROFILE=~/config.json deis login deis.example.com ... Configuration saved to /home/testuser/config.json The configuration flag works identically to and overrides $DEIS_PROFILE : $ deis whoami -c ~/config.json You are deis at deis.example.com","title":"Support for Multiple Profiles"},{"location":"users/cli/#proxy-support","text":"If your workstation uses a proxy to reach the network where the cluster lies, set the http_proxy or https_proxy environment variable to enable proxy support: $ export http_proxy=\"http://proxyip:port\" $ export https_proxy=\"http://proxyip:port\" Note Configuring a proxy is generally not necessary for local Minikube clusters.","title":"Proxy Support"},{"location":"users/cli/#cli-plugins","text":"Plugins allow developers to extend the functionality of the Deis Client, adding new commands or features. If an unknown command is specified, the client will attempt to execute the command as a dash-separated command. In this case, deis resource:command will execute deis-resource with the argument list command . In full form: $ # these two are identical $ deis accounts:list $ deis-accounts list Any flags after the command will also be sent to the plugin as an argument: $ # these two are identical $ deis accounts:list --debug $ deis-accounts list --debug But flags preceding the command will not: $ # these two are identical $ deis --debug accounts:list $ deis-accounts list","title":"CLI Plugins"},{"location":"users/registration/","text":"Users and Registration \u00b6 There are two classes of Workflow users: normal users and administrators. Users can use most of the features of Workflow - creating and deploying applications, adding/removing domains, etc. Administrators can perform all the actions that users can, but they also have owner access to all applications. The first user created on a Workflow installation is automatically an administrator. Register with a Controller \u00b6 Use deis register with the Controller URL (supplied by your Deis administrator) to create a new account. After successful registration you will be logged in as the new user. $ deis register http://deis.example.com username: myuser password: password (confirm): email: myuser@example.com Registered myuser Logged in as myuser Important The first user to register with Deis Workflow automatically becomes an administrator. Additional users who register will be ordinary users. Login to Workflow \u00b6 If you already have an account, use deis login to authenticate against the Deis Workflow API. $ deis login http://deis.example.com username: deis password: Logged in as deis Logout from Workflow \u00b6 Logout of an existing controller session using deis logout . $ deis logout Logged out as deis Verify Your Session \u00b6 You can verify your client configuration by running deis whoami . $ deis whoami You are deis at http://deis.example.com Note Session and client configuration is stored in the ~/.deis/client.json file. Registering New Users \u00b6 By default, new users are not allowed to register after an initial user does. That initial user becomes the first \"admin\" user. Others will now receive an error when trying to register, but when logged in, an admin user can register new users: $ deis register --login=false --username=newuser --password=changeme123 --email=newuser@deis.io Controlling Registration Modes \u00b6 After creating your first user, you may wish to change the registration mode for Deis Workflow. Deis Workflow supports three registration modes: Mode Description admin_only (default) Only existing admins may register new users enabled Registration is enabled and anyone can register disabled Does not allow anyone to register new users. To modify the registration mode for Workflow you may add or modify the REGISTRATION_MODE environment variable for the controller component. If Deis Workflow is already running, use: kubectl --namespace=deis patch deployments deis-controller -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"deis-controller\",\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"disabled\"}]}]}}}}' Modify the value portion to match the desired mode. Kubernetes will automatically deploy a new ReplicaSet and corresponding Pod with the new environment variables set. Managing Administrative Permissions \u00b6 You can use the deis perms command to promote a user to an admin: $ deis perms:create john --admin Adding john to system administrators... done View current admins: $ deis perms:list --admin === Administrators admin john Demote admins to normal users: $ deis perms:delete john --admin Removing john from system administrators... done Re-issuing User Authentication Tokens \u00b6 The controller API uses a simple token-based HTTP Authentication scheme. Token authentication is appropriate for client-server setups, such as native desktop and mobile clients. Each user of the platform is issued a token the first time that they sign up on the platform. If this token is compromised, it will need to be regenerated. A user can regenerate their own token like this: $ deis auth:regenerate An administrator can also regenerate the token of another user like this: $ deis auth:regenerate -u test-user At this point, the user will no longer be able to authenticate against the controller with his auth token: $ deis apps 401 UNAUTHORIZED Detail: Invalid token They will need to log back in to use their new auth token. If there is a cluster wide security breach, an administrator can regenerate everybody's auth token like this: $ deis auth:regenerate --all=true Changing Account Password \u00b6 A user can change their own account's password like this: $ deis auth:passwd current password: new password: new password (confirm): An administrator can change the password of another user's account like this: $ deis auth:passwd --username=<username> new password: new password (confirm):","title":"Users and Registration"},{"location":"users/registration/#users-and-registration","text":"There are two classes of Workflow users: normal users and administrators. Users can use most of the features of Workflow - creating and deploying applications, adding/removing domains, etc. Administrators can perform all the actions that users can, but they also have owner access to all applications. The first user created on a Workflow installation is automatically an administrator.","title":"Users and Registration"},{"location":"users/registration/#register-with-a-controller","text":"Use deis register with the Controller URL (supplied by your Deis administrator) to create a new account. After successful registration you will be logged in as the new user. $ deis register http://deis.example.com username: myuser password: password (confirm): email: myuser@example.com Registered myuser Logged in as myuser Important The first user to register with Deis Workflow automatically becomes an administrator. Additional users who register will be ordinary users.","title":"Register with a Controller"},{"location":"users/registration/#login-to-workflow","text":"If you already have an account, use deis login to authenticate against the Deis Workflow API. $ deis login http://deis.example.com username: deis password: Logged in as deis","title":"Login to Workflow"},{"location":"users/registration/#logout-from-workflow","text":"Logout of an existing controller session using deis logout . $ deis logout Logged out as deis","title":"Logout from Workflow"},{"location":"users/registration/#verify-your-session","text":"You can verify your client configuration by running deis whoami . $ deis whoami You are deis at http://deis.example.com Note Session and client configuration is stored in the ~/.deis/client.json file.","title":"Verify Your Session"},{"location":"users/registration/#registering-new-users","text":"By default, new users are not allowed to register after an initial user does. That initial user becomes the first \"admin\" user. Others will now receive an error when trying to register, but when logged in, an admin user can register new users: $ deis register --login=false --username=newuser --password=changeme123 --email=newuser@deis.io","title":"Registering New Users"},{"location":"users/registration/#controlling-registration-modes","text":"After creating your first user, you may wish to change the registration mode for Deis Workflow. Deis Workflow supports three registration modes: Mode Description admin_only (default) Only existing admins may register new users enabled Registration is enabled and anyone can register disabled Does not allow anyone to register new users. To modify the registration mode for Workflow you may add or modify the REGISTRATION_MODE environment variable for the controller component. If Deis Workflow is already running, use: kubectl --namespace=deis patch deployments deis-controller -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"deis-controller\",\"env\":[{\"name\":\"REGISTRATION_MODE\",\"value\":\"disabled\"}]}]}}}}' Modify the value portion to match the desired mode. Kubernetes will automatically deploy a new ReplicaSet and corresponding Pod with the new environment variables set.","title":"Controlling Registration Modes"},{"location":"users/registration/#managing-administrative-permissions","text":"You can use the deis perms command to promote a user to an admin: $ deis perms:create john --admin Adding john to system administrators... done View current admins: $ deis perms:list --admin === Administrators admin john Demote admins to normal users: $ deis perms:delete john --admin Removing john from system administrators... done","title":"Managing Administrative Permissions"},{"location":"users/registration/#re-issuing-user-authentication-tokens","text":"The controller API uses a simple token-based HTTP Authentication scheme. Token authentication is appropriate for client-server setups, such as native desktop and mobile clients. Each user of the platform is issued a token the first time that they sign up on the platform. If this token is compromised, it will need to be regenerated. A user can regenerate their own token like this: $ deis auth:regenerate An administrator can also regenerate the token of another user like this: $ deis auth:regenerate -u test-user At this point, the user will no longer be able to authenticate against the controller with his auth token: $ deis apps 401 UNAUTHORIZED Detail: Invalid token They will need to log back in to use their new auth token. If there is a cluster wide security breach, an administrator can regenerate everybody's auth token like this: $ deis auth:regenerate --all=true","title":"Re-issuing User Authentication Tokens"},{"location":"users/registration/#changing-account-password","text":"A user can change their own account's password like this: $ deis auth:passwd current password: new password: new password (confirm): An administrator can change the password of another user's account like this: $ deis auth:passwd --username=<username> new password: new password (confirm):","title":"Changing Account Password"},{"location":"users/ssh-keys/","text":"Users and SSH Keys \u00b6 For Dockerfile and Buildpack based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. Users may have multiple SSH keys as needed. Generate an SSH Key \u00b6 If you do not already have an SSH key or would like to create a new key for Deis Workflow, generate a new key using ssh-keygen : $ ssh-keygen -f ~/.ssh/id_deis -t rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/admin/.ssh/id_deis. Your public key has been saved in /Users/admin/.ssh/id_deis.pub. The key fingerprint is: 3d:ac:1f:f4:83:f7:64:51:c1:7e:7f:80:b6:70:36:c9 admin@plinth-23437.local The key's randomart image is: +--[ RSA 2048]----+ | .. | | ..| | . o. .| | o. E .o.| | S == o..o| | o +. .o| | . o + o .| | . o = | | . . | +-----------------+ $ ssh-add ~/.ssh/id_deis Identity added: /Users/admin/.ssh/id_deis (/Users/admin/.ssh/id_deis) Adding and Removing SSH Keys \u00b6 By publishing the public half of your SSH key to Deis Workflow the component responsible for receiving git push will be able to authenticate the user and ensure that they have access to the destination application. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done You can always view the keys associated with your user as well: $ deis keys:list === admin Keys admin@plinth-23437.local ssh-rsa AAAAB3Nz...3437.local admin@subgenius.local ssh-rsa AAAAB3Nz...nius.local Remove keys by their name: $ deis keys:remove admin@plinth-23437.local Removing admin@plinth-23437.local SSH Key... don","title":"SSH Keys"},{"location":"users/ssh-keys/#users-and-ssh-keys","text":"For Dockerfile and Buildpack based application deploys via git push , Deis Workflow identifies users via SSH keys. SSH keys are pushed to the platform and must be unique to each user. Users may have multiple SSH keys as needed.","title":"Users and SSH Keys"},{"location":"users/ssh-keys/#generate-an-ssh-key","text":"If you do not already have an SSH key or would like to create a new key for Deis Workflow, generate a new key using ssh-keygen : $ ssh-keygen -f ~/.ssh/id_deis -t rsa Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/admin/.ssh/id_deis. Your public key has been saved in /Users/admin/.ssh/id_deis.pub. The key fingerprint is: 3d:ac:1f:f4:83:f7:64:51:c1:7e:7f:80:b6:70:36:c9 admin@plinth-23437.local The key's randomart image is: +--[ RSA 2048]----+ | .. | | ..| | . o. .| | o. E .o.| | S == o..o| | o +. .o| | . o + o .| | . o = | | . . | +-----------------+ $ ssh-add ~/.ssh/id_deis Identity added: /Users/admin/.ssh/id_deis (/Users/admin/.ssh/id_deis)","title":"Generate an SSH Key"},{"location":"users/ssh-keys/#adding-and-removing-ssh-keys","text":"By publishing the public half of your SSH key to Deis Workflow the component responsible for receiving git push will be able to authenticate the user and ensure that they have access to the destination application. $ deis keys:add ~/.ssh/id_deis.pub Uploading id_deis.pub to deis... done You can always view the keys associated with your user as well: $ deis keys:list === admin Keys admin@plinth-23437.local ssh-rsa AAAAB3Nz...3437.local admin@subgenius.local ssh-rsa AAAAB3Nz...nius.local Remove keys by their name: $ deis keys:remove admin@plinth-23437.local Removing admin@plinth-23437.local SSH Key... don","title":"Adding and Removing SSH Keys"}]}